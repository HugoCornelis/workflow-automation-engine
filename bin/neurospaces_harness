#!/usr/bin/perl -w
#!/usr/bin/perl -d:ptkdb
#
# $Id: run 1.80 Wed, 26 Dec 2007 21:42:57 -0600 hugo $
#

use strict;


our $core_directory;

our $built_exe_directory;

# our $perl_modules_directory;

our $config;


# BEGIN
# {
#     #! make check

#     push @INC, '../perl';

#     #! make distcheck

#     push @INC, '../../perl';

#     #! normal run

#     push @INC, './perl';

#     #! after install

#     push @INC, '/usr/local/glue/swig/perl';

#     # check for ".genesis3" directory. If not present we create
#     # it and set a directory for perl inline code. 
#     my $inline_path = "$ENV{HOME}/.genesis3/ssp/InlineCode";
#     if(! -e $inline_path)
#     {
#       use File::Path;

#       &File::Path::mkpath($inline_path);
#     }

#     $ENV{PERL_INLINE_DIRECTORY} = $inline_path;

# }


sub initialize_running_mode
{
    # default : running stand-alone

    my $test_mode = 'stand-alone';

    # find the package core directory

    $config = do './tests.config';

    if (!defined $config)
    {
	if ($ENV{srcdir})
	{
	    $config = do "$ENV{srcdir}/tests.config";

	    # register that we are running from automake

	    $test_mode = 'automake';
	}
    }

    if (!defined $config)
    {
	die "No test configuration found";
    }

    # protect for automake

    if ($test_mode eq 'stand-alone')
    {
	$core_directory = $config->{core_directory};
    }
    else
    {
	$core_directory = "$ENV{srcdir}/$config->{core_directory}";

	$core_directory = $config->{core_directory};

    }

    # remove parent and current directories

    $core_directory =~ s(([^\.])\./)($1)g;

    $core_directory =~ s([^/\.]+/\.\./)()g;

    print "$0: core_directory is $core_directory\n";

    # add to tests directory to include paths

    if (!exists $config->{tests_directory})
    {
	$config->{tests_directory} = "${core_directory}tests/specifications";
    }

    unshift @INC, $config->{tests_directory};
}


my $loaded_mail_sender = eval "require Mail::Sender";

use Data::Comparator qw(data_comparator);
use Data::Transformator;

use Expect;

use Getopt::Long;

use Neurospaces::Tester;;

use YAML;


my $option_email = defined $ENV{NEUROSPACES_HARNESS_OPTION_EMAIL} ? $ENV{NEUROSPACES_HARNESS_OPTION_EMAIL} : 0 ;
my $option_flattenout;
my $option_help;
my $option_numerical_compare = $config->{numerical_compare} || 0;
my $option_random_order;
my $option_regex_selector = ".*";
my $option_report_disabled;
my $option_report_mac;
my $option_report_target;
my $option_show;
my $option_timeout_multiplier = 1;
my $option_timings;
my $option_trace;
my $option_verbose;


sub initialize_environment
{
    print "Executable is $0,\n";
    print "core_directory is $core_directory\n";

    my $environment_settings = $config->{environment_settings};

    foreach my $environment_setting_name (keys %$environment_settings)
    {
	my $environment_setting = $environment_settings->{$environment_setting_name};

	# if simply setting values in the environment

	if (!ref $environment_setting)
	{
	    # set the value in the environment

	    $ENV{$environment_setting_name} = $environment_setting;
	}

	# if additional initialization required

	elsif (ref $environment_setting eq 'HASH')
	{
	    # get environment_setting value

	    my $value = $environment_setting->{value};

	    # set the value in the environment

	    $ENV{$environment_setting_name} = $value;

	    # give feedback

	    my $description = $environment_setting->{description};

	    $description =~ s/%value/$value/g;

	    print $description;

	    # loop over shell commands for initialization

	    my $shell_commands = $environment_setting->{initialization}->{shell};

	    foreach my $shell_command (@$shell_commands)
	    {
		# replace value

		$shell_command =~ s/%value/$value/g;

		# execute command

		print "$0: executing ($shell_command)\n";

		system $shell_command;
	    }
	}
	else
	{
	    die "$0: illegal environment_settings, was processing $environment_setting";
	}
    }

    if (defined ($config->{environment}))
    {
	print "Your models will be searched for in the directory $ENV{NEUROSPACES_NMC_MODELS}\n\n";
    }
}


my $error_count = 0;

my $test_report;

sub initialize_globals
{
    my $test_report
	= {
	    description => {
		command => $0,
		name => "Test report",
		package => $config->{package},
	    },
	    global => {
		config => $config,
		error_count => $error_count,
		status => 'initializing',
		test_count => 0,
		time_start => `date`,
	    },
	    target => {
		OS => $^O,
		system => {
		    libc => (join '', `ls -l /lib/libc-* && ls -l /usr/lib/libc-*`),
		    uname => (join '', `uname -a`),
		    cpu => (join '', `cat /proc/cpuinfo`),
		},
		packages => {
		    '/etc/lsb-release' => (join '', `cat /etc/lsb-release`),
		    autoconf => (join '', `autoconf --version`),
		    automake => (join '', `automake --version`),
		    bison => (join '', `bison --version`),
		    flex => (join '', `flex --version`),
		    gcc => (join '', `gcc 2>&1 --version && gcc 2>&1 -v`),
		    perl => (join '', `perl 2>&1 -v && perl 2>&1 -V`),
		    python => (join '', `python 2>&1 --version`),
		    python_installation => (join '', `./contrib/pythontest 2>&1`),,
		    swig => (join '', `swig 2>&1 -version`),
		},
	    },
    };
}


$SIG{'__DIE__'}
    = sub
      {
	  use Carp;

	  print STDERR Carp::longmess(@_);

	  $test_report->{global}->{status} = 'Died';

	  report_exit(3, @_);
      };


$SIG{'INT'}
    = sub
      {
	  $test_report->{global}->{status} = 'Interrupted';

	  report_exit(2);
      };


sub general_preparation
{
    my $module_definition = shift;

    my $command_definition = shift;

    my $preparation
	= ($command_definition
	   ? $command_definition->{preparation}
	   : $module_definition->{preparation});

    if ($preparation)
    {
	my $preparation_name
	    = ($command_definition
	       ? "command '$command_definition->{command}'"
	       : "module '$module_definition->{name}'");

	print "*** Preparing $preparation_name ($preparation->{description})\n";

	my $preparer = $preparation->{preparer};

	my $preparation_result = &$preparer();

	return $preparation_result;
    }
    else
    {
	return undef;
    }
}


sub general_reparation
{
    my $module_definition = shift;

    my $command_definition = shift;

    my $preparation_result = shift;

    my $reparation
	= ($command_definition
	   ? $command_definition->{reparation}
	   : $module_definition->{reparation});

    my $reparation_name
	= ($command_definition
	   ? "command '$command_definition->{command}'"
	   : "module '$module_definition->{name}'");

    if ($reparation)
    {
	print "*** Reparing $reparation_name ($reparation->{description})\n";

	my $reparer = $reparation->{reparer};

	my $reparation_error = &$reparer($preparation_result);

	# process errors

	if ($reparation_error)
	{
	    my $module_name = $module_definition->{name};

	    my $subdescription
		= ($command_definition
		   ? $command_definition->{description}
		   : $module_definition->{description});

	    report_error_add
		(
		 {
		     description => $reparation_name,
		     error => $reparation_error,
		     module_name => $module_name,
		     subdescription => $subdescription,
		 },
		);
	}
    }
}


my $global_exp;

my $global_previous_command_side_effects;

my $global_running_command_definition;

sub command_spawn_new
{
    my $command_definition = shift;

    # a command can be an absolute pathname,
    # can come from the _build directory
    # or from the sources for a script

# 		-f $command and print "Found command $command\n";
# 		-f $built_exe_directory . $command and print "Found built $built_exe_directory$command\n";
# 		-f $core_directory . $command and print "Found core $core_directory$command\n";

    my $command = $command_definition->{command};

    my $test_command = $command;
    # = (-f $command
    #    ? $command
    #    : (defined $built_exe_directory
    #       ? (-f $built_exe_directory . $command
    #        ? $built_exe_directory . $command
    #        : $core_directory . $command)
    #       : $command));

    # find differences between how to run this command and
    # the one already running

    my $new_command_definition
	= {
	    arguments => $command_definition->{arguments},
	    command => $test_command,
	  };

    my $differences = data_comparator($new_command_definition, $global_running_command_definition);

    # remember to spawn a new command

    my $spawn_new;

    $spawn_new =
	(
	 # if we do not have a previous command

	 !$global_exp

	 # or if there were differences with the previous command

	 || !$differences->is_empty()

	 # or if the previous command had side effects

	 || $global_previous_command_side_effects

	 # or if we had to prepare this command

	 || $command_definition->{preparation}
	);

    # prefix the command with the core directory

    $command = $new_command_definition->{command};

    my $arguments = $command_definition->{arguments};

    # if the command can be executed

    my $test_startup;

# 		    if (-x $command)
    if (defined $command)
    {
	if ($spawn_new)
	{
	    if ($global_exp)
	    {
		# terminate the previous command

		#t could be that the hard_close() call is needed because
		#t neurospaces uses readline, not sure needs investigation,
		#t perhaps.

		$global_exp->hard_close();
	    }

	    # create a new Expect object by spawning a new process with the new command

	    $global_exp = Expect->new();

	    #! see the expect manual for this one

	    $global_exp->raw_pty(1);

	    # 		    $exp->slave->stty(qw(raw -echo));

	    $global_exp->spawn
		(
		 (
		  $option_trace
		  ? ("strace", "-f")
		  : ()
		 ),
		 $command,
		 @$arguments
		)
		or die "$0: cannot spawn $command: $!\n";

	    # set the running_command_definition

	    $global_running_command_definition = $new_command_definition;

	    print "*** Executing $command " . (join ' ', map { "'$_'" } @$arguments) . "\n";

	    # remember to do startup testing

	    $test_startup = 1;

	    # there were no side effects yet

	    $global_previous_command_side_effects = 0;
	}
	else
	{
	    print "*** Recycling $command " . (join ' ', map { "'$_'" } @$arguments) . "\n";

	    $test_startup = 0;
	}
    }
    # else
    # {
    # 	my $error = "$command is not executable";

    # 	report_error_add
    # 	    (
    # 	     {
    # 	      description => $description,
    # 	      error => $error,
    # 	      module_name => $module_name,
    # 	     },
    # 	    );

    # 	next;
    # }

    return $global_exp, $test_startup;
}


sub main
{
    parse_options();

    initialize_running_mode();

    initialize_environment();

    initialize_globals();

    # find all the test module files

    my $test_modules = test_library_construct();

    # read the test module files

    $test_modules = test_library_expand($test_modules);

    # total test count so far is zero

    my $test_count = 0;

    # compute the library checksum

    my $library_sha_before;

    if (defined ($config->{model_library}))
    {
	$library_sha_before = model_library_sha();

    }

    # the previous command had no side effects on the loaded model (since there is no model yet)

    my $previous_command_side_effects = 0;

    # set status: running

    $test_report->{global}->{status} = 'Running';

    # randomize test module order if requested

    if (defined $option_random_order)
    {
	require List::Util;

	my $seed = time() ^ $$ ^ unpack "%L*", `ps axww | gzip`;

	if ($option_random_order =~ /^[0-9]*$/
	    and $option_random_order ne 1)
	{
	    $seed = $option_random_order
	}

	print "Randomizing test specifications, seed is $seed\n";

	srand($seed);

	$test_report->{random_seed} = $seed;

	# and shuffle the modules

	$test_modules = [ List::Util::shuffle(@$test_modules), ];
    }
    else
    {
	$test_report->{random_seed} = 'not randomized';
    }

    $test_report->{global}->{test_count} = 0;

    # loop over all module definitions

    foreach my $module_definition (@$test_modules)
    {
	if (!defined $module_definition->{name})
	{
	    $module_definition->{name} = 'unnamed';

	    report_error_add
		(
		 {
		  description => 'unnamed module',
		  error => 'unnamed module',
		  module_name => 'unnamed module',
		 },
		);
	}

	my $module_name = $module_definition->{name};

	if (!defined $module_definition->{description})
	{
	    $module_definition->{description} = $module_definition->{name};

	    report_error_add
		(
		 {
		  description => 'no module description',
		  error => 'no module description',
		  module_name => $module_name,
		 },
		);
	}

	if ($module_definition->{disabled})
	{
	    if (not $option_show)
	    {
		report_message(1, 2, "Module $module_definition->{description} is disabled ($module_definition->{disabled}).
Total of $test_report->{global}->{test_count} tests (encountered $error_count error(s) so far)");
	    }

	    $test_report->{disabled}->{modules}->{$module_name} = $module_definition->{disabled};

	    next;
	}


# 	if ($module_definition->{mac_report})
# 	{
# 	    report_message(1, 2, "Module $module_definition->{description} is disabled on Mac OSX: ($module_definition->{mac_report}).
# Total of $test_report->{global}->{test_count} tests (encountered $error_count error(s) so far)");

# 	    $test_report->{mac_report}->{modules}->{$module_name} = $module_definition->{mac_report};

# 	    next;
# 	}


	if ($module_definition->{error})
	{
	    report_error_add
		(
		 {
		  description => $module_definition->{description},
		  error => "this test was tagged with the error flag",
		  module_name => $module_name,
		  subdescription => $module_definition->{error},
		 },
		);

	    next;
	}

	report_message(2, 1, "Running tests of module $module_definition->{description} ($module_definition->{name})");

	# emit comment if any

	my $comment = $module_definition->{comment};

	if ($comment)
	{
	    print "*** Comment: $comment\n";
	}

	# prepare the module test environment

	my $module_preparation_result = general_preparation($module_definition, undef);

	# loop over commands for this module

	my $command_definitions = $module_definition->{command_definitions};

	foreach my $command_definition (@$command_definitions)
	{
	    my $description = $command_definition->{description};

	    if ($command_definition->{disabled})
	    {
		if (not $option_show)
		{
		    report_message(1, 2, "Tests of $description are disabled ($command_definition->{disabled})
Total of $test_report->{global}->{test_count} tests (encountered $error_count error(s) so far)");

		    $test_report->{disabled}->{command_definitions}->{$module_name}->{$description} = $command_definition->{disabled};
		}

		next;
	    }


# 	    if ($command_definition->{mac_report})
# 	    {
# 		report_message(1, 2, "Tests of $description are disabled on Mac OSX: ($command_definition->{mac_report})
# Total of $test_report->{global}->{test_count} tests (encountered $error_count error(s) so far)");

# 		$test_report->{mac_report}->{command_definitions}->{$module_name}->{$description} = $command_definition->{mac_report};

# 		next;
# 	    }

	    if ($command_definition->{error})
	    {
		report_error_add
		    (
		     {
		      description => $description,
		      error => "this test was tagged with the error flag",
		      module_name => $module_name,
		      subdescription => $command_definition->{error},
		     },
		    );

		next;
	    }

	    if ($option_show)
	    {
		if (!$test_report->{selected}->{$module_name}->{$description})
		{
		    $test_report->{selected}->{$module_name}->{$description} = 1;
		}

		next;
	    }

	    # give some diagnostics

	    if (@$command_definitions > 1)
	    {
		report_message(2, 1, "Running tests of $description");

		# emit comment if any

		my $comment = $command_definition->{comment};

		if ($comment)
		{
		    print "*** Comment: $comment\n";
		}
	    }

	    # prepare the command test environment

	    my $preparation_result = general_preparation($module_definition, $command_definition);

	    my $command = $command_definition->{command};

	    my $command_object;

	    my ($exp, $test_startup);

	    # we have to either instantiate an object that produces output ...

	    if ($command_definition->{class})
	    {
		# instantiate the object

		my $class = $command_definition->{class};

		my $filename = $class . ".pm";

		$filename =~ s(::)(/)g;

		require $filename;

		$command_object = eval "$class->new()";
	    }

	    # ... or run perl code that produces output

	    elsif (ref $command eq 'CODE')
	    {
		# code is already instantiated, nothing to do here
	    }

	    # ... or run a command that produces output

	    else
	    {
		# start the command and connect with its I/O channels

		#! this is similar to having a class name 'Expect' and calling Expect->new()
		#! but with optimization to prevent spawning new commands unnecessarily

		($exp, $test_startup) = command_spawn_new($command_definition);
	    }

	    # loop over all tests for this command

	    my $command_tests = $command_definition->{command_tests};

	    foreach my $command_test (@$command_tests)
	    {
		# give feedback about this specific test

		my $description = $command_test->{description};

		if ($command_test->{disabled})
		{
		    report_message(1, 2, "Tests of $description are disabled ($command_test->{disabled})
Total of $test_report->{global}->{test_count} tests (encountered $error_count error(s) so far)");

		    $test_report->{disabled}->{command_tests}->{$module_name}->{$description} = $command_test->{disabled};

		    next;
		}

# 		if ($command_test->{mac_report})
# 		{
# 		    report_message(1, 2, "Tests of $description are disabled on Mac OSX: ($command_test->{mac_report})
# Total of $test_report->{global}->{test_count} tests (encountered $error_count error(s) so far)");

# 		    $test_report->{mac_report}->{command_tests}->{$module_name}->{$description} = $command_test->{mac_report};

# 		    next;
# 		}

		if ($command_test->{error})
		{
		    report_error_add
			(
			 {
			  description => $description,
			  error => "this test was tagged with the error flag",
			  module_name => $module_name,
			  subdescription => $command_test->{error},
			 },
			);

		    next;
		}

		# expect this output

		my ($matched_pattern_position,
		    $error,
		    $successfully_matching_string,
		    $before_match,
		    $after_match);

		my $expected;

		my $time_elapsed;

		print "*** Test: $description\n";

		# if the command_definition instantiated an object

		if ($command_object
		    and (ref $command_test->{write} eq 'ARRAY'))
		{
		    # write data to the object using the given methods
		    # and arguments and obtain a result from the
		    # object

		    my $result;

		    my $last_method;

		    my $writes = $command_test->{write};

		    foreach my $write (@$writes)
		    {
			my $method = $write->{method};

			$last_method = $method;

			my $arguments = $write->{arguments};

			$result = $command_object->$method(@$arguments);
		    }

		    # comopare the read data with what is expected

		    if (exists $command_test->{read})
		    {
			my $read = $command_test->{read};

			$error
			    = ($result eq $read
			       ? ""
			       : "$last_method returned $result, expected $read");

			$before_match = $result;

			$expected = $read;
		    }
		}

		# if the command_definition has executable perl code

		elsif (ref $command eq 'CODE')
		{
		    # execute the perl code

		    $error
			= &$command
			    (
			     $command_test,
			     {
			      c_code => {
					 directory => $core_directory,
					},
			     },
			    );
		}

		# else the command definition runs a shell command

		else
		{
		    if ($description =~ /startup successful \?$/)
		    {
			if (!$test_startup)
			{
			    print "*** Skipped: not testing startup tests on a recycled command ($description)\n";

			    next;
			}
		    }

		    # emit comment if any

		    my $comment = $command_test->{comment};

		    if ($comment)
		    {
			print "*** Comment: $comment\n";
		    }

		    # set read, wait and write strings

		    my $read = $command_test->{read};

		    my $wait = $command_test->{wait};

		    my $write = $command_test->{write};

		    # set the external tester that tests the generated output with what should be expected

		    #! the external tester runs an executable shell command

		    my $tester = $command_test->{tester};

		    # set timeout, defaults to two seconds, but for newly created processes add two additional seconds.

		    my $timeout
			= defined $command_test->{timeout}
			    ? $command_test->{timeout} * $option_timeout_multiplier
				: $test_startup
				    ? 4 * $option_timeout_multiplier
					: 2 * $option_timeout_multiplier;

		    use Time::HiRes qw(gettimeofday tv_interval);

		    # write

		    my $time_start = [ gettimeofday(), ];

		    if (ref $write eq 'HASH')
		    {
		    }
		    elsif (defined $write)
		    {
			print "*** Write: $write\n";

			$exp->send("$write\n");
		    }

		    # wait

		    if ($wait)
		    {
			print "*** Wait: $wait\n";

			select(undef, undef, undef, $wait);
		    }

		    # check the shell command that will be executed with a timeout

		    my $shell = $command_test->{shell};

		    if (ref $shell eq 'HASH')
		    {
			#! not sure what this can be
		    }
		    elsif (defined $shell)
		    {
			# run the shell command for a maximum of $timeout seconds

			print "*** Shell: timeout $timeout $shell\n";

			system "timeout $timeout $shell";
		    }

		    # if there is a test external to the application

		    if ($tester)
		    {
			my $shell = $tester->{shell};

			# there must be a shell command we should run

			if ($shell)
			{
			    my $produced = `$shell`;

			    $expected = defined $tester->{expected} ? $tester->{expected} : '';

#			    if ($expected)
			    {
#				$expected = quotemeta $tester->{expected};

				if (($produced eq ''
				     and $expected ne '')
				    or ($produced ne ''
					and $expected eq ''))
				{
				    $error = "external tester produces output that is different from what is expected, one is empty, the other is not";

				    $before_match = $produced;
				}
				elsif ($produced =~ /$expected/)
				{
				}
				else
				{
				    $error = "external tester produces output that is different from what is expected";

				    $before_match = $produced;
				}
			    }
# 			    else
# 			    {
# 				die "$0: *** Error: external testers must have expected output";
# 			    }
			}
			else
			{
			    die "$0: *** Error: external testers must have a shell command";
			}
		    }

		    # read

		    elsif (defined $read)
		    {
			# substitute variables

			$read = substitute_variables($read);

			# if literal text expected

			if (!ref $read)
			{
			    if (exists $command_test->{white_space})
			    {
				if ($command_test->{white_space} eq 'convert seen 0a to 0d 0a newlines')
				{
				    print "*** Converting seen 0a to 0d 0a newlines\n";

				    $read =~ s(\x0a)(\x0d\x0a)g;
				}
			    }

			    ($matched_pattern_position,
			     $error,
			     $successfully_matching_string,
			     $before_match,
			     $after_match)
				= $exp->expect($timeout, $read, );

			    $expected = $read;
			}

			# if array, means regex match

			elsif (ref $read eq 'ARRAY')
			{
			    ($matched_pattern_position,
			     $error,
			     $successfully_matching_string,
			     $before_match,
			     $after_match)
				= $exp->expect($timeout, @$read, );

			    #! skip the expect '-re' flag

			    $expected = $read->[1];
			}

			# else, hash: one of several alternatives expected

			else
			{
			    # compose the alternatives regex

			    if ($read->{alternatives})
			    {
				my $alternatives = $read->{alternatives};

				$expected = '(' . (join '|', map { quotemeta } @$alternatives) . ')';

				# read from the application

				($matched_pattern_position,
				 $error,
				 $successfully_matching_string,
				 $before_match,
				 $after_match)
				    = $exp->expect($timeout, "-re", $expected, );
			    }

			    # if an application output file is expected

			    elsif ($read->{application_output_file})
			    {
				# read it

				my $application_output_file
				    = $read->{application_output_file};

				my $pwd = `pwd`;

				chomp $pwd;

 				print "*** Application output file: $application_output_file (in $pwd)\n";

				# and compare it with an expected output file

				my $expected_output_file
				    = $read->{expected_output_file};

				local $/;

				my $application_output = `cat "$application_output_file"`;

				my $expected_output;

				if ($expected_output_file)
				{
				    print "*** Expected output file: $expected_output_file\n";

				    $expected_output = `cat "$expected_output_file"`;
				}
				elsif (defined $read->{expected_output})
				{
				    $expected_output = $read->{expected_output};
				}

				$expected = $expected_output;

				if ($expected_output eq $application_output)
				{
				    $before_match = $application_output;
				}
				else
				{
				    $before_match = $application_output;

				    $read = $expected_output;

				    $error = 'expected_output does not match application_output';
				}
			    }

			    # if there is a shell command given

			    elsif ($read->{shell})
			    {
				# run it

				my $shell = $read->{shell};

				my $expected = `$shell`;

				# and compare its output with the output of the application

				($matched_pattern_position,
				 $error,
				 $successfully_matching_string,
				 $before_match,
				 $after_match)
				    = $exp->expect($timeout, $expected, );

			    }
			    else
			    {
				die "test not understood by $0, aborting (illegal read clause for $description)";
			    }
			}

			$time_elapsed = tv_interval($time_start);

			# fill in the elapsed time in the report

			if ($option_timings)
			{
			    $test_report->{timings}->{$module_name}->{$description} = $time_elapsed;
			}

			# if things don't match

			if ($error)
			{
			    # if allowed to compare numerically

			    if ((!$command_test->{string_only}
				 && $option_numerical_compare)

				# or forced to compare numerically

				|| $command_test->{numerical_compare}
				|| $command_definition->{numerical_compare}
				|| $module_definition->{numerical_compare})
			    {
				# compare numerically

				push @{$test_report->{numerical_compare}}, $command_test->{description};

				$error
				    = Neurospaces::Tester::Comparators::numerical
					(
					 {
					  description => $command_test->{description},
					 },
					 $before_match,
					 $read,
					 $error);
			    }
			}
		    }
		}

		# process errors

		if ($error)
		{
		    my $description = $command_test->{description};

		    my $command_definition_description = $command_definition->{description};

		    my $message;

		    if ($option_verbose)
		    {
			$message = $before_match;
		    }

 		    report_error_add
			(
			 {
			  description => $description,
			  error => $error,
			  expected => $expected,
			  message => $message,
			  module_name => $module_name,
			  seen => $before_match,
			  subdescription => $command_definition_description,
			 },
			);

		}

		# register if this command had side effects

		$previous_command_side_effects ||= $command_test->{side_effects} || 0;

		# increment total test count

		$test_report->{global}->{test_count}++;
	    }

	    # repair the command test environment

	    general_reparation($module_definition, $command_definition, $preparation_result);

	    if (@$command_definitions > 1)
	    {
		report_message(1, 2, "End for tests of $description
Total of $test_report->{global}->{test_count} tests (encountered $error_count error(s) so far)");
	    }

	    # register if this command had side effects

	    #! e.g. using a preparer/reparer combination

	    $previous_command_side_effects ||= $command_definition->{side_effects} || 0;
	}

	# repair the test environment

	general_reparation($module_definition, undef, $module_preparation_result);

	# if library checksum mismatch

	if (defined ($config->{model_library}))
	{
	    my $library_sha_after = model_library_sha();

	    if ($library_sha_after ne $library_sha_before)
	    {
		my $error = 'model library checksum mismatch (model library has changed)';

		my $description = $module_definition->{description};

		report_error_add
		    (
		     {
		      description => $description,
		      error => $error,
		      module_name => $module_name,
		     },
		    );
	    }
	}

	# register if this command had side effects

	#! don't think this make sense, but anyway ...

	$previous_command_side_effects ||= $module_definition->{side_effects} || 0;

	if (not $option_show)
	{
	    report_message(1, 2, "End of tests of module $module_definition->{description}
Total of $test_report->{global}->{test_count} tests (encountered $error_count error(s) so far)");
	}
    }

    # if there is a command running

    if ($global_exp)
    {
	# terminate the command

	#t could be that the hard_close() call is needed because
	#t neurospaces uses readline, not sure needs investigation,
	#t perhaps.

	$global_exp->hard_close();
    }

    $test_report->{global}->{status} = 'Finished';

    report_exit(0);
}


sub parse_options
{
    my $result
	= GetOptions
	    (
	     "email" => \$option_email,
	     "flattenout" => \$option_flattenout,
	     "help!" => \$option_help,
	     "numerical-compare!" => \$option_numerical_compare,
	     "randomize-order=s" => \$option_random_order,
	     "regex-selector=s" => \$option_regex_selector,
	     "report-disabled!" => \$option_report_disabled,
	     "report-mac!" => \$option_report_mac,
	     "report-target!" => \$option_report_target,
	     "show!" => \$option_show,
	     "timeout-multiplier=s" => \$option_timeout_multiplier,
	     "timings!" => \$option_timings,
	     "trace!" => \$option_trace,
	     "v|verbose+" => \$option_verbose,
	    );

    if (!$result)
    {
	die "$0: Error in option processing";
    }

    $test_report->{options}
	= {
	   email => $option_email,
	   flattenout => $option_flattenout,
	   help => $option_help,
	   numerical_compare => $option_numerical_compare,
	   random_order => $option_random_order,
	   regex_selector => $option_regex_selector,
	   report_disabled => $option_report_disabled,
	   report_target => $option_report_target,
	   show => $option_show,
	   timeout_multiplier => $option_timeout_multiplier,
	   timings => $option_timings,
	   trace => $option_trace,
	   verbose => $option_verbose,
	  };

    if ($option_help)
    {
	print
	    "
$0: test definition executor

options:
    --email              allow to send emails, the default is taken from \$ENV{NEUROSPACES_HARNESS_OPTION_EMAIL}.
    --flattenout         flattenout the test definitions before testing,
                         this experimental feature might increase test performance,
                         by recycling test definitions.
    --help               print usage information.
    --numerical-compare  attempt to compare numbers numerically when string differences are found (default enabled).
    --randomize-order    randomize the order of the tests before executing them (require List::Util to be installed).
    --regex-selector     defines a regex to run specific tests.
    --report-disabled    include information of disabled tests in the test report.
    --report-mac         include information of disabled tests on Mac OSX.
    --show               show tests that would be run using the current configuration.
    --timeout-multiplier multiply all timeout values with this constant.
    --timings            add timing information about the tests to the report.
    --trace              enable tracing using the strace unix shell command.
    --verbose            set verbosity level.
";

	exit 1;
    }

}


sub report_error_add
{
    my $arguments = shift;

    my $description = $arguments->{description};
    my $error = $arguments->{error};
    my $expected = $arguments->{expected};
    my $message = $arguments->{message};
    my $module_name = $arguments->{module_name};
    my $seen = $arguments->{seen};
    my $subdescription = $arguments->{subdescription};

    my $package_name = $test_report->{description}->{package}->{name};

    $error_count++;

    print STDERR "*** Error $error_count: $error ($description, package $package_name, $module_name, error_count $error_count)\n";

    # fill in the error report

    $test_report->{global}->{error_count} = $error_count;

    if ($subdescription)
    {
	$test_report->{errors}->{modules}->{$module_name}->{$error_count}->{$subdescription}->{description} = $description;
    }
    else
    {
	$test_report->{errors}->{modules}->{$module_name}->{$error_count}->{description} = $description;
    }

    $test_report->{errors}->{modules}->{$module_name}->{$error_count}->{error} = $error;

    if (defined $message)
    {
	#! subdescription can be undefined here, in which case
	#! $message is undefined too.  Both can be defined when
	#! running in verbose mode seems, allows to track regex
	#! problems ... I think.

	$test_report->{errors}->{modules}->{$module_name}->{$error_count}->{$subdescription}->{report} = $message;
    }

    if (defined $expected
	and defined $seen)
    {
	my $processed_expected = [ split "\n", $expected, ];

	$processed_expected = join "\n*** Error $error_count: expected: ", "", @$processed_expected, "\n";

	print STDERR $processed_expected;

	my $processed_seen = [ split "\n", $seen, ];

	$processed_seen = join "\n*** Error $error_count: seen: ", "", @$processed_seen, "\n";

	print STDERR $processed_seen;

	use IO::File;

	my $expected_filename = "/tmp/text_$config->{package}->{name}_$error_count.expected";

	my $expected_file = IO::File->new(">$expected_filename");

	if ($expected_file)
	{
	    print $expected_file $expected;

	    $expected_file->close();
	}
	else
	{
	    print STDERR "*** Warning: cannot open $expected_filename for writing\n";
	}

	my $seen_filename = "/tmp/text_$config->{package}->{name}_$error_count.seen";

	my $seen_file = IO::File->new(">$seen_filename");

	if ($seen_filename)
	{
	    print $seen_file $seen;

	    $seen_file->close();
	}
	else
	{
	    print STDERR "*** Warning: cannot open $seen_filename for writing\n";
	}

	my $diff = `diff "$expected_filename" "$seen_filename"`;

	my $diff_filename = "/tmp/text_$config->{package}->{name}_$error_count.diff";

	my $diff_file = IO::File->new(">$diff_filename");

	if ($diff_file)
	{
	    print $diff_file $diff;

	    $diff_file->close();
	}
	else
	{
	    print STDERR "*** Warning: cannot open $diff_filename for writing\n";
	}

	my $processed_diff = [ split "\n", $diff, ];

	$processed_diff = join "\n*** Error $error_count: diff: ", "", @$processed_diff, "\n";

	print STDERR $processed_diff;

    }

}


sub report_exit
{
    my $exit_code = shift;

    my $description = shift;

    $test_report->{global}->{time_end} = `date`;

    if (defined $description
        && $exit_code eq 3)
    {
	print "*** die: $description\n";
    }

    my $report_target = $option_report_target || $error_count;

    # yaml out the test report

    my $report_text
	= "\n"
	    . Dump(
		   {
		    description => $test_report->{description},
		    ($option_report_disabled ? (disabled => $test_report->{disabled}) : ()),
# 		    ($option_report_mac ? (mac_report => $test_report->{mac_report}) : ()),
		    ($option_show ? () : (errors => $test_report->{errors})),
		    ($option_show ? () : (global => $test_report->{global})),
		    ($report_target ? (target => $test_report->{target}) : ()),
		    ($option_show ? (selected => $test_report->{selected}) : ()),
		   },
		  );

    print($report_text);

    # and write the full report to a file

    my $report_filename = ">/tmp/report_$config->{package}->{name}.yml";

    eval
    {
	YAML::DumpFile($report_filename, $test_report);
    };

    if ($@)
    {
	print STDERR "*** Error: Failed to write output report to $report_filename\n";
    }

    # if email enabled by the options

    if ($option_email)
    {
	# check for a default route

	#! from perl/basic.t

	my $no_default_route = (`/sbin/route` =~ /default/ ? '' : 'no default route to the internet found');

	if (!$no_default_route)
	{
	    # ask use if sending an email is ok

	    my $default_answer_prompt = $error_count ? "Y/n" : "y/N";

	    print "\n--\n  These tests generated $error_count error(s)";
	    print ( $error_count ? "  Because errors were found, you should really consider sending an email to inform the developer of this software package\n" : "" );
	    print "\n  Ok to send an email to hugo.cornelis\@gmail.com for this test report,\n  this email will not reveal your identity to the recipient ?  [$default_answer_prompt]";

	    my $answer = readline(*STDIN);

	    # send an email if ok

	    if ($answer =~ /^y/)
	    {
		#t perhaps should consider Mail::Builder, don't know

		if ($loaded_mail_sender)
		{
		    my $sender
			= Mail::Sender->new
			    (
			     {
# 			      smtp => 'googlemail.l.google.com',
			      smtp => 'mta1.uthscsa.edu',
			      from => 'hugo.cornelis@gmail.com',
			     },
			    );

		    print
			"Sending ... should not take more than 30 seconds
";

		    my $message
			= (
			   "neurospaces_harness test report\n"
			   . "Generated on " . `date` . "\n"
			   . "\n========\n"
			   . Dump($test_report)
			   . "\n========\n"
			  );

		    $sender->MailMsg
			(
			 {
			  to => 'cornelis@uthscsa.edu',
			  subject => '[neurospaces_harness] test report',
			  msg => $message,
			 },
			);

		    # 	    $sender->Attach
		    # 		(
		    # 		 {
		    # 		  description => 'test_report',
		    # 		 },
		    # 		);

		    $sender->Close();

		    if ($sender->{error})
		    {
			print
			    "*** Error: $sender->{error}
Email was not sent.
";
		    }
		    else
		    {
			print
			    "Email was sent.
";
		    }
		}
		else
		{
		    print
			"*** Error: Cannot load the perl module Mail::Sender, contact your sysadmin to install this perl module.
(use the shell command \"sudo perl -MCPAN -e 'install Mail::Sender'\")
Email was not sent.
";
		}
	    }
	    else
	    {
		print
		    "Email was not sent.
";
	    }
	}
	else
	{
	    print
		"*** Warning: No default route to the internet found.
Email was not sent.
";
	}
    }
    else
    {
	print
	    "No email sent.
";
    }

    # if there were errors

    if ($error_count)
    {
	# exit with failure

	$exit_code ||= 1;

	print "$0: $test_report->{global}->{test_count} test(s), $error_count error(s)\n";

	print "$0: exit_code $exit_code\n\n";

	exit $exit_code;
    }

    # else

    else
    {
	# exit, possibly success

	print "$0: $error_count error(s)\n\n";

	exit $exit_code;
    }
}


sub report_message
{
    my $header = shift;

    my $trailer = shift;

    my $message = shift;

    my $lines = [ split '\n', $message, ];

    my $longest = 0;

    map
    {
	($longest < length) && ($longest = length)
    }
	@$lines;

    my $line = '-' x $longest;

    if (!$option_show)
    {
	print "\n";
	print "$line\n" for 0 .. $header;
	print "\n";
	print "$message\n\n";
	print "$line\n" for 0 .. $trailer;
	print "\n";
    }
}


sub substitute_variables
{
    my $string = shift;

    my $variables
	= [
	   [ '$(libdir)' => "$core_directory/tests/models", ],
	  ];

    foreach my $variable (@$variables)
    {
	my $searcher = quotemeta($variable->[0]);

	$string =~ s/$searcher/$variable->[1]/g;
    }

    return $string;
}


sub test_library_construct
{
    # define the tests

    my $additional_test_modules
	= [
	  ];

    my $program_name = $0;

    $program_name =~ s/.*\///;

    my $library = $0;

    $library =~ s/$program_name$/specifications/;

    my $test_modules
	= [
	   @$additional_test_modules,
	   map
	   {
	       chomp; $_;
	   }
	   sort
	   `find $config->{tests_directory} -name "*.t"`,
	  ];

    return $test_modules;
}


sub test_library_expand
{
    my $library = shift;

    my $result = [];

    # parse all modules

    foreach my $test_module (@$library)
    {
	if ($test_module !~ /$option_regex_selector/i)
	{
	    next;
	}

	my $module_definition = test_library_readfile($test_module);

	if ($module_definition)
	{
	    push @$result, $module_definition;
	}
    }

    if ($option_flattenout)
    {
	# sort modules

	#t first need to transform: select command_definitions, flatten
	#t out, keep the module names (for referencing errors).

	my $transformator
	    = Data::Transformator->new
		(
		 apply_identity_transformation => 0,
		 name => 'test-module-selector',
		 contents => $result,
		 separator => '`',
		 array_filter =>
		 sub
		 {
		     my ($context, $component) = @_;

		     # never filter for the first two component in the path

		     my $depth = $context->{array};
		     $depth = $#$depth;

		     if ($depth < 2)
		     {
			 return 1;
		     }

		     # extract the data: command definitions with test commands

		     $context->{path} =~ m|^[^/]*/([^/]*)/([^/]*)|;

		     my $content = Data::Transformator::_context_get_current_content($context);

		     # push it onto the result

		     my $result = Data::Transformator::_context_get_main_result($context);

		     if (!$result->{content})
		     {
			 $result->{content} = [];
		     }

		     push @{$result->{content}}, $content;

		     # add the module name

		     my $module_name = $context->{array}->[1]->{content}->{name};

		     $content->{module_name} = $module_name;

		     # add the module description

		     my $module_description = $context->{array}->[1]->{content}->{description};

		     $content->{module_description} = $module_description;

		     # result is known, everything gets filtered

		     0;
		 },
		);

	#t for an empty array as content, the transformator returns an
	#t undef, this is a bug that still needs fixing.

	my $tests = $transformator->transform() || [];

	# sort the flattened test definitions

	$tests
	    = [
	       sort
	       {
		   my $module1 = $a;
		   my $module2 = $b;

		   my $command1 = $module1->{command};
		   my $command2 = $module2->{command};

		   my $command1_arguments = $module1->{arguments} || [];
		   my $command2_arguments = $module2->{arguments} || [];

		   my $command1_string = join ' ', $command1, @$command1_arguments;
		   my $command2_string = join ' ', $command2, @$command2_arguments;

		   my $comparison = $command1_string cmp $command2_string;

		   if ($module1->{tester_head})
		   {
		       $comparison = -1;
		   }
		   elsif ($module2->{tester_head})
		   {
		       $comparison = 1;
		   }

		   $comparison;
	       }
	       @$tests,
	      ];

	# transform back to the regular test module format by putting
	# every command definition in its own module

	$tests
	    = [
	       map
	       {
		   my $command_definition = $_;

		   (
		    {
		     command_definitions => [
					     $command_definition,
					    ],
		     description => $command_definition->{module_description},
		     name => $command_definition->{module_name},
		    }
		   );
	       }
	       @$tests,
	      ];

	# set result

	$result = $tests;
    }

    # return result

    return $result;
}


sub test_library_is_yaml
{
    my $filename = shift;

    my $result;

    use IO::File;

    my $fh = IO::File->new();

    if ($fh->open("< $filename"))
    {
	my $first_line = <$fh>;

	$first_line =~ s/(\s)*//g;

	if ($first_line eq '---')
	{
	    $result = 'is_yaml';
	}

	$fh->close;
    }

    return $result;
}


sub test_library_readfile
{
    my $pathname = shift;

    my $result;

    use YAML;

    if (test_library_is_yaml($pathname))
    {
	$result = YAML::LoadFile($pathname);

	if ($@)
	{
	    report_error_add
	    (
	     {
	      description => $@,
	      error => $@,
	      module_name => $pathname,
	     },
	    );
	}
    }
    else
    {
	$result = do $pathname;

	if ($@)
	{
	    report_error_add
	    (
	     {
	      description => $@,
	      error => $@,
	      module_name => $pathname,
	     },
	    );
	}

	$pathname =~ m((.*)/(.*));

	my $filename = $2;

	YAML::DumpFile("/tmp/$filename", $result);
    }

    return $result;
}


sub model_library_sha
{
    # find all models

    use File::Find::Rule;

    my $files = [ File::Find::Rule->file()->in( $ENV{NEUROSPACES_NMC_MODELS} ), ];

    my $shas
	= [
	   map
	   {
	       `sha1sum $_`;
	   }
	   @$files,
	  ];

    use Digest::SHA qw(sha1_hex);

    my $sha = sha1_hex(join ', ', @$shas);

    return $sha;
}


main();


