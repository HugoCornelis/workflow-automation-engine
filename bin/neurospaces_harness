#!/usr/bin/perl -w
#!/usr/bin/perl -d:ptkdb
#

use strict;

my $loaded_mail_sender = eval "require Mail::Sender";

use Data::Transformator;

use Neurospaces::Tester;

use POSIX qw( strftime );

use YAML;


my $option_check_test_names;
my $option_config_filename = './tests.config';
my $option_console_type = 'status';
our $option_debugging;
my $option_dump_json;
my $option_dump_perl;
my $option_dump_yaml;
my $option_dump_file_structured_json;
my $option_dump_file_structured_yaml;
my $option_email = defined $ENV{NEUROSPACES_HARNESS_OPTION_EMAIL} ? $ENV{NEUROSPACES_HARNESS_OPTION_EMAIL} : 0 ;
my $option_flattenout;
my $option_harness_prune;
my $option_help;
my $option_input_command_tests = [];
my $option_input_commands= [];
my $option_input_modules = [];
my $option_numerical_compare;
my $option_output;
my $option_output_content_line_limit = 10;
my $option_output_figures;
my $option_output_html;
my $option_output_latex;
my $option_output_levels = [];
my $option_output_pdf;

# the following option is not yet available from the command line interface

my $option_output_table_of_contents = 'yes';

# the following option is not yet available from the command line interface

my $option_output_title_page = '';

my $option_random_order;
my $option_regex_selector = ".*";
my $option_report_disabled;
my $option_show;
my $option_show_command_tests;
my $option_tags = [];
my $option_timeout_multiplier = 1;
my $option_timings = 1;
my $option_trace;
our $option_verbose;


our $global_config;

my $global_all_output_levels
    = [
       "meta",
       "module",
       "command_definition",
       "command_test",
      ];

my $global_reporter_classes
    = {
       'linear' => {
		    class => "Heterarch::Test::Reporting::Linear",
		   },
       'status' => {
		    class => "Heterarch::Test::Reporting::Status",
		   },
      };

my $global_command_line_configuration
    = {
       application => {
		       initialize_configuration_and_environment => "main::application_initialize_configuration_and_environment",
		       synopsis => "
$0: test definition processor and executor

synopsis:

$0 <command> <options>

",
		       usage => "
options:
    --check-test-names           Check the pathnames of the specification files against the names of the tests.
    --config-filename            The name of the file with the configuration (default is: $option_config_filename).
    --console-type               The type of the console output (one of " . (join ", ", sort keys %$global_reporter_classes) . ").
    --debugging                  Enable specific debugging options.
    --dump-json                  Dump test specifications to json files in /tmp/.
    --dump-perl                  Dump test specifications to perl files in /tmp/.
    --dump-yaml                  Dump test specifications to yaml files in /tmp/.
    --dump-file-structured-yaml  Dump test specifications to well structured yaml files and directories in /tmp/.
    --email                      Allow to send emails, the default is taken from \$ENV{NEUROSPACES_HARNESS_OPTION_EMAIL}.
    --flattenout                 Flattenout the test definitions before testing,
                                 this experimental feature might increase test performance,
                                 by recycling test definitions.
    --harness-prune              Remove all the docker containers.
    --help                       Print usage information.
    --input-command-tests        Merge the given file or directory as command tests to be executed (can be given several times).
    --input-commands             Merge the given file or directory as commands to be tested (can be given several times).
    --input-modules              Merge the given file or directory as modules to be tested (can given several times).
    --numerical-compare          Attempt to compare numbers numerically when string differences are found (default enabled).
    --output                     The class that should generate the output.
    --output-content-line-limit  Maximum number of lines when generating content output (latex, html, pdf).
    --output-figures             Generate figures for test output with a figure clause.
    --output-html                Generate HTML output.
    --output-latex               Generate Latex output.
    --output-levels              Generate output for these levels (default is '" . ( join ', ', @$global_all_output_levels ) . "'.
    --output-pdf                 Generate PDF output.
    --randomize-order            Randomize the order of the tests before executing them (require List::Util to be installed).
    --regex-selector             Defines a regex to run specific tests.
    --report-disabled            Include information of disabled tests in the test report.
    --show                       Show tests that would be run using the current configuration.
    --show-command-tests         Show all the command definitions that would be run during test execution, including the input to those commands.
    --tags                       Only test test modules that have been tagged with these tags (default: all tags).
    --timeout-multiplier         Multiply all timeout values with this constant.
    --timings                    Add timing information about the tests to the report.
    --trace                      Enable tracing using the given unix shell command (eg. 'strace -f', 'retsnoop', 'RRLOG=/tmp/rr.log rr record' or syzbot/syzkaller, https://hackerbikepacker.com/syzbot).
    --verbose                    Set verbosity level.
",
		      },
       command_configuration => {
				 default_command => "run-tests",
				 known_commands => {
						    "configuration-create" => {
									       description => "Create an initial test configuration with instructions how to expand it to a full test suite.",
									       executor => "main::harness_command_configuration_create",
									       help => {
											synopsis => "$0 configuration-create <options> <package-name> <package-version> [ <test-module-name> ]",
											usage => "Options:
    --help         Show this help message.
    --output-json  Output the configuration in json format.
    --output-yaml  Output the configuration in yaml format.
",
										       },
									       options => {
											   "help!" => do { my $option_help; \$option_help; },
											   "output-json!" => do { my $option_output_json; \$option_output_json; },
											   "output-yaml!" => do { my $option_output_yaml; \$option_output_yaml; },
											  },
									       skip_configuration => 'a command that creates a configuration cannot require a configuration',
									      },
						    "help" => "Show the help page.",
						    "command-add" => {
								      description => "Add a new command with the given name under the given module and try to insert its current output as the expected output.",
								      executor => "main::harness_command_module_command_add",
								      help => {
									       synopsis => "$0 command-add <options> <module-name> <command-name> <'command-test-description'>",
									       usage => "Options:
    --command-output The command that produces correct output on STDOUT, if no command-output is given the tested command is used.
    --comment        The comment to insert.  The comment is inserted both at command definition level and at command test level.
    --description    The description to insert.  The description is inserted both at command definition level and at command test level.
    --help           Show this help message.
    --output-json    Output in json format.
    --output-yaml    Output in yaml format.
",
									      },
								      options => {
										  "command-output=s" => do { my $option_command_output; \$option_command_output; },
										  "comment=s" => do { my $option_comment; \$option_comment; },
										  "help!" => do { my $option_help; \$option_help; },
										  "output-json!" => do { my $option_output_json; \$option_output_json; },
										  "output-yaml!" => do { my $option_output_yaml; \$option_output_yaml; },
										 },
								     },
						    "module-create" => {
									description => "Create a new module with the given name.",
									executor => "main::harness_command_module_create",
									help => {
										 synopsis => "$0 module-create <options> <module-name>",
										 usage => "Options:
    --help         Show this help message.
    --output-json  Output the new module in json format.
    --output-yaml  Output the new module in yaml format.
",
										},
									options => {
										    "help!" => do { my $option_help; \$option_help; },
										    "output-json!" => do { my $option_output_json; \$option_output_json; },
										    "output-yaml!" => do { my $option_output_yaml; \$option_output_yaml; },
										   },
								       },
						    "module-update" => {
									description => "Update the given module with the given arguments and directives.",
									executor => "main::harness_command_module_update",
									help => {
										 synopsis => "$0 module-update <options> <module-name>",
										 usage => "This command reads the (existing) test module with the given name and the reproduces it as file-structured yaml.

Options:
    --help         Show this help message.
    --output-json  Update the new module in json format.
    --output-yaml  Update the new module in yaml format.
",
										},
									options => {
										    "help!" => do { my $option_help; \$option_help; },
										    "output-json!" => do { my $option_output_json; \$option_output_json; },
										    "output-yaml!" => do { my $option_output_yaml; \$option_output_yaml; },
										   },
									subcommands => [],
								       },
						    # "query" => "Query the tests, print the query result.",
						    "run-tests" => {
								    description => "Run the tests, possibly with an executor that converts the tests rather than running them.",
								    executor => "main::harness_command_run_tests",
								    help => {
									     usage => "Please use the 'help' command to see the help page of the 'run-tests' command.\n",
									    },
								    options => {
										"help!" => do { my $option_help; \$option_help; },
									       },
								   },
						   },
				},
       option_configuration => {
				options => {
					    "check-test-names!" => \$option_check_test_names,
					    "config-filename=s" => \$option_config_filename,
					    "console-type=s" => \$option_console_type,
					    "debugging=s" => \$option_debugging,
					    "dump-json!" => \$option_dump_json,
					    "dump-perl!" => \$option_dump_perl,
					    "dump-yaml!" => \$option_dump_yaml,
					    "dump-file-structured-json!" => \$option_dump_file_structured_json,
					    "dump-file-structured-yaml!" => \$option_dump_file_structured_yaml,
					    "email" => \$option_email,
					    "flattenout" => \$option_flattenout,
					    "harness-prune!" => \$option_harness_prune,
					    "help!" => \$option_help,
					    "input-command-tests=s" => $option_input_command_tests,
					    "input-commands=s" => $option_input_commands,
					    "input-modules=s" => $option_input_modules,
					    "numerical-compare!" => \$option_numerical_compare,
					    "output=s" => \$option_output,
					    "output-content-line-limit=s" => \$option_output_content_line_limit,
					    "output-figures" => \$option_output_figures,
					    "output-html" => \$option_output_html,
					    "output-latex" => \$option_output_latex,
					    "output-levels=s" => $option_output_levels,
					    "output-pdf" => \$option_output_pdf,
					    "randomize-order=s" => \$option_random_order,
					    "regex-selector=s" => \$option_regex_selector,
					    "report-disabled!" => \$option_report_disabled,
					    "show!" => \$option_show,
					    "show-command-tests!" => \$option_show_command_tests,
					    "tags=s" => $option_tags,
					    "timeout-multiplier=s" => \$option_timeout_multiplier,
					    "timings!" => \$option_timings,
					    "trace=s" => \$option_trace,
					    "v|verbose+" => \$option_verbose,
					   },
			       },
      };


my $global_console_window_configuration
    = {
       "progress_bar" => {
			  "formatter" => \&Heterarch::Test::Reporting::ConsoleWindow::progress,
			  "formatter_options" => {
						  "decimals" => 0,
						  "empty" => '-',
						  "fill" => '█',
						  "prefix" => '',
						  "suffix" => 'Complete',
						  "total" => -1,
						 },
			  "length" => 120,
			  "line_number" => 0,
			  "prompt" => "   Progress: ",
			 },
       "message_module" => {
			    "formatter" => \&Heterarch::Test::Reporting::ConsoleWindow::note,
			    "length" => 120,
			    "line_number" => 2,
			    "prompt" => "     Module: ",
			   },
       "message_harnessing" => {
				"formatter" => \&Heterarch::Test::Reporting::ConsoleWindow::note,
				"length" => 120,
				"line_number" => 3,
				"prompt" => "    Harness: ",
			       },
       "message_command" => {
			     "formatter" => \&Heterarch::Test::Reporting::ConsoleWindow::note,
			     "length" => 120,
			     "line_number" => 4,
			     "prompt" => "    Command: ",
			    },
       "message_test" => {
			  "formatter" => \&Heterarch::Test::Reporting::ConsoleWindow::note,
			  "length" => 120,
			  "line_number" => 5,
			  "prompt" => "       Test: ",
			 },
       "message_details" => {
			     "formatter" => \&Heterarch::Test::Reporting::ConsoleWindow::note,
			     "length" => 120,
			     "line_number" => 6,
			     "prompt" => "    Details: ",
			    },
       "message_info" => {
			  "formatter" => \&Heterarch::Test::Reporting::ConsoleWindow::note,
			  "length" => 120,
			  "line_number" => 8,
			  "prompt" => "Information: ",
			 },
       "message_warning" => {
			     "formatter" => \&Heterarch::Test::Reporting::ConsoleWindow::note,
			     "length" => 120,
			     "line_number" => 10,
			     "prompt" => "    Warning: ",
			    },
       "message_error" => {
			   "formatter" => \&Heterarch::Test::Reporting::ConsoleWindow::note,
			   "length" => 120,
			   "line_number" => 11,
			   "prompt" => " Last Error: ",
			  },
       "end" => {
		 "enabled" => "yes",
		 "formatter" => \&Heterarch::Test::Reporting::ConsoleWindow::note,
		 "length" => 120,
		 "line_number" => 12,
		 "prompt" => "   Finished: ",
		},
      };

my $global_console_window_library_configuration
    = {
       "progress_bar" => {
			  "formatter" => \&Heterarch::Test::Reporting::ConsoleWindow::progress,
			  "formatter_options" => {
						  "decimals" => 0,
						  "empty" => '-',
						  "fill" => '█',
						  "prefix" => '',
						  "suffix" => 'Complete',
						  "total" => -1,
						 },
			  "length" => 120,
			  "line_number" => 0,
			  "prompt" => "   Progress: ",
			 },
       "message_info" => {
			  "formatter" => \&Heterarch::Test::Reporting::ConsoleWindow::note,
			  "length" => 120,
			  "line_number" => 1,
			  "prompt" => "Information: ",
			 },
       "message_warning" => {
			     "formatter" => \&Heterarch::Test::Reporting::ConsoleWindow::note,
			     "length" => 120,
			     "line_number" => 2,
			     "prompt" => "    Warning: ",
			    },
       "message_error" => {
			   "formatter" => \&Heterarch::Test::Reporting::ConsoleWindow::note,
			   "length" => 120,
			   "line_number" => 3,
			   "prompt" => "      Error: ",
			  },
       "end" => {
		 "enabled" => "yes",
		 "formatter" => \&Heterarch::Test::Reporting::ConsoleWindow::note,
		 "length" => 120,
		 "line_number" => 4,
		 "prompt" => "   Finished: ",
		},
      };

my $global_configuration_initialized;

my $global_error_count = 0;
our $global_fd_output;
my $global_previous_command_side_effects;
my $global_test_report;


package CommandLineDispatcher;

use Getopt::Long qw(GetOptionsFromArray :config require_order);


sub command_line_dispatch
{
    my $command_line_configuration = shift;

    my $harness_command = shift;

    my $arguments = shift || [];

    my $command_configuration = $command_line_configuration->{command_configuration};

    my $known_commands = $command_configuration->{known_commands};

    if (! exists $known_commands->{$harness_command})
    {
	print "\n$0: *** Error: The command '$harness_command' does not exist.\n";

	exit 1;
    }

    if (!exists $known_commands->{$harness_command}->{options})
    {
	print "\n$0: *** Error: The command '$harness_command' does not have a '--help' option.\n";

	exit 1;
    }

    my $options = $known_commands->{$harness_command}->{options};

    my $option_result = GetOptionsFromArray($arguments, %$options);

    if (! $option_result)
    {
	$options->{"help!"} = 'option processing error';
    }

    my $option_help = $options->{"help!"};

    if ($$option_help)
    {
	if (! exists $known_commands->{$harness_command}->{help})
	{
	    print "\nNo help found for this command '$harness_command'\n";
	}
	else
	{
	    my $description = $known_commands->{$harness_command}->{description};

	    my $help = $known_commands->{$harness_command}->{help};

	    my $synopsis = $help->{synopsis} || "$0 $harness_command <options> <arguments>";

	    my $usage = $help->{usage} || "No usage description found for this command '$harness_command'\n";;

	    print "\n$synopsis\n\n$description\n\n$usage\n";
	}

	exit 0;
    }

    my $harness_command_definition = $command_configuration->{known_commands}->{$harness_command};

    my $harness_command_executor = $harness_command_definition->{executor};

    # obtain a copy of stdout for the reporters

    open($global_fd_output, ">&STDOUT");

    # instantiate the reporter

    my $reporter_class = $global_reporter_classes->{$option_console_type}->{class};

    my $default_reporter
	= $reporter_class->new(
			       {
				configuration => $global_console_window_library_configuration,
				fd_output => $global_fd_output,
			       },
			      );

    {
	no strict "refs";

	my $error = &$harness_command_executor($harness_command_definition, $harness_command, $arguments, $default_reporter);
    }
}


sub command_line_application_initialize
{
    my $command_line_configuration = shift;

    my $command = shift;

    my $arguments = shift;

    my $command_configuration = $command_line_configuration->{command_configuration};

    my $harness_command_definition = $command_configuration->{known_commands}->{$command};

    my $requires_configuration = (!exists $harness_command_definition->{skip_configuration}
				  || !$harness_command_definition->{skip_configuration});

    if ($requires_configuration)
    {
	my $application_initialize_configuration_and_environment = $command_line_configuration->{application}->{initialize_configuration_and_environment};

	no strict "refs";

	&$application_initialize_configuration_and_environment($command_line_configuration, $command);
    }
}


sub parse_command
{
    my $command_line_configuration = shift;

    my $arguments = shift;

    my $command_configuration = $command_line_configuration->{command_configuration};

    my $command_result = shift @$arguments || $command_configuration->{default_command};

    my $known_commands = $command_configuration->{known_commands};

    if (not exists $known_commands->{$command_result})
    {
	$command_result = "help";
    }

    return $command_result;
}


sub parse_command_line
{
    my $command_line_configuration = shift;

    my $arguments = shift;

    my $option_result = parse_options($command_line_configuration, $arguments);

    my $command_result = parse_command($command_line_configuration, $arguments);

    if ($option_result eq 'help'
	or $command_result eq 'help')
    {
	my $command_configuration = $command_line_configuration->{command_configuration};

	my $command_descriptions = "The default command is '$command_configuration->{default_command}'.

commands:
";

	my $known_commands = $command_configuration->{known_commands};

	foreach my $known_command (sort keys %$known_commands)
	{
	    my $command_help = $known_commands->{$known_command};

	    if (ref $command_help)
	    {
		$command_help = $command_help->{description};
	    }

	    my $command_description = sprintf("    %-21s%-20s\n", $known_command, $command_help);

	    $command_descriptions .= $command_description;
	}

	my $synopsis = $command_line_configuration->{application}->{synopsis};

	my $usage = $command_line_configuration->{application}->{usage};

	print "$synopsis$command_descriptions$usage";

	exit 0;
    }

    return $command_result;
}


sub parse_options
{
    my $command_line_configuration = shift;

    my $arguments = shift;

    my $options = $command_line_configuration->{option_configuration}->{options};

    my $result = GetOptionsFromArray($arguments, %$options);

    if (!$result)
    {
	die "$0: Error in option processing";
    }

    if (not exists $Heterarch::Test::Reporting::console_types->{$option_console_type})
    {
	die "$0: *** Error --console-type should specify one of " . (join ", ", sort keys %$Heterarch::Test::Reporting::console_types) . ".";
    }

    if (not defined $option_output)
    {
	if ($option_output_html)
	{
	    $global_test_report->{output_format} = 'yaml_exit';

	    $option_output = "Heterarch::Test::Output::Formatter::HTMLTable";
	}
	elsif ($option_output_latex)
	{
	    $global_test_report->{output_format} = 'latex';

	    $option_output = "Heterarch::Test::Output::Formatter::Latex";
	}
	elsif ($option_output_pdf)
	{
	    $global_test_report->{output_format} = 'pdf';

	    $option_output = "Heterarch::Test::Output::Formatter::PDF";
	}
	elsif ($option_show)
	{
	    $global_test_report->{output_format} = 'yaml_exit';

	    $option_output = "Heterarch::Test::Output::Formatter::YAML::Summary";
	}
	elsif ($option_show_command_tests)
	{
	    $global_test_report->{output_format} = 'yaml_exit';

	    $option_output = "Heterarch::Test::Output::Formatter::YAML::CommandTests";
	}
	else
	{
	    $global_test_report->{output_format} = 'executor';

	    $option_output = "Heterarch::Test::Executor";
	}
    }
    else
    {
	$global_test_report->{output_format} = 'not_executor';
    }

    if ($option_output ne "Heterarch::Test::Executor")
    {
	$option_console_type = 'linear';
    }

    if (not scalar @$option_output_levels)
    {
	use Clone 'clone';

	$option_output_levels = clone($global_all_output_levels);
    }

    $global_test_report->{options}
	= {
	   check_test_names => $option_check_test_names,
	   config_filename => $option_config_filename,
	   console_type => $option_console_type,
	   debugging => $option_debugging,
	   dump_json => $option_dump_json,
	   dump_perl => $option_dump_perl,
	   dump_yaml => $option_dump_yaml,
	   dump_file_structured_json => $option_dump_file_structured_json,
	   dump_file_structured_yaml => $option_dump_file_structured_yaml,
	   email => $option_email,
	   flattenout => $option_flattenout,
	   harness_prune => $option_harness_prune,
	   help => $option_help,
	   input_commands => $option_input_commands,
	   input_modules => $option_input_modules,
	   input_command_tests => $option_input_command_tests,
	   numerical_compare => $option_numerical_compare,
	   output => $option_output,
	   output_figures => $option_output_figures,
	   output_html => $option_output_html,
	   output_latex => $option_output_latex,
	   output_levels => $option_output_levels,
	   output_pdf => $option_output_pdf,
	   random_order => $option_random_order,
	   regex_selector => $option_regex_selector,
	   report_disabled => $option_report_disabled,
	   show => $option_show,
	   show_command_tests => $option_show_command_tests,
	   tags => $option_tags,
	   timeout_multiplier => $option_timeout_multiplier,
	   timings => $option_timings,
	   trace => $option_trace,
	   verbose => $option_verbose,
	  };

    my $option_result = '';

    if ($option_help)
    {
	$option_result = 'help';
    }

    return $option_result;
}


package main;


sub harness_command_configuration_create
{
    my $harness_command_definition = shift;

    my $command = shift;

    my $arguments = shift || [];

    my $reporter = shift;

    my $package_name = shift @$arguments;

    my $package_version = shift @$arguments || 'alpha';

    my $test_module_name = shift @$arguments || '000_module_template';

    if (! defined $package_name)
    {
	die "$0: *** Error: $command expects an argument for the name of the new package/project";
    }

    my $test_configuration_template
	= "
#!/usr/bin/perl -w
#!/usr/bin/perl -d:ptkdb
#

use strict;


# \$Format: \"my \$package_name = \\\"\${package}\\\";\"\$
my \$package_name = \"$package_name\";

# \$Format: \"my \$package_version = \\\"\${label}\\\";\"\$
my \$package_version = \"$package_version\";


my \$config
    = {
       core_directory => './',
       description => '$package_name function, unit, regression and inter-active tests, that partially document $package_name functionality.',
       environment_settings => {
				MY_PROJECT_SPECIFIC_VARIABLE => 'MY_PROJECT_SPECIFIC_VARIABLE_VALUE',
			       },
       html_output_directory => './tests/html',
       package => {
		   name => \$package_name,
		   version => \$package_version,
		  }
      };


return \$config;


";

    my $error = '';

    if (!-e 'tests.config')
    {
	# create the test configuration

	use IO::File;

	my $file = IO::File->new("> tests.config");

	if (defined $file)
	{
	    print $file $test_configuration_template;

	    $file->close();

	    chmod 0700, "tests.config";

	    print "$0: Created a template test configuration in ./tests.config.\n";
	}
	else
	{
	    $error = "Cannot create a template test configuration in ./tests.config.";
	}
    }
    else
    {
	$error = "There is a test configuration in ./tests.config, aborting.";
    }

    # create the folders for the test specifications

    if (!$error)
    {
	if (!mkdir 'tests')
	{
	    $error = "Cannot create the 'tests' directory (error number $!).";
	}
    }

    if (!$error)
    {
	if (!mkdir 'tests/specifications')
	{
	    $error = "Cannot create the 'tests/specifications' directory (error number $!).";
	}
    }

    # create a first test module definition

    if (!$error)
    {
	$error = harness_command_module_create("harness_command_module_create", $arguments, $reporter, $test_module_name);
    }

    if ($error)
    {
	print "$0: *** Error: $error\n";
    }

    # return the error if there is one

    return $error;
}


my $global_command_definition_template
    = {
       comment => "This type of comment element can be inserted at any level in the YAML files that define tests.

For a concise example, see the second command definition that was generated with this one.

The tests are defined with arrays of command definitions that each can have an array of command tests.

Recognized key words at the level of the command definitions are (in alphabetical order):

class: The name of a perl class that will execute the tests.
command: The command the must be tested, with space seperated arguments and options.
command_tests: An array of the tests executed against the command.
disable: Gives the reason why this test command is disabled.
description: A single line description of all the tests for the given command.
error: Gives the reason why this test command will always fail.
numerical_compare: Allow small arithmetic differences during the comparison of the expected result with the produced result.
tag: An array of tags associated with this command.  These are matched with the tags given on the command line.

",
       command => "# <the command with its single space seperated arguments to be tested>",
       command_tests => [
			 {
			  comment => "This type of comment element can be inserted at any level in the YAML files that define tests.

The command tests defines an array of tests that must be executed against the command.

Possible keywords are:

application_output_file: The pathname of a file that will be produced by the test.
description: A single line description: of the executed test.
disable: Gives the reason why this command test is disabled.
error: Gives the reason why this command test will always fail.
expected_output_file: The pathname of a file with the contents that is expected.
read: The expected output on STDOUT of the command.  This can be a regular expression (take a look at the examples).
tag: An array of tags associated with this command test.  These are matched with the tags given on the command line.
tester: A shell command that will be run after the command has produced output (likely to be combined with a wait keyword for reliability and reproducibility).
timeout: An optional timeout after which the test will fail if the expected output is not seen yet.
wait: An optional number of seconds to wait before attempting to read from STDIN of the command.
white_space: If this has the value 'convert seen 0a to 0d 0a newlines', that is what it will do.  This is used when running the tests inside a Docker container.
write: An optional string to write to STDIN of the command, where the command is then expected to produce the expected output.


Note that more keywords have been defined, including for running C and perl code.  They are currently not documented.

",
			  description => "<a single line description of the specific test, it can be a question that asks what is tested>",
			  read => "<the output that is expected from running the test>",
			 },
			 {
			  description => "<a single line description of the specific test, it can be a question that asks what is tested>",
			  read => "<a string that is expected from running the test after writing to STDOUT what is specified with the 'write' keyword>",
			  write => "<a string that must be written to STDIN>",
			 },
			],
       description => "<a single line description of the command being tested>",
      };


sub harness_command_module_command_add
{
    my $harness_command_definition = shift;

    my $command = shift;

    my $arguments = shift || [];

    my $reporter = shift;

    my $module_name = shift || shift @$arguments;

    my $command_to_be_tested = shift || shift @$arguments;

    my $description = shift || shift @$arguments;

    if (! defined $module_name)
    {
	die "$0: *** Error: $command expects an argument for the name of the existing module to which the command to be tested should be added.";
    }

    if (! defined $command_to_be_tested)
    {
	die "$0: *** Error: $command expects an argument for the command to be tested.";
    }

    if (! defined $description)
    {
	die "$0: *** Error: $command expects an argument for the description of the command to be tested.";
    }

    my $options = $harness_command_definition->{options};

    my $option_comment = $options->{"comment=s"};

    my $comment;

    if (defined $$option_comment)
    {
	$comment = $$option_comment;
    }

    use Clone 'clone';

    my $tests_directory = $global_config->{tests_directory};

    my $module_path_name = "$tests_directory/$module_name";

    if (-r $module_path_name)
    {
    }
    else
    {
	die "$0: *** Error: $module_path_name not found.";
    }

    my $module_definition = Heterarch::Test::Library::module_read($reporter, "$module_path_name/summary.yml");

    if (!$module_definition)
    {
	die "$0: *** Error: $module_path_name does not have a valid test module definition..";
    }

    my $command_definition = clone($global_command_definition_template);

    $command_definition->{command} = $command_to_be_tested;

    $command_definition->{description} = $description;

    my $output = `$command_to_be_tested`;

    $command_definition->{command_tests} = [];

    my $command_tests = $command_definition->{command_tests};

    my $command_test
	= {
	   defined $comment ? (comment => $comment) : (),
	   description => $description,
	   read => $output,
	  };

    push @$command_tests, $command_test;

    # my $command_definitions = $module_definition->{command_definitions};

    # push @$command_definitions, $command_definition;

    my $directory = "$module_path_name/command_definitions";

    my $prefix = Heterarch::Test::Library::directory_next_filename_prefix($directory);

    my $error;

    my $command_definition_filename;

    if (defined $prefix)
    {
	my $file_type = 'yaml';

	$command_definition_filename = $prefix . "_" . Heterarch::Test::Library::sentence_summarize($description) . ($file_type eq 'yaml' ? ".yml" : ".json");

	my $result = Heterarch::Test::Library::command_definition_dump_file_structured_yaml($command_definition, "$directory/$command_definition_filename", $file_type);

	# my $result = Heterarch::Test::Library::module_definition_dump_file_structured_yaml($module_name, $module_definition, $tests_directory, $reporter, 'yaml');

	if ($result =~ /error/i)
	{
	    $error = "Error adding the command to the test module $module_name ($result).";
	}
    }
    else
    {
	$error = "Error: directory_next_filename_prefix does not return a prefix (does the directory $directory exist?).";
    }

    if ($error)
    {
	print "$0: *** Error: $error\n";
    }
    else
    {
	print "$0: Added a test with filename $command_definition_filename for this command to the test module $module_name.\n";
    }

    # return the error if there is one

    return $error;
}


sub harness_command_module_create
{
    my $harness_command_definition = shift;

    my $command = shift;

    my $arguments = shift || [];

    my $reporter = shift;

    my $module_name = shift || shift @$arguments;

    if (! defined $module_name)
    {
	die "$0: *** Error: $command expects an argument for the name of the new module";
    }

    my $summary
	= {
	   comment => "This type of comment element can be inserted at any level in the YAML files that define tests.

The top level summary file of a test module gives general information about the module without specifying any tests.

Recognized key words are (in alphabetical order):

description: Gives a general description of the test module.
disable: Gives the reason why this test module is disabled.
documentation: Has keywords with information for inclusion in documents.  They are not considered druing tests.
error: Gives the reason why this test module will always fail.
harnessing: A harnessing key word defines the container that is used to run the commands to be tested.

In most cases the harnessing keyword has one subkeyword 'class' that defines:

    docker: Properties of the Docker image and container.
    identifier: An internal Docker container identifier.
    type: The internal type of the code that is used to manage the container, most commonly 'Heterarch::Test::ExecutionContext::Harness::Docker'.

The 'docker' keyword defines:

    default_user: The name of the user inside the container running the tests.
    dockerfile: A relative pathname to the Dockerfile that defines the docker image.
    name_container: The public name of the Docker container.
    name_image: The public name of the Docker image that is used to instantiate the container.

name: The name of the module, this must match with the pathname of the module.  It is used for error reporting.
numerical_compare: Allow small arithmetic differences during the comparison of the expected result with the produced result.
tag: An array of tags associated with this test module.  These are matched with the tags given on the command line.

",
	   description => "<description of your module>",
	   documentation => {
			     explanation => "<a few sentences that explain the purpose of the program being tested>",
			     purpose => "<a single line description of the purpose of this test module>",
			    },
	   name => "<the full pathname of this test module, relative to the test specifications directory>",
	  };

    use Clone 'clone';

    my $command_definition1 = clone($global_command_definition_template);

    my $command_definition2
	= {
	   command => "# <the command with its single space seperated arguments to be tested>",
	   command_tests => [
			     {
			      description => "<a single line description of the specific test, it can be a question that asks what is tested>",
			      read => "<the output that is expected from running the test>",
			     },
			     {
			      description => "<a single line description of the specific test, it can be a question that asks what is tested>",
			      read => "<a string that is expected from running the test after writing to STDOUT what is specified with the 'write' keyword>",
			      timeout => "<the number of seconds to wait before failing the test>",
			      wait => "<the number of seconds to wait before attempting to read from STDIN>",
			      write => "<a string that must be written to STDIN>",
			     },
			    ],
	   description => "<a single line description of the command being tested>",
	  };

    $summary->{command_definitions} = [ $command_definition1, $command_definition2, ];

    my $path_prefix = $global_config->{tests_directory} || "tests/specifications";

    my $result = Heterarch::Test::Library::module_definition_dump_file_structured_yaml($module_name, $summary, $path_prefix, $reporter, 'yaml');

    my $error;

    if ($result =~ /error/i)
    {
	$error = "Error creating test module $module_name in $path_prefix ($result).";
    }

    if ($error)
    {
	print "$0: *** Error: $error\n";
    }
    else
    {
	print "$0: Created test module $module_name in $path_prefix.\n";
    }

    # return the error if there is one

    return $error;
}


sub harness_command_module_update
{
    my $harness_command_definition = shift;

    my $command = shift;

    my $arguments = shift || [];

    my $reporter = shift;

    my $module_name = shift @$arguments;

    if (! defined $module_name)
    {
	die "$0: *** Error: $command expects an argument for the name of the module to be updated";
    }

    # find the test module that must be updated

    my $tests_directory = $global_config->{tests_directory};

    my $module_path_name = "$tests_directory/$module_name/summary.yml";

    if (-r $module_path_name)
    {
    }
    else
    {
	die "$0: *** Error: $module_path_name not found.";
    }

    my $module_definition = Heterarch::Test::Library::module_read($reporter, $module_path_name);

    my $module_definitions = [ $module_definition, ];

    #t command_definition 0, command_test 0, read clause.

    # we don't care about a possible model library

    my $model_library_shas = {};

    # if (defined ($global_config->{external_model_libraries}))
    # {
    # 	$model_library_shas = ModelLibrary::shas($global_config->{external_model_libraries});
    # }

    # create an execution context for running the tests

    my $execution_context = Heterarch::Test::ExecutionContext->new($model_library_shas, 0, );

    # create a test executor for running and updating the tests

    my $executor = Heterarch::Test::Executor::ModuleUpdater->new($execution_context);

    # note that there is only one module_definition

    foreach my $module_definition (@$module_definitions)
    {
	bless $module_definition, "Heterarch::Test::Module";

	my $error = $module_definition->md_run($execution_context, $executor);

	if ($error)
	{
	    return $error;
	}
    }

    # do final processing of the executor

    my $test_library = Heterarch::Test::Library->new($global_config->{tests_directory}, $reporter, );

    $test_library->{test_modules} = $module_definitions;

    $executor->ex_terminate($test_library);

    # end the execution_context

    $execution_context->ec_terminate();

    # return no error

    return '';
}


sub harness_command_run_tests
{
    my $harness_command_definition = shift;

    my $command = shift;

    my $default_reporter = shift;

    # find all the test module files

    my $test_library = Heterarch::Test::Library->new($global_config->{tests_directory}, $default_reporter, );

    $test_library->construct();

    $test_library->expand();

    $test_library->read_html
	(
	 {
	  introduction_filename => $global_config->{introduction_filename},
	 },
	);

    $test_library->merge_modules($option_input_modules);

    $test_library->merge_commands($option_input_commands);

    $test_library->merge_command_tests($option_input_command_tests);

    my $library_error = $test_library->validate();

    if ($library_error)
    {
	die "$0: *** Test Library Error: $library_error";
    }

    # randomize test module order if requested

    my $module_definitions = $test_library->{test_modules};

    if (defined $option_random_order)
    {
	# randomize the test module library

	my $random_seed;

	( $module_definitions, $random_seed ) = Heterarch::Test::Library::randomize_order($module_definitions, $option_random_order, $default_reporter);

	$global_test_report->{random_seed} = $random_seed;
    }
    else
    {
	$global_test_report->{random_seed} = 'not randomized';
    }

    # if there are model libraries

    my $model_library_shas = {};

    if (defined $global_config->{external_model_libraries})
    {
	$model_library_shas = ModelLibrary::shas($global_config->{external_model_libraries});
    }

    # set expected totals for the test counters

    my $expected_module_total = 0;

    my $expected_command_total = 0;

    my $expected_test_total = 0;

    foreach my $module_definition (@$module_definitions)
    {
	#t should use ->md_run()

	my $command_definitions = $module_definition->{command_definitions};

	foreach my $command_definition (@$command_definitions)
	{
	    #t should use ->cd_run()

	    my $command_tests = $command_definition->{command_tests};

	    foreach my $command_test (@$command_tests)
	    {
		#t should use ->ct_run_complete()

		$expected_test_total++;
	    }

	    $expected_command_total++;
	}

	$expected_module_total++;
    }

    $global_test_report->{global}->{test_counters}->{expected_totals}
	= {
	   module_definition => $expected_module_total,
	   command_definition => $expected_command_total,
	   command_test => $expected_test_total,
	  };

    # set status

    $global_test_report->{global}->{test_counters}->{current}
	= {
	   module_definition => 0,
	   command_definition => 0,
	   command_test => 0,
	  };

    $global_test_report->{global}->{status} = 'Running';

    # create an execution context for running the tests

    my $execution_context = Heterarch::Test::ExecutionContext->new($model_library_shas, $expected_test_total, );

    # create a test executor for running the tests following the requested type of output

    my $executor = $option_output->new($execution_context);

    # loop over all module definitions

    foreach my $module_definition (@$module_definitions)
    {
	bless $module_definition, "Heterarch::Test::Module";

	my $error = $module_definition->md_run($execution_context, $executor);
    }

    $global_test_report->{global}->{time_end} = strftime("%Y-%m-%d %H:%M:%S", localtime(time()));

    # do final processing of the executor

    $executor->ex_terminate($test_library);

    # end the execution_context

    $execution_context->ec_terminate();

    # close pending commands

    Heterarch::Test::CommandDefinition::Interactive::close_pending();

    # close the test report

    $global_test_report->{global}->{status} = 'Finished';

    # final report

    report_exit({ exit_code => 0, reporter => $default_reporter, }, );
}


sub application_initialize_configuration_and_environment
{
    my $command_line_configuration = shift;

    my $harness_command = shift;

    initialize_config();

    initialize_config_environment();

    initialize_globals();

    initialize_docker_harness();

    # initialize_signal_handlers() is called in the command executor
    # because the signal handlers assume that some of the global
    # variables have been initialized (the $reporter ao.).
}


sub initialize_config
{
    # find the package core directory

    $global_config = do $option_config_filename;

    if (not defined $global_config)
    {
	die "No test configuration found";
    }

    # add to tests directory to include paths

    if (not exists $global_config->{tests_directory})
    {
	$global_config->{tests_directory} = "./tests/specifications";

	$global_config->{introduction_filename} = "tests/introduction.html";
    }

    # correct numerical_compare mode for this configuration

    if (not $option_numerical_compare)
    {
	$option_numerical_compare = $global_config->{numerical_compare} || 0;
    }

    $global_configuration_initialized = 'from initialize_config';
}


sub initialize_config_environment
{
    my $fd_initialization;

    open($fd_initialization, ">&STDOUT");

    my $environment_settings = $global_config->{environment_settings};

    foreach my $environment_setting_name (keys %$environment_settings)
    {
	my $environment_setting = $environment_settings->{$environment_setting_name};

	# if simply setting values in the environment

	if (!ref $environment_setting)
	{
	    # set the value in the environment

	    $ENV{$environment_setting_name} = $environment_setting;
	}

	# if additional initialization required

	elsif (ref $environment_setting eq 'HASH')
	{
	    # get environment_setting value

	    my $value = $environment_setting->{value};

	    # set the value in the environment

	    $ENV{$environment_setting_name} = $value;

	    # give feedback

	    my $description = $environment_setting->{description};

	    $description =~ s/%value/$value/g;

	    if ($option_verbose)
	    {
		print $fd_initialization $description;
	    }

	    # loop over shell commands for initialization

	    my $shell_commands = $environment_setting->{initialization}->{shell};

	    foreach my $shell_command (@$shell_commands)
	    {
		# replace value

		$shell_command =~ s/%value/$value/g;

		# execute command

		if ($option_verbose)
		{
		    print $fd_initialization "$0: Executing ($shell_command)\n";
		}

		system $shell_command;
	    }
	}
	else
	{
	    die "$0: illegal environment_settings, was processing $environment_setting";
	}
    }
}


sub initialize_globals
{
    $global_test_report
	= {
	   %$global_test_report,
	   description => {
			   command => $0,
			   name => "Test report",
			   package => $global_config->{package},
			  },
	   global => {
		      config => $global_config,
		      error_count => $global_error_count,
		      status => 'initializing',
		      test_counters => {
					current => {
						    module_definition => -1,
						    command_definition => -1,
						    command_test => -1,
						   },
					expected_totals => {
							    module_definition => -1,
							    command_definition => -1,
							    command_test => -1,
							   },
				       },
		      time_start => strftime("%Y-%m-%d %H:%M:%S", localtime(time())),
		     },
	   target => {
		      OS => $^O,
		      system => {
				 libc => (join '', `(ls -l /lib/libc-* && ls -l /usr/lib/libc-*) 2>/dev/null`),
				 uname => (join '', `uname -a`),
				 cpu => (join '', `cat /proc/cpuinfo`),
				},
		      packages => {
				   '/etc/lsb-release' => (join '', `cat 2>&1 /etc/lsb-release`),
				   autoconf => (join '', `autoconf 2>&1 --version`),
				   automake => (join '', `automake 2>&1 --version`),
				   bison => (join '', `bison 2>&1 --version`),
				   flex => (join '', `flex 2>&1 --version`),
				   gcc => (join '', `gcc 2>&1 --version && gcc 2>&1 -v`),
				   perl => (join '', `perl 2>&1 -v && perl 2>&1 -V`),
				   python => (join '', `python 2>&1 --version`),
				   python_installation => (join '', `./contrib/pythontest 2>&1`),
				   swig => (join '', `swig 2>&1 -version`),
				  },
		     },
	  };

    # the previous command had no side effects on the loaded model (since there is no model yet)

    $global_previous_command_side_effects = 0;
}


sub initialize_docker_harness
{
    return Heterarch::Test::ExecutionContext::Harness::Docker::select_docker_command($option_console_type);
}


sub initialize_signal_handlers
{
    $SIG{'__DIE__'}
	= sub
          {
	      use Carp;

	      print STDERR Carp::longmess(@_);

	      $global_test_report->{global}->{status} = 'Died';

	      if ($global_configuration_initialized)
	      {
		  report_exit({ exit_code => 3, reason => [ @_, ] , }, );
	      }
	      else
	      {
		  exit 3;
	      }
	  };


    $SIG{'INT'}
	= sub
          {
	      $global_test_report->{global}->{status} = 'Interrupted';

	      if ($global_configuration_initialized)
	      {
		  report_exit({ exit_code => 2, }, );
	      }
	      else
	      {
		  exit 2;
	      }
	  };
}


sub main
{
    bless($global_command_line_configuration, "CommandLineDispatcher");

    my $arguments = [ @ARGV, ];

    my $harness_command = $global_command_line_configuration->parse_command_line($arguments);

    $global_command_line_configuration->command_line_application_initialize($harness_command, $arguments);

    $global_command_line_configuration->command_line_dispatch($harness_command, $arguments);
}


sub report_exit
{
    my $options = shift;

    my $exit_code = $options->{exit_code};

    my $reporter;

    if (exists $options->{reporter})
    {
	$reporter = $options->{reporter};
    }

    my $description = "";

    if (exists $options->{reason})
    {
	$description = $options->{reason};
    }

    if (defined $description
        && $exit_code eq 3)
    {
	print STDERR "*** die: $description\n";
    }

    report_file_dump();

    # if email enabled by the options

    report_send_by_email();

    # if there were errors

    if ($global_error_count)
    {
	# exit with failure

	$exit_code ||= 1;

	print $global_fd_output "$0: $global_test_report->{global}->{test_counters}->{current}->{command_test} test(s), $global_error_count error(s)\n";

	print $global_fd_output "$0: exit_code $exit_code\n\n";

	exit $exit_code;
    }

    # else

    else
    {
	# exit, possibly success

	print $global_fd_output "$0: $global_error_count error(s)\n\n";

	exit $exit_code;
    }
}


sub report_file_dump
{
    my $reporter = shift;

    # write the full report to a file

    my $report_filename = ">/tmp/report_$global_config->{package}->{name}.yml";

    eval
    {
	YAML::DumpFile($report_filename, $global_test_report);
    };

    if ($@)
    {
	print STDERR "*** Error: Failed to write output report to $report_filename\n";
    }
    else
    {
	# if ($reporter)
	# {
	#     $reporter->report_message_info("message_info", "See '$report_filename' for the detailed report.");
	# }
	# else
	{
	    print $global_fd_output "*** Info: See '$report_filename' for the detailed report\n";
	}
    }
}


sub report_send_by_email
{
    my $reporter = shift;

    if (!$option_email)
    {
	# if ($reporter)
	# {
	#     $reporter->report_message_info("message_info", "No email sent.");
	# }
	# else
	{
	    print $global_fd_output "No email sent.
";
	}

	return '';
    }

    # check for a default route

    #! from perl/basic.t

    my $no_default_route = (`/sbin/route` =~ /default/ ? '' : 'no default route to the internet found');

    if (!$no_default_route)
    {
	# ask if sending an email is ok

	my $default_answer_prompt = $global_error_count ? "Y/n" : "y/N";

	print $global_fd_output "\n---\n  These tests generated $global_error_count error(s)";
	print $global_fd_output ( $global_error_count ? "  Because errors were found, you should really consider sending an email to inform the developer of this software package\n" : "" );
	print $global_fd_output "\n  Ok to send an email to hugo.cornelis\@gmail.com for this test report,\n  this email will not reveal your identity to the recipient ?  [$default_answer_prompt]";

	my $answer = readline(*STDIN);

	# send an email if ok

	if ($answer =~ /^y/)
	{
	    #t perhaps should consider Mail::Builder, don't know

	    if ($loaded_mail_sender)
	    {
		my $sender
		    = Mail::Sender->new
		    (
		     {
		      # smtp => 'googlemail.l.google.com',
		      smtp => 'mta1.uthscsa.edu',
		      from => 'hugo.cornelis@gmail.com',
		     },
		    );

		print $global_fd_output "Sending ... should not take more than 30 seconds
";

		my $message
		    = (
		       "neurospaces_harness test report\n"
		       . "Generated on " . strftime("%Y-%m-%d %H:%M:%S", localtime(time())) . "\n"
		       . "\n========\n"
		       . Dump($global_test_report)
		       . "\n========\n"
		      );

		$sender->MailMsg
		    (
		     {
		      to => 'cornelis@uthscsa.edu',
		      subject => '[neurospaces_harness] test report',
		      msg => $message,
		     },
		    );

		# 	    $sender->Attach
		# 		(
		# 		 {
		# 		  description => 'global_test_report',
		# 		 },
		# 		);

		$sender->Close();

		if ($sender->{error})
		{
		    print STDERR "*** Error: $sender->{error}
Email was not sent.
";
		}
		else
		{
		    print $global_fd_output "Email was sent.
";
		}
	    }
	    else
	    {
		print STDERR "*** Error: Cannot load the perl module Mail::Sender, contact your sysadmin to install this perl module.
(use the shell command \"sudo perl -MCPAN -e 'install Mail::Sender'\")
Email was not sent.
";
	    }
	}
	else
	{
	    print $global_fd_output "Email was not sent.
";
	}
    }
    else
    {
	print STDERR "*** Warning: No default route to the internet found.
Email was not sent.
";
    }

    return 'email sent';
}


package ModelLibrary;


sub shas
{
    # model_libraries is an array of paths

    my $model_libraries = shift;

    # if there are model libraries

    my $model_library_shas = {};

    {
	# compute the shas of the modeling libraries

	foreach my $modeling_library (@$model_libraries)
	{
	    my $sha = _sha($modeling_library);

	    $model_library_shas->{$modeling_library}->{sha} = $sha;
	}
    }

    # return result

    return $model_library_shas;
}


sub _sha
{
    my $modeling_library_path = shift;

    # find all models

    use File::Find::Rule;

    my $files = [ File::Find::Rule->file()->in( $modeling_library_path ), ];

    my $shas
	= [
	   map
	   {
	       `sha1sum $_`;
	   }
	   @$files,
	  ];

    use Digest::SHA qw(sha1_hex);

    my $sha = sha1_hex(join ', ', @$shas);

    return $sha;
}


package Heterarch::Test::CommandDefinition;


our @ISA = ("Heterarch::Test::Element");


#
# Given a command_definition and an optional command_prefix, construct
# an array with the command as a string and the arguments as the rest
# of the array.
#

sub cd_construct_command_line
{
    my $command_definition = shift;

    my $command_prefix = shift;

    # if we have a command_prefix

    if (defined $command_prefix
	and scalar @$command_prefix)
    {
	# the command is the first element of the command prefix, the rest are arguments

	my $argument_array = [];

	if (exists $command_definition->{arguments})
	{
	    $argument_array = $command_definition->{arguments};
	}

	#t when no command entry is present: Use of uninitialized value in concatenation (.) or string at /usr/local/bin/neurospaces_harness line 1566.

	my $command_line = $command_definition->{command} . " " . (join ' ', @$argument_array);

	my $command_and_arguments = [ @$command_prefix, $command_line, ];

	my $command = shift @$command_and_arguments;

	my $command_line_object
	    = {
	       arguments => $command_and_arguments,
	       command => $command,
	       original_command => $command_line,
	      };

	return $command_line_object;
    }

    # if we don't have a command prefix

    else
    {
	# the command is the first word, all the rest are arguments

	my $command_array = [];

	if (exists $command_definition->{command})
	{
	    $command_array = [ split '\s', $command_definition->{command}, ];
	}

	my $argument_array = [];

	if (exists $command_definition->{arguments})
	{
	    $argument_array = $command_definition->{arguments};
	}

	my $command_arguments = [ @$command_array, @$argument_array, ];

	my $command_line = join ' ', @$command_arguments;

	my $command = shift @$command_arguments;

	my $command_line_object
	    = {
	       arguments => $command_arguments,
	       command => $command,
	       original_command => $command_line,
	      };

	return $command_line_object;
    }
}


sub cd_run
{
    my $command_definition = shift;

    my $execution_context = shift;

    my $executor = shift;

    # do selection and prepare the test environment

    my $module_definition = $execution_context->get_module_definition();

    my $not_started = $execution_context->ec_examine($module_definition, $command_definition);

    if ($not_started)
    {
	return "command_definition start failed ($not_started)";
    }

    # call the perl code, spaw_new

    # 1. an object given its class.
    # 2. a piece of perl code that is run.
    # 3. an interactive system shell command.

    $executor->ex_cd_start();

    # loop over all tests for this command

    my $command_tests = $command_definition->{command_tests};

    foreach my $command_test (@$command_tests)
    {
	bless $command_test, "Heterarch::Test::CommandTest";

	# lookup the class for this command test

	$command_test->rebless();

	$command_test->ct_run_complete($execution_context, $executor);
    }

    # repair the command test environment

    $execution_context->ec_end($module_definition, $command_definition);

    # register if this command had side effects

    #! e.g. using a preparer/reparer combination

    $global_previous_command_side_effects ||= $command_definition->{side_effects} || 0;

    # increment command definition count

    $global_test_report->{global}->{test_counters}->{current}->{command_definition}++;

    return '';
}


sub process_clauses
{
    my $command_definition = shift;

    my $execution_context = shift;

    if (exists $command_definition->{wait})
    {
	my $wait = $command_definition->{wait};

	$execution_context->wait($wait);
    }
}


sub rebless
{
    my $command_definition = shift;

    # by default we have a regular command definition, but the hacked exceptions are ...

    my $target_package = "Heterarch::Test::CommandDefinition";

    # ... we have to either instantiate an object that produces output ...

    if ($command_definition->{class})
    {
	$target_package = "Heterarch::Test::CommandDefinition::PerlClass";
    }

    # ... or run perl code that produces output

    elsif (ref $command_definition->{command} eq 'CODE')
    {
	$target_package = "Heterarch::Test::CommandDefinition::PerlCode";
    }

    # ... or run a command that produces output

    else
    {
	$target_package = "Heterarch::Test::CommandDefinition::Interactive";
    }

    # rebless

    bless $command_definition, $target_package;

    # return result

    return $command_definition;
}


package Heterarch::Test::CommandDefinition::Interactive;;


our @ISA = ("Heterarch::Test::CommandDefinition");


use Data::Comparator qw(data_comparator);


my $global_exp;

my $global_running_command_definition;


sub close_pending
{
    # if there is a command running

    if ($global_exp)
    {
	# terminate the command

	#t could be that the hard_close() call is needed because
	#t neurospaces uses readline, not sure needs investigation,
	#t perhaps.

	$global_exp->hard_close();
    }
}


sub spawn_new
{
    my $command_definition = shift;

    my $execution_context = shift;

    # apply the execution prefix from the harnessing clauses

    my $command_line = $execution_context->ec_construct_command_line($command_definition);

    if (defined $option_debugging
	and $option_debugging eq 'spawn_new')
    {
	use YAML;

	print Dump(
		   {
		    option_debugging => {
					 command_line => $command_line,
					},
		   },
		  );
    }

    my $test_startup = "yes, do the startup testing";

    if (exists $command_line->{command})
    {
	# compare the running command with this command

	my $differences = data_comparator($command_line, $global_running_command_definition);

	# remember to spawn a new command

	my $spawn_new = not $command_definition->{recycle};

	# if the command can be executed

	my $arguments = $command_line->{arguments};

	my $command = $command_line->{command};

	if (defined $command)
	{
	    my $reporter = $execution_context->{reporter};

	    if ($spawn_new)
	    {
		if ($global_exp)
		{
		    # terminate the previous command

		    #t could be that the hard_close() call is needed because
		    #t neurospaces uses readline, not sure needs investigation,
		    #t perhaps.

		    $global_exp->hard_close();
		}

		# create a new Expect object by spawning a new process with the new command

		require Expect;

		$global_exp = Expect->new();

		#! From the manual: Set pty to raw mode before
		#! spawning. This disables echoing and CR->LF
		#! translation and gives a more pipe-like
		#! behaviour. Note that this must be set before spawning
		#! the program.

		$global_exp->raw_pty(1);

		if (not $reporter->isa("Heterarch::Test::Reporting::Linear"))
		{
		    $global_exp->log_stdout(0);
		}

		# 		    $exp->slave->stty(qw(raw -echo));

		$global_exp->spawn
		    (
		     (
		      $option_trace
		      ? ($option_trace)
		      : ()
		     ),
		     $command,
		     @$arguments
		    )
		    or die "$0: cannot spawn $command: $!\n";

		# set the running_command_definition

		$global_running_command_definition = $command_line;

		$reporter->report_message("message_command", "*** Executing $command $command_line->{original_command}");

		# remember to do startup testing

		$test_startup = 1;

		# there were no side effects yet

		$global_previous_command_side_effects = 0;
	    }
	    else
	    {
		$reporter->report_message("message_command", "*** Recycling $command " . (join ' ', map { "'$_'" } @$arguments));

		$test_startup = 0;
	    }
	}
    }
    elsif (exists $command_line->{internal})
    {
    }

    # return the expect object and whether a new command has been started

    return $global_exp, $test_startup;
}


#
# sub start
#
# Starts the application command and connects to its I/O channels.
#

sub cd_start
{
    my $self = shift;

    my $executor = shift;

    # start the command and connect with its I/O channels

    #! this is similar to having a class clause with value 'Expect' and calling Expect->new()

    my $execution_context = $executor->{execution_context};

    my ($exp, $test_startup) = $self->spawn_new($execution_context);

    $executor->{expect_object} = $exp;

    #! I believe this is obsolete

    $executor->{test_startup} = $test_startup;
}


package Heterarch::Test::CommandDefinition::PerlClass;;


our @ISA = ("Heterarch::Test::CommandDefinition");


#
# sub start
#
# Calls the new method of the given class to instantiate a Perl object.
#

sub cd_start
{
    my $self = shift;

    my $executor = shift;

    # instantiate the object

    my $class = $self->{class};

    my $filename = $class . ".pm";

    $filename =~ s(::)(/)g;

    require $filename;

    $self->{command_object} = eval "$class->new()";
}


package Heterarch::Test::CommandDefinition::PerlCode;


our @ISA = ("Heterarch::Test::CommandDefinition");


#
# sub start
#
# No-op.
#
# Deprecated: Hardcoded perl code in the test specifications should be removed.
#

sub cd_start
{
    my $self = shift;

    my $executor = shift;

    # code is already instantiated, nothing to do here

    my $sub = $self->{command};

    # previously, arguments were: self, config.  config has a key
    # $config->{c_code}->{directory} pointing to the directory with
    # the C source code.

    # with the assumption that self has never been used.

    my $error = &$sub();

    if ($error)
    {
	# my $command_definition = $execution_context->get_command_definition();

	# my $current = $self->_path_get_current();

	# my $module_definition = $current->{current_module_definition};

	# my $command_definition = $current->{current_command_definition};

	# my $command_test = $current->{current_command_test};

	my $execution_context = $executor->{execution_context};

	my $module_definition = $execution_context->get_module_definition();

	my $module_name = $module_definition->{name};

	my $reporter = $execution_context->{reporter};

	$reporter->report_error_add
		(
		 {
		  context_path => $execution_context->get_context_path(),
		  description => "command_definition $self->{description}",
		  error => $error,
		  module_name => $module_name,
		 },
		);
    }

    return $error;
}


package Heterarch::Test::CommandDefinition::IsFileExecutable;


our @ISA = ("Heterarch::Test::CommandDefinition");


#
# sub start
#

sub cd_start
{
    my $self = shift;

    my $executor = shift;

    # code is already instantiated, nothing to do here

    my $sub = $self->{command};

    my $error;

    if (-x "workflow-tests-commands-data/examples_sh/sh_single_command.sh")
    {
    }
    else
    {
	$error = "workflow-tests-commands-data/examples_sh/sh_single_command.sh does not have its execute bit set"
    }

    if ($error)
    {
	# my $command_definition = $execution_context->get_command_definition();

	# my $current = $self->_path_get_current();

	# my $module_definition = $current->{current_module_definition};

	# my $command_definition = $current->{current_command_definition};

	# my $command_test = $current->{current_command_test};

	my $execution_context = $executor->{execution_context};

	my $module_definition = $execution_context->get_module_definition();

	my $module_name = $module_definition->{name};

	my $reporter = $execution_context->{reporter};

	$reporter->report_error_add
		(
		 {
		  context_path => $execution_context->get_context_path(),
		  description => "Heterarch::Test::CommandDefinition::IsFileExecutable $self->{description}",
		  error => $error,
		  module_name => $module_name,
		 },
		);
    }

    return $error;
}


package Heterarch::Test::CommandTest;


our @ISA = ("Heterarch::Test::Element");


#
# after_testing()
#
# 1. records the time it took to execute the test.
# 2. calls approximate testers if this is allowed by options.
#

sub after_testing
{
    my $self = shift;

    my $execution_context = shift;

    my $test_result = shift;

    my $module_definition = $execution_context->get_module_definition();

    # fill in the elapsed time in the report

    if ($option_timings)
    {
	use Time::HiRes qw(tv_interval);

	my $time_start = $self->{time_start};

	my $time_elapsed = tv_interval($time_start);

	my $module_name = $module_definition->{name};

	my $description = $self->{description};

	my $test_counter = $execution_context->get_counter_command_test_counter();

	$global_test_report->{timings}->{$module_name}->{"$test_counter. $description"} = $time_elapsed;
    }

    # attempt to correct if the result is almost correct

    #! perl code does not produce a full test result object, so we cannot try to correct an almost correct result

    my $command_definition = $execution_context->get_command_definition();

    my $command = $command_definition->{command};

    if (not (ref $command eq 'CODE'))
    {
	# if things don't match

	if ($test_result->{error})
	{
	    # if allowed to compare numerically

	    if ((!$self->{string_only}
		 && $option_numerical_compare)

		# or forced to compare numerically

		|| $self->{numerical_compare}
		|| $command_definition->{numerical_compare}
		|| $module_definition->{numerical_compare})
	    {
		# compare numerically

		push @{$global_test_report->{numerical_compare}}, $self->{description};

		#! this call uses the $read variable, making it harder to bring this call
		#! outside the condition that tests if this variable is defined
		#! this variable contains the expected output

		$test_result->{error}
		    = Neurospaces::Tester::Comparators::numerical
		        (
			 {
			  description => $self->{description},
			 },
			 $test_result->{before_match},
			 $test_result->{expected},
			 $test_result->{error});
	    }
	}
    }

    # return result

    return $test_result;
}


sub _before_run
{
    my $self = shift;

    my $execution_context = shift;

    # record time

    use Time::HiRes qw(gettimeofday);

    my $time_start = [ gettimeofday(), ];

    $self->{time_start} = $time_start;
}


#
# sub before_testing()
#
# Calls ->_before_run() to record the current time.
#
# This method is overriden in the Interactive package.
#

sub before_testing
{
    my $self = shift;

    my $execution_context = shift;

    # record time

    $self->_before_run($execution_context);
}


sub ct_run_complete
{
    my $command_test = shift;

    my $execution_context = shift;

    my $executor = shift;

    # do selection and prepare the test environment

    my $module_definition = $execution_context->get_module_definition();

    my $command_definition = $execution_context->get_command_definition();

    # emit comment if any

    my $not_started = $execution_context->ec_examine($module_definition, $command_definition, $command_test);

    if ($not_started)
    {
	return "command_test start failed ($not_started)";
    }

    # run the test executor which will run the command_test

    my $execution_result = $executor->ex_ct_run($command_test);

    # process errors

    my $error = $execution_result->{error};

    if ($error)
    {
	my $description = $command_test->{description};

	my $command_definition_description = $command_definition->{description};

	my $message;

	my $before_match = $execution_result->{before_match};

	#! wondering what option_verbose has to do with the reporting of errors

	if ($option_verbose)
	{
	    $message = $before_match;
	}

	my $reporter = $execution_context->{reporter};

	my $module_name = $module_definition->check_name($reporter);

	$reporter->report_error_add
		(
		 {
		  context_path => $execution_context->get_context_path(),
		  description => $description,
		  error => $error,
		  expected => $execution_result->{expected},
		  message => $message,
		  module_name => $module_name,
		  seen => $before_match,
		  subdescription => $command_definition_description,
		 },
		);
    }

    # end the execution of this test

    $execution_context->ec_end($module_definition, $command_definition, $command_test);

    # register if this command had side effects

    $global_previous_command_side_effects ||= $command_test->{side_effects} || 0;

    # increment command test count

    $global_test_report->{global}->{test_counters}->{current}->{command_test}++;

    my $reporter = $execution_context->{reporter};

    $reporter->report_progress("progress_bar", $global_test_report->{global}->{test_counters}->{current}->{command_test});

    return '';
}


#
# rebless the given command_test to a package that is suitable to test
# it, given its keys and properties.
#
# possible target packages are:
#
# "Heterarch::Test::CommandTest";
# "Heterarch::Test::CommandTest::CommandObject"
# this one is not supported anymore: $target_package = "Heterarch::Test::CommandTest::PerlCode";
# "Heterarch::Test::CommandTest::Interactive"
# "Heterarch::Test::CommandTest::Interactive::ShellTester"
# "Heterarch::Test::CommandTest::Interactive::Literal"
# "Heterarch::Test::CommandTest::Interactive::Regex"
# "Heterarch::Test::CommandTest::Interactive::Alternatives"
# "Heterarch::Test::CommandTest::Interactive::File"
# "Heterarch::Test::CommandTest::Interactive::Shell"
#

sub rebless
{
    my $command_test = shift;

    my $target_package = "Heterarch::Test::CommandTest";

    if (ref $command_test->{write} eq 'ARRAY')
    {
	# command_object

	$target_package = "Heterarch::Test::CommandTest::CommandObject";

	my $writes = $command_test->{write};

	foreach my $write (@$writes)
	{
	    my $method = $write->{method};

	    my $arguments = $write->{arguments};
	}

	# compare the read data with what is expected

	if (exists $command_test->{read})
	{
	    my $read = $command_test->{read};
	}
    }

    # if the command_definition has executable perl code

    # elsif (ref $command eq 'CODE')
    # {
	# $target_package = "Heterarch::Test::CommandTest::PerlCode";

    # }

    # else the command definition runs a shell command

    else
    {
	# set read, wait and write strings

	$target_package = "Heterarch::Test::CommandTest::Interactive";

	my $read = $command_test->{read};

	my $wait = $command_test->{wait};

	my $write = $command_test->{write};

	# set timeout, defaults to two seconds, but for newly created processes add two additional seconds.

	my $timeout
	    = (defined $command_test->{timeout}
	       ? $command_test->{timeout} * $option_timeout_multiplier
	       : (0
		  ? 4 * $option_timeout_multiplier
		  : 2 * $option_timeout_multiplier));

	# write

	if (ref $write eq 'HASH')
	{
	}
	elsif (defined $write)
	{
	    # send write to the command under test via the expect object
	}

	# wait

	if ($wait)
	{
	    # wait for $wait seconds
	}

	# check the shell command that will be executed with a timeout

	my $shell = $command_test->{shell};

	if (ref $shell eq 'HASH')
	{
	    #! not sure what this can be
	}
	elsif (defined $shell)
	{
	    # run the command for a maximum of $timeout seconds

	    # fall through
	}

	# if there is an external application to test the final output

	#! the previous shell command was a post-processor, this one is a tester

	my $tester = $command_test->{tester};

	if ($tester)
	{
	    $target_package = "Heterarch::Test::CommandTest::Interactive::ShellTester";

	    # set the external tester that compares the generated output with what is expected

	    #! the external tester runs an executable shell command

	    my $shell = $tester->{shell};

	    # there must be a shell command we should run

	    if ($shell)
	    {
		my $produced = `$shell`;

		my $test_result
		    = {
		       expected => defined $tester->{expected} ? $tester->{expected} : '',
		      };

		if (($produced eq ''
		     and $test_result->{expected} ne '')
		    or ($produced ne ''
			and $test_result->{expected} eq ''))
		{
		    $test_result->{error} = "external tester produces output that is different from what is expected, one is empty, the other is not";

		    $test_result->{before_match} = $produced;
		}
		elsif ($produced =~ /$test_result->{expected}/)
		{
		}
		else
		{
		    $test_result->{error} = "the external tester produces output that is different from the expected output";

		    $test_result->{before_match} = $produced;
		}
	    }
	    else
	    {
		die "$0: *** Error: external testers must have a shell command";
	    }
	}

	# read

	elsif (defined $read)
	{
	    # if literal text expected

	    if (!ref $read)
	    {
		if (exists $command_test->{white_space})
		{
		    if ($command_test->{white_space} eq 'convert seen 0a to 0d 0a newlines')
		    {
			$read =~ s(\x0a)(\x0d\x0a)g;
		    }
		}

		$target_package = "Heterarch::Test::CommandTest::Interactive::Literal";

		# expect $read for output
	    }

	    # if array, means regex match

	    elsif (ref $read eq 'ARRAY')
	    {
		# expect $read to match as a regex with the output

		$target_package = "Heterarch::Test::CommandTest::Interactive::Regex";

	    }

	    # else, hash: one of several alternatives expected

	    else
	    {
		# compose the alternatives regex

		if ($read->{alternatives})
		{
		    # expect that the output literally matches with one of the given alternatives

		    $target_package = "Heterarch::Test::CommandTest::Interactive::Alternatives";

		    my $alternatives = $read->{alternatives};
		}

		# if an application output file is expected

		elsif ($read->{application_output_file})
		{
		    $target_package = "Heterarch::Test::CommandTest::Interactive::File";

		    # read it

		    my $application_output_file = $read->{application_output_file};

		    # and literally compare it with an expected output file or with the {expected_output}

		    my $expected_output_file = $read->{expected_output_file};

		    if ($expected_output_file)
		    {
		    }
		    elsif (defined $read->{expected_output})
		    {
		    }
		}

		# if there is a shell command given

		elsif ($read->{shell})
		{
		    $target_package = "Heterarch::Test::CommandTest::Interactive::Shell";

		    # run it and capture its output

		    my $shell = $read->{shell};

		    # and compare its output with the output of the application
		}
		else
		{
		    my $description = $command_test->{description};

		    die "test not understood by $0, aborting (illegal read clause for $description)";
		}
	    }
	}
    }

    # rebless

    bless $command_test, $target_package;

    # return result

    return $command_test;
}


#
# run()
#
# The default implementation executes perl code in the command definition.
#

sub ct_run_command
{
    my $self = shift;

    my $execution_context = shift;

    my $executor = shift;

    my $command_definition = $execution_context->get_command_definition();

    my $module_definition = $execution_context->get_module_definition();

    my $command = $command_definition->{command};

    # expect this output

    my $test_result;

    # if the command_definition has executable perl code

    if (ref $command eq 'CODE')
    {
	# execute the perl code

	use Cwd;

	my $directory = getcwd();

	my $error
	    = &$command
	    (
	     $self,
	     {
	      c_code => {
			 directory => $directory,
			},
	     },
	    );

	$test_result
	    = {
	       error => $error,
	      };
    }

    # return result

    return $test_result;
}


package Heterarch::Test::CommandTest::CommandObject;


our @ISA = ("Heterarch::Test::CommandTest");


#
# run()
#
# write the write clauses of the command test to the test object.
# expect the contents of the read clause for output.
#

sub ct_run_command
{
    my $self = shift;

    my $execution_context = shift;

    my $executor = shift;

    my $command_definition = $execution_context->get_command_definition();

    my $module_definition = $execution_context->get_module_definition();

    my $command = $command_definition->{command};

    # expect this output

    my $test_result;

    # record time

    $self->before_testing($execution_context);

    # if the command_definition instantiated an object

    my $command_object = $executor->{command_object};

    # write data to the object using the given methods
    # and arguments and obtain a result from the
    # object

    my $result;

    my $last_method;

    my $writes = $self->{write};

    foreach my $write (@$writes)
    {
	my $method = $write->{method};

	$last_method = $method;

	my $arguments = $write->{arguments};

	$result = $command_object->$method(@$arguments);
    }

    # compare the read data with what is expected

    if (exists $self->{read})
    {
	my $read = $self->{read};

	$test_result
	    = {
	       error => ($result eq $read
			 ? ""
			 : "$last_method returned $result, expected $read"),
	       before_match => $result,
	       expected => $read,
	      };
    }

    # try correcting

    $self->after_testing($execution_context, $test_result);

    # return the final test result

    return $test_result;
}


package Heterarch::Test::CommandTest::Interactive;

#
# The interactive package provides methods for testing interactive
# commands:
#
# - waiting for predetermined amount of time.
#
# - post processing of application results before the test takes
#   place.
#
# - record execution times.
#
# It overrides the ->before_testing() method to conveniently call some
# of these methods.
#
# Derived packages should only override the ->run() method.
#


our @ISA = ("Heterarch::Test::CommandTest");


sub before_testing
{
    my $self = shift;

    my $execution_context = shift;

    my $executor = shift;

    # record time

    $self->_before_run($execution_context);

    # do write processing

    $self->_process_write($execution_context, $executor);

    # do wait processing

    $self->_process_wait($execution_context);

    # do post processing

    $self->_prepare_run($execution_context);
}


# compute a sensible timeout for interaction with the command that is
# being tested.

sub get_timeout
{
    my $self = shift;

    my $test_startup = $self->{test_startup};

    my $result
	= (defined $self->{timeout}
	   ? $self->{timeout} * $option_timeout_multiplier
	   : ($test_startup
	      ? 4 * $option_timeout_multiplier
	      : 2 * $option_timeout_multiplier));

    return $result;
}


#
# _prepare_run()
#
# Provides processing of a 'shell' clause to post-process results
# generated by the application.
#

sub _prepare_run
{
    my $self = shift;

    my $execution_context = shift;

    # check the shell command that will be executed with a timeout

    my $shell = $self->{shell};

    if (ref $shell eq 'HASH')
    {
	#! not sure what this can be
    }
    elsif (defined $shell)
    {
	# run the command for a maximum of $timeout seconds

	# allow it to post-process results generated by the command that is being tested

	my $timeout = $self->get_timeout();

	my $reporter = $execution_context->{reporter};

	$reporter->report_message("message_details", "*** Shell: timeout $timeout $shell\n");

	system "timeout $timeout $shell";

	#t check the output or status of the shell command?

	# fall through
    }

    #t return something sensible

    return $?;
}


sub _process_wait
{
    my $self = shift;

    my $execution_context = shift;

    if (exists $self->{wait})
    {
	my $wait = $self->{wait};

	$execution_context->wait($wait);
    }
}


sub _process_write
{
    my $self = shift;

    my $execution_context = shift;

    my $executor = shift;

    my $write = $self->{write};

    # write

    if (ref $write eq 'HASH')
    {
    }
    elsif (defined $write)
    {
	my $reporter = $execution_context->{reporter};

	$reporter->report_message("message_details", "*** Write: $write\n");

	$executor->{expect_object}->send("$write\n");
    }
}


# I believe this is only a template for derived classes.

sub ct_run_command
{
    my $self = shift;

    my $execution_context = shift;

    my $executor = shift;

    my $command_definition = $execution_context->get_command_definition();

    my $module_definition = $execution_context->get_module_definition();

    my $command = $command_definition->{command};

    # record time, do write, wait processing, pre-processing

    $self->before_testing($execution_context, $executor);

    # try correcting

    my $test_result;

    $self->after_testing($execution_context, $test_result);

    # return the final test result

    return $test_result;
}


package Heterarch::Test::CommandTest::Interactive::ShellTester;


our @ISA = ("Heterarch::Test::CommandTest::Interactive");


# write the write clauses of the command test.
# use the shell command in the tester clause to produce the application output.
#   the shell command should find the produced output and process it.
# compare this output with the expected output.

sub ct_run_command
{
    my $self = shift;

    my $execution_context = shift;

    my $executor = shift;

    my $command_definition = $execution_context->get_command_definition();

    my $module_definition = $execution_context->get_module_definition();

    my $command = $command_definition->{command};

    # record time, do write, wait processing, pre-processing

    $self->before_testing($execution_context, $executor);

    # if there is an external application to test the final output

    #! the previous shell command was a post-processor, this one is a tester

    my $tester = $self->{tester};

    # set the external tester that compares the generated output with what is expected

    #! the external tester runs an executable shell command

    my $shell = $tester->{shell};

    my $produced = `$shell`;

    my $test_result
	= {
	   expected => defined $tester->{expected} ? $tester->{expected} : '',
	  };

    #			    if ($expected)
    #				$expected = quotemeta $tester->{expected};

    if (($produced eq ''
	 and $test_result->{expected} ne '')
	or ($produced ne ''
	    and $test_result->{expected} eq ''))
    {
	$test_result->{error}
	    = "external tester produces output that is different from what is expected, one is empty, the other is not";

	$test_result->{before_match} = $produced;
    }
    elsif ($produced =~ /$test_result->{expected}/)
    {
    }
    else
    {
	$test_result->{error} = "the external tester produces output that is different from the expected output";

	$test_result->{before_match} = $produced;
    }

    # try correcting

    $self->after_testing($execution_context, $test_result);

    # return the final test result

    return $test_result;
}


package Heterarch::Test::CommandTest::Interactive::Literal;


our @ISA = ("Heterarch::Test::CommandTest::Interactive");


# write the write clauses of the command test.
# read the application output using the expect object.
# literally compare the application output with the expected output.

sub ct_run_command
{
    my $self = shift;

    my $execution_context = shift;

    my $executor = shift;

    my $command_definition = $execution_context->get_command_definition();

    my $module_definition = $execution_context->get_module_definition();

    my $command = $command_definition->{command};

    # record time, do write, wait processing, pre-processing

    $self->before_testing($execution_context, $executor);

    # set the expected output

    my $read = $self->{read};

    if (exists $execution_context->{variable_actions})
    {
	my $variable_actions = $execution_context->{variable_actions};

	foreach my $variable_actions_entry (@$variable_actions)
	{
	    foreach my $variable_name (sort keys %$variable_actions_entry)
	    {
		my $variable_value = $variable_actions_entry->{$variable_name};

		$read =~ s/$variable_name/$variable_value/g;
	    }
	}
    }

    # if literal text expected

    if (exists $self->{white_space})
    {
	my $reporter = $execution_context->{reporter};

	if ($self->{white_space} eq 'convert seen 0a to 0d 0a newlines')
	{
	    $reporter->report_message("message_details", "*** Converting seen \\x0a to \\x0d \\x0a newlines\n");

	    $read =~ s(\x0a)(\x0d\x0a)g;
	}
	elsif ($self->{white_space} eq 'convert seen \\x0d \\x0a to \\x0a newlines')
	{
	    $reporter->report_message("message_details", "*** Converting seen \\x0d \\x0a to \\x0a newlines\n");

	    $read =~ s(\x0d\x0a)(\x0a)g;
	}
	elsif ($self->{white_space} eq 'convert seen \\x0d \\x0a to \\x0a newlines')
	{
	    $reporter->report_message("message_details", "*** Converting seen \\x0d \\x0a to \\x0a newlines\n");

	    $read =~ s(\x0d\x0a)(\x0a)g;
	}
    }

    my $timeout = $self->get_timeout();

    my ($matched_pattern_position,
	$error,
	$successfully_matching_string,
	$before_match,
	$after_match)
	= $executor->{expect_object}->expect($timeout, $read, );

    my $test_result
	= {
	   matched_pattern_position => $matched_pattern_position,
	   error => $error,
	   successfully_matching_string => $successfully_matching_string,
	   before_match => $before_match,
	   after_match => $after_match,
	   expected => $read,
	  };

    # try correcting

    $self->after_testing($execution_context, $test_result);

    # return the final test result

    return $test_result;
}


package Heterarch::Test::CommandTest::Interactive::Regex;


our @ISA = ("Heterarch::Test::CommandTest::Interactive");


# write the write clauses of the command test.
# read the application output using the expect object.
# compare the application output with the expected output as a regex.

sub ct_run_command
{
    my $self = shift;

    my $execution_context = shift;

    my $executor = shift;

    my $command_definition = $execution_context->get_command_definition();

    my $module_definition = $execution_context->get_module_definition();

    my $command = $command_definition->{command};

    # record time, do write, wait processing, pre-processing

    $self->before_testing($execution_context, $executor);

    # set the expected output

    my $read = $self->{read};

    # if array, means regex match

    my $timeout = $self->get_timeout();

    my ($matched_pattern_position,
	$error,
	$successfully_matching_string,
	$before_match,
	$after_match)
	= $executor->{expect_object}->expect($timeout, @$read, );

    my $test_result
	= {
	   matched_pattern_position => $matched_pattern_position,
	   error => $error,
	   successfully_matching_string => $successfully_matching_string,
	   before_match => $before_match,
	   after_match => $after_match,

	   #! skip the expect '-re' flag

	   expected => $read->[1],
	  };

    # try correcting

    $self->after_testing($execution_context, $test_result);

    # return the final test result

    return $test_result;
}


package Heterarch::Test::CommandTest::Interactive::Alternatives;


our @ISA = ("Heterarch::Test::CommandTest::Interactive");


# write the write clauses of the command test.
# read the application output using the expect object.
# compare the application output with the expected output which is a list of alternatives.

sub ct_run_command
{
    my $self = shift;

    my $execution_context = shift;

    my $executor = shift;

    my $command_definition = $execution_context->get_command_definition();

    my $module_definition = $execution_context->get_module_definition();

    my $command = $command_definition->{command};

    # record time, do write, wait processing, pre-processing

    $self->before_testing($execution_context, $executor);

    # compose the alternatives regex

    my $read = $self->{read};

    my $alternatives = $read->{alternatives};

    my $test_result
	= {
	   expected => '(' . (join '|', map { quotemeta } @$alternatives) . ')',
	  };

    # read from the application

    my $timeout = $self->get_timeout();

    my ($matched_pattern_position,
	$error,
	$successfully_matching_string,
	$before_match,
	$after_match)
	= $executor->{expect_object}->expect($timeout, "-re", $test_result->{expected}, );

    $test_result->{matched_pattern_position} = $matched_pattern_position;
    $test_result->{error} = $error;
    $test_result->{successfully_matching_string} = $successfully_matching_string;
    $test_result->{before_match} = $before_match;
    $test_result->{after_match} = $after_match;

    # try correcting

    $self->after_testing($execution_context, $test_result);

    # return the final test result

    return $test_result;
}


package Heterarch::Test::CommandTest::Interactive::File;


our @ISA = ("Heterarch::Test::CommandTest::Interactive");


# write the write clauses of the command test.
# read the application output from a file.
# compare the application output with the expected output which is a file.

sub ct_run_command
{
    my $self = shift;

    my $execution_context = shift;

    my $executor = shift;

    my $command_definition = $execution_context->get_command_definition();

    my $module_definition = $execution_context->get_module_definition();

    my $command = $command_definition->{command};

    # record time, do write, wait processing, pre-processing

    $self->before_testing($execution_context, $executor);

    # read the application output file

    my $read = $self->{read};

    my $application_output_file = $read->{application_output_file};

    my $pwd = `pwd`;

    chomp $pwd;

    my $reporter = $execution_context->{reporter};

    $reporter->report_message("message_details", "*** Application output file: $application_output_file (in $pwd)\n");

    # and compare it with the expected output file

    my $expected_output_file = $read->{expected_output_file};

    local $/;

    my $application_output = $self->file_content_read($execution_context, "command_test $self->{description}", $application_output_file);

    my $expected_output;

    if ($expected_output_file)
    {
	$reporter->report_message("message_details", "*** Expected output file: $expected_output_file\n");

	$expected_output = $self->file_content_read($execution_context, "command_test $self->{description}", $expected_output_file);
    }
    elsif (defined $read->{expected_output})
    {
	$expected_output = $read->{expected_output};
    }

    my $test_result
	= {
	   expected => $expected_output,
	  };

    if ($expected_output eq $application_output)
    {
	$test_result->{before_match} = $application_output;
    }
    else
    {
	$test_result->{before_match} = $application_output;

	$read = $expected_output;

	$test_result->{error} = 'expected_output does not match application_output';
    }

    # try correcting

    $self->after_testing($execution_context, $test_result);

    # return the final test result

    return $test_result;
}


sub file_content_read
{
    my $command_test = shift;

    my $execution_context = shift;

    my $description = shift;

    my $filename = shift;

    my $content;

    use IO::File;

    my $file = IO::File->new("<$filename");

    if ($file)
    {
	local $/; # enable 'slurp' mode

	$content = <$file>;

	$file->close();
    }
    else
    {
	my $module_definition = $execution_context->get_module_definition();

	my $module_name = $module_definition->{name};

	my $reporter = $execution_context->{reporter};

	$reporter->report_error_add
	    (
	     {
	      context_path => $execution_context->get_context_path(),
	      description => "file open error for $description",
	      error => "$description cannot open file $filename",
	      module_name => $module_name,
	     },
	    );
    }

    return $content;
}


package Heterarch::Test::CommandTest::Interactive::Shell;


our @ISA = ("Heterarch::Test::CommandTest::Interactive");


# write the write clauses of the command test.
# run the given shell command and capture its output.
# read the application output using the expect object.
# compare this output with the application output.

sub ct_run_command
{
    my $self = shift;

    my $execution_context = shift;

    my $executor = shift;

    my $command_definition = $execution_context->get_command_definition();

    my $module_definition = $execution_context->get_module_definition();

    my $command = $command_definition->{command};

    # record time, do write, wait processing, pre-processing

    $self->before_testing($execution_context, $executor);

    # run the given shell command and capture its output

    my $read = $self->{read};

    my $shell = $read->{shell};

    my $expected = `$shell`;

    # and compare its output with the output of the application

    my $timeout = $self->get_timeout();

    my ($matched_pattern_position,
	$error,
	$successfully_matching_string,
	$before_match,
	$after_match)
	= $executor->{expect_object}->expect($timeout, $expected, );

    my $test_result
	= {
	   matched_pattern_position => $matched_pattern_position,
	   error => $error,
	   successfully_matching_string => $successfully_matching_string,
	   before_match => $before_match,
	   after_match => $after_match,
	   expected => $expected,
	  };

    # try correcting

    $self->after_testing($execution_context, $test_result);

    # return the final test result

    return $test_result;
}


package Heterarch::Test::Element;


our $selected_output_levels;


# could also use Array::Util, but it is not always installed

sub array_union_intersection_difference
{
    my $array1 = shift;

    my $array2 = shift;

    my (@union, @intersection, @difference);

    my %count = ();

    foreach my $element (@$array1, @$array2)
    {
	$count{$element}++
    }

    foreach my $element (keys %count)
    {
	push @union, $element;

	push @{ $count{$element} > 1
		    ? \@intersection
		    : \@difference },
		    $element;
    }

    return ( \@union, \@intersection, \@difference );
}


# sub is_selected() should implement a logical and of the different selection criteria

sub is_selected
{
    my $self = shift;

    my $reporter = shift;

    # implement a logical and of the different selection criteria

    my $result = $self->is_selected_by_output_level_options($reporter);

    if ($result)
    {
	$result = $self->is_selected_by_tag($reporter);
    }

    return $result;

    # my $self = shift;

    # my $reporter = shift;

    # return $self->is_selected_by_output_level_options($reporter);
}


sub is_selected_by_output_level_options
{
    my $self = shift;

    my $reporter = shift;

    # map the selected output levels to a hash to facilitate easy detection what has been enabled

    if (not defined $selected_output_levels)
    {
	$selected_output_levels
	    = {
	       map
	       {
		   my $output_level = $_;

		   my $result = { $output_level => "from options", };

		   %$result;
	       }
	       @$option_output_levels,
	      };
    }

    # convert the class to its output level

    use Scalar::Util 'blessed';

    my $type = defined blessed $self && $self->isa("Heterarch::Test::Module") ? "module" : "";

    $type ||= defined blessed $self && $self->isa("Heterarch::Test::CommandDefinition") ? "command_definition" : "";

    $type ||= defined blessed $self && $self->isa("Heterarch::Test::CommandTest") ? "command_test" : "";

    # determine whether this output level was selected

    my $selected = $selected_output_levels->{$type};

    # return result

    return $selected;
}


# return true if this element definition has a tag that matches the tag options.

sub is_selected_by_tag
{
    my $element_definition = shift;

    my $reporter = shift;

    my $element_name = $element_definition->{name};

    if (defined $option_debugging
	and $option_debugging eq 'tags')
    {
	use YAML;

	print Dump(
		   {
		    option_debugging => {
					 selected_by_tag_element_name => $element_name,
					},
		   },
		  );
    }

    if (not scalar @$option_tags)
    {
	return ":all";
    }

    my $element_definition_tags = $element_definition->{tags};

    # use Array::Util qw(intersect);

    my ( $union, $intersection, $difference ) = array_union_intersection_difference($element_definition_tags, $option_tags);

    if (scalar @$intersection)
    {
	return $intersection;
    }
    else
    {
	if ($global_test_report->{output_format} eq 'executor')
	{
	    $reporter->report_message_info("message_info", "Element $element_definition->{description} is not selected by tag (" . (join ", ", @$option_tags ) . " are selected tags).
Total of $global_test_report->{global}->{test_counters}->{current}->{command_test} test(s) (encountered $global_error_count error(s) so far)");
	}

	$global_test_report->{not_selected_by_tag}->{elements}->{$element_name} = 'not_selected_by_tag';

	return undef;
    }
}


package Heterarch::Test::ExecutionContext;


#
# _prepare_engine() implements the engine for both preparation and
# reparation that are used for test modules and command definitions.
#
# Returns a ref to a string if an error occurs.  The string describes
# the error that occurred.
#

sub prepare_engine
{
    my $self = shift;

    my $executor_element = shift;

    my $description = shift;

    my $previous_result = shift;

    my $result = 'nothing executed';

    # either execute regular perl code

    #! in the case of a docker based harness, the code that was
    #! inserted to create the docker image and container, will be
    #! executed here.

    if (ref $executor_element eq 'CODE')
    {
	# print STDERR "sub _prepare_engine(): CODE\n";

	$result = &$executor_element($previous_result);
    }

    # ... or instantiate the object that will do the preparation

    #! this is used to instantiate a web browser and initialize it.

    elsif (exists $executor_element->{class})
    {
	# print STDERR "sub _prepare_engine(): class\n";

	# instantiate the object

	my $class = $executor_element->{class};

	my $filename = $class . ".pm";

	$filename =~ s(::)(/)g;

	require $filename;

	my $executor_element_object = eval "$class->new()";

	# apply all the methods and collect the results

	$result = [];

	my $applicators = $executor_element->{applicators};

	foreach my $applicator (@$applicators)
	{
	    my $method = $applicator->{method};

	    my $arguments = $applicator->{arguments};

	    my $applicator_result = $executor_element_object->$method($arguments);

	    if (ref $applicator_result eq 'SCALAR')
	    {
		$result = \ "Error: $description failed ($$applicator_result)";

		last;
	    }

	    push @$result, $applicator_result;
	}
    }

    # or execute an array of system shell commands

    elsif (exists $executor_element->{system_commands})
    {
	# print STDERR "sub _prepare_engine(): system_commands\n";

	my $system_commands = $executor_element->{system_commands};

	if (ref $system_commands eq 'ARRAY')
	{
	    foreach my $system_command (@$system_commands)
	    {
		system $system_command;

		if ($? ne 0)
		{
		    $result = \ "Error: $description failed ($system_command)";

		    last;
		}
	    }
	}
    }

    # return result

    return $result;
}


#t to be replaced with instance variables

our $command_definition_counter_per_module = 0;
our $command_definition_counter_global = 0;

our $command_test_counter_per_command_definition = 0;
our $command_test_counter_per_module = 0;
our $command_test_counter_global = 0;

our $module_counter_global = 0;


sub _maintain_counters
{
    my $self = shift;

    my $current = shift;

    my $module_definition = $current->{current_module_definition};

    my $command_definition = $current->{current_command_definition};

    my $command_test = $current->{current_command_test};

    if (defined $command_test)
    {
	$command_test_counter_global++;
	$command_test_counter_per_module++;
	$command_test_counter_per_command_definition++;
    }
    elsif (defined $command_definition)
    {
	$command_definition_counter_global++;
	$command_definition_counter_per_module++;

	$command_test_counter_per_command_definition = 0;
    }
    elsif (defined $module_definition)
    {
	$module_counter_global++;

	$command_definition_counter_per_module = 0;
	$command_test_counter_per_module = 0;
    }
    else
    {
	die "$0: internal error when _maintain_counters(): nothing left to count\n";
    }
}


sub _path_add_harness_list_to_current
{
    my $self = shift;

    my $harness_list = shift;

    my $current = $self->_path_get_current();

    $current->{current_harness_list} = $harness_list;
}


sub _path_get_current
{
    my $self = shift;

    my $path = $self->{path};

    my $current = $path->[$#$path];

    return $current;
}


sub _path_pop_current
{
    my $self = shift;

    my $path = $self->{path};

    my $result = pop @$path;

    return $result;
}


sub _path_push_current
{
    my $self = shift;

    my $current = shift;

    my $path = $self->{path};

    push @$path, $current;

    $self->_maintain_counters($current);

}


sub _push_preparation_result
{
    my $self = shift;

    my $preparation_result = shift;

    my $path = $self->{preparation_result};

    push @$path, $preparation_result;

}


sub _pop_preparation_result
{
    my $self = shift;

    my $path = $self->{preparation_result};

    my $result = pop @$path;

    return $result;
}


sub _top_preparation_result
{
    my $self = shift;

    my $path = $self->{preparation_result};

    my $result = $path->[$#$path];

    return $result;
}


sub ec_construct_command_line
{
    my $self = shift;

    my $command_definition = shift;

    my $harness = $self->harness_current();

    if (defined $option_debugging
	and $option_debugging eq 'harnessing')
    {
	use YAML;

	my $current = $self->_path_get_current();

	my $harness_list = $current->{current_harness_list};

	print Dump(
		   {
		    option_debugging => {
					 harness_current => $harness,
					 harness_list => $harness_list,
					},
		   },
		  );
    }

    my $command_line;

#     foreach my $harness_identifier (@$global_active_harness_identifiers)
    {
# 	my $harness = $global_harnessing_identifiers->{$harness_identifier};

	# if there is an active harness

	if ($harness)
	{
	    # tell it to construct a command line

	    #! this command line can either have a command and arguments or have the flag 'internal'.

	    # $DB::single = 1;

	    $command_line = $harness->hs_construct_command_line($command_definition, $self);
	}

	# without an active harness

	else
	{
	    # retrieve the shell command and its arguments

	    my $command_prefix = [];

	    $command_line = $command_definition->cd_construct_command_line($command_prefix, $self);
	}
    }

    return $command_line;
}


sub ec_end
{
    my $self = shift;

    my $module_definition = shift;

    my $command_definition = shift;

    my $command_test = shift;

    #! note: reparation_error has already been processed

    my $reparation_error = $self->_reparation();

    #t I have the impression this should be implemented through an
    #t method call rather than an if clause, see also identical comments.

    if ($global_test_report->{output_format} eq 'executor')
    {
	my $message_level;

	my $module_name = $module_definition->{name};

	my $description;

	my $name;

	if (defined $command_test)
	{
	    $message_level = "message_test";

	    $description = $command_test->{description} ? "*** Test: $command_test->{description}" : "(Warning: no description of this command_test when ending the execution context)";

	    $name = "";
	}
	elsif (defined $command_definition)
	{
	    $message_level = "message_command";

	    $description = $command_definition->{description} ? "command $command_definition->{description}" : "(Warning: no description of this command_definition when ending the execution context)";

	    $name = " ($command_definition->{command})";
	}
	else
	{
	    $message_level = "message_module";

	    $description = "module $module_definition->{description}";

	    $name = " ($module_definition->{name})";
	}

	my $reporter = $self->{reporter};

	if (defined $command_test)
	{
	    # no output here, the test output is emitted in ->ec_examine()
	}
	else
	{
	    $reporter->report_message_end($message_level, "End of tests of $description
Total of $global_test_report->{global}->{test_counters}->{current}->{command_test} test(s) (encountered $global_error_count error(s) so far)");
	}
    }

    $self->_path_pop_current();
}


sub ec_variable_actions_pop
{
    my $self = shift;

    if (not exists $self->{variable_actions})
    {
	$self->{variable_actions} = [];
    }

    my $variable_actions = $self->{variable_actions};

    my $variable_action = pop @$variable_actions;

    return $variable_action;
}


sub ec_variable_actions_push
{
    my $self = shift;

    my $new_variable_actions = shift;

    if (not exists $self->{variable_actions})
    {
	$self->{variable_actions} = [];
    }

    my $variable_actions = $self->{variable_actions};

    push @$variable_actions, $new_variable_actions;
}


sub get_command_definition
{
    my $self = shift;

    my $current = $self->_path_get_current();

    my $command_definition = $current->{current_command_definition};

    return $command_definition;
}


sub get_command_test
{
    my $self = shift;

    my $current = $self->_path_get_current();

    my $command_test = $current->{current_command_test};

    return $command_test;
}


sub get_context_path
{
    my $self = shift;

    my $decorated_context_path = shift;

    # add module counter and identifier

    my $context_path_separator = "___/___";

    my $result;

    if ($decorated_context_path)
    {
	$result = $self->get_module_definition_counter();

	$result .= $context_path_separator;

	$result .= $self->get_module_definition()->{name};

	# add command_definition counter and identifier

	my $command_definition = $self->get_command_definition();

	if (defined $command_definition)
	{
	    $result .= $context_path_separator;

	    $result .= $self->get_counter_command_definition_per_module();

	    $result .= $context_path_separator;

	    # the command_definition identifier is based on the system
	    # shell command that is used to perform the tests

	    #t Depending on the command definition in the test module,
	    #t this may expand to a command with or without its arguments,
	    #t with or without any spaces.

	    if (exists $command_definition->{command})
	    {
		$result .= $command_definition->{command};
	    }
	    else
	    {
		$result .= "NONE";
	    }

	    # add command_test counter and identifier

	    my $command_test = $self->get_command_test();

	    if (defined $command_test)
	    {
		$result .= $context_path_separator;

		$result .= $self->get_counter_command_test_per_command_definition();

		$result .= $context_path_separator;

		# the command_test identifier is based on the write clause

		if (exists $command_test->{write}
		    and defined $command_test->{write})
		{
		    $result .= $command_test->{write};
		}
		else
		{
		    $result .= "NONE";
		}
	    }
	}
    }
    else
    {
	$result = $self->get_module_definition_counter();

	$result .= $context_path_separator;

	my $command_definition = $self->get_command_definition();

	if (defined $command_definition)
	{
	    $result .= $self->get_counter_command_definition_per_module();
	}
	else
	{
	    $result .= "-1";
	}

	$result .= $context_path_separator;

	my $command_test = $self->get_command_test();

	if (defined $command_test)
	{
	    $result .= $self->get_counter_command_test_per_command_definition();
	}
	else
	{
	    $result .= "-1";
	}
    }

    # return result

    return $result;
}


sub get_counter_command_definition_per_module
{
    my $self = shift;

    #t to be replaced with instance variables

    return $command_definition_counter_per_module;
}


sub get_counter_command_test_counter
{
    return $command_test_counter_global;
}


sub get_counter_command_test_per_command_definition
{
    my $self = shift;

    #t to be replaced with instance variables

    return $command_test_counter_per_command_definition;
}


sub get_module_definition
{
    my $self = shift;

    my $current = $self->_path_get_current();

    my $module_definition = $current->{current_module_definition};

    return $module_definition;
}


sub get_module_definition_counter
{
    my $self = shift;

    #t to be replaced with instance variables

    return $module_counter_global;
}


my $global_active_harness_identifiers = [];

my $global_harnessing_identifiers = {};


sub harness_current
{
    my $self = shift;

    if (defined $option_debugging
	and $option_debugging eq 'harnessing')
    {
	use YAML;

	print Dump(
		   {
		    option_debugging => {
					 global_active_harness_identifiers => $global_active_harness_identifiers,
					 global_harnessing_identifiers => $global_harnessing_identifiers,
					},
		   },
		  );
    }

    my $active_harness_identifier = $self->harness_identifier_current();

    my $active_harness;

    if (defined $active_harness_identifier)
    {
	$active_harness = $global_harnessing_identifiers->{$active_harness_identifier};
    }

    return $active_harness;
}


sub harness_identifier_current
{
    my $identifier = $global_active_harness_identifiers->[$#$global_active_harness_identifiers];

    return $identifier;
}


sub harness_identifier_pop
{
    my $identifier = pop @$global_active_harness_identifiers;

    return $identifier;
}


sub harness_identifier_push
{
    my $self = shift;

    my $identifier = shift;

    push @$global_active_harness_identifiers, $identifier;
}


sub has_error_flag
{
    my $self = shift;

    my $module_definition = shift;

    my $command_definition = shift;

    my $command_test = shift;

    my $module_name = $module_definition->{name};

    my $active_element
	= (defined $command_test
	   ? $command_test
	   : (defined $command_definition
	      ? $command_definition
	      : $module_definition));

    my $error = $active_element->{error};

    my $description = $active_element->{description};

    if ($error)
    {
	my $reporter = $self->{reporter};

	$reporter->report_error_add
		(
		 {
		  context_path => $self->get_context_path(),
		  description => $description,
		  error => "this test was tagged with the error flag",
		  module_name => $module_name,
		  subdescription => $error,
		 },
		);

	return 1;
    }
    else
    {
	return 0;
    }
}


sub is_disabled
{
    my $self = shift;

    my $module_definition = shift;

    my $command_definition = shift;

    my $command_test = shift;

    my $active_element
	= (defined $command_test
	   ? $command_test
	   : (defined $command_definition
	      ? $command_definition
	      : $module_definition));

    my $disabled = $active_element->{disabled};

    if ($disabled)
    {
	my $description = $active_element->{description};

	my $report_key
	    = (defined $command_test
	       ? "command_tests"
	       : (defined $command_definition
		  ? "command_definitions"
		  : "modules"));

	my $module_name = $module_definition->{name};

	$global_test_report->{disabled}->{$report_key}->{$module_name}->{$description} = $disabled;

	if ($global_test_report->{output_format} eq 'executor')
	{
	    my $reporter = $self->{reporter};

	    $reporter->report_message_info("message_info", "Tests of $description are disabled ($disabled)
Total of $global_test_report->{global}->{test_counters}->{current}->{command_test} test(s) (encountered $global_error_count error(s) so far)");
	}

	return 1;
    }
    else
    {
	return 0;
    }
}


sub ec_is_selected
{
    my $self = shift;

    my $module_definition = shift;

    my $command_definition = shift;

    my $command_test = shift;

    my $reporter = $self->{reporter};

    my $module_name = $module_definition->{name};

    my $active_element
	= (defined $command_test
	   ? $command_test
	   : (defined $command_definition
	      ? $command_definition
	      : $module_definition));

    my $result = $active_element->is_selected($reporter);

    return $result;
}


our $harnessing_count = 0;


sub _preparation
{
    my $self = shift;

    my $current = $self->_path_get_current();

    my $module_definition = $current->{current_module_definition};

    my $command_definition = $current->{current_command_definition};

    my $command_test = $current->{current_command_test};

    # command_tests with a harnessing clause are unsupported, they
    # cannot be 'prepared'.

    if ($command_test)
    {
	return undef;
    }

    my $module_name = $module_definition->{name};

    if ($command_definition)
    {
	if (exists $command_definition->{preparation}
	    and exists $command_definition->{harnessing})
	{
	    die "$0: command_definition ($command_definition->{description}) has both a preparation and harnessing clause\n";
	}
    }
    else
    {
	if (exists $module_definition->{preparation}
	    and exists $module_definition->{harnessing})
	{
	    die "$0: module_definition ($module_definition->{description}) has both a preparation and harnessing clause\n";
	}
    }

    my $active_element
	= (defined $command_test
	   ? $command_test
	   : (defined $command_definition
	      ? $command_definition
	      : $module_definition));

    # convert the old format preparation / reparation to the new format of harnessing

    if (not exists $active_element->{harnessing})
    {
	if (exists $active_element->{preparation})
	{
	    $active_element->{harnessing}->{preparation} = $active_element->{preparation};

	    delete $active_element->{preparation};
	}

	if (exists $active_element->{reparation})
	{
	    $active_element->{harnessing}->{reparation} = $active_element->{reparation};

	    delete $active_element->{reparation};
	}
    }

    # process the harnessing preparation clause

    my $harnessing = $active_element->{harnessing};

    use Clone 'clone';

    my $preparation = clone($harnessing->{preparation});

    my $preparation_result;

    my $all_preparation_harnesses = [];

    $self->_path_add_harness_list_to_current($all_preparation_harnesses);

    # if we are really running tests

    #t I have the impression this should be implemented through an
    #t method call rather than an if clause, see also identical comments.

    if ($global_test_report->{output_format} eq 'executor')
    {
	my $harnessing_class;
	my $harnessing_identifier;

	# if there is a docker container preparation

	if (exists $harnessing->{class})
	{
	    # create the harness for this identifier

	    $harnessing_class = $harnessing->{class};

	    $harnessing_identifier = $harnessing_class->{identifier};
	}

	# old style preparation does not have a valid harnessing clause, so create one

	elsif (defined $preparation)
	{
	    $harnessing_count++;

	    my $reparation = clone($harnessing->{reparation});

	    $harnessing_class
		= {
		   preparation => $preparation,
		   reparation => $reparation,
		   type => "Heterarch::Test::ExecutionContext::Harness::Builtin::Preparer",
		  };

	    $harnessing_identifier = "with_preparer_$harnessing_count";
	}
	else
	{
	    $harnessing_count++;

	    $harnessing_class
		= {
		   type => "Heterarch::Test::ExecutionContext::Harness::Builtin::Empty",
		  };

	    $harnessing_identifier = "empty_harness_$harnessing_count";
	}

	my $harness = Heterarch::Test::ExecutionContext::Harness::create_or_fetch($harnessing_class, $harnessing_identifier);

	# add it to the list of preparation harnesses

	push @$all_preparation_harnesses, $harness;

	# while there are preparation clauses

	foreach my $preparation_harness (@$all_preparation_harnesses)
	{
	    #t when no command entry is present: Use of uninitialized value in concatenation (.) or string at /usr/local/bin/neurospaces_harness line 4435.

	    my $preparation_name
		= ($command_definition
		   ? "command '$command_definition->{command}'"
		   : "module '$module_definition->{name}'");

	    # execute the preparation clause

	    $preparation_result = $preparation_harness->hs_preparer($self, $preparation_name);

	    # if the preparer returned an error string

	    my $preparation_error;

	    if (ref $preparation_result eq 'SCALAR')
	    {
		# obtain the error string

		$preparation_error = $$preparation_result;

		$preparation_harness->{preparation_error} = $preparation_error;
	    }

	    # process errors

	    if ($preparation_error)
	    {
		my $module_name = $module_definition->{name};

		my $subdescription
		    = ($command_definition
		       ? $command_definition->{description}
		       : $module_definition->{description});

		my $reporter = $self->{reporter};

		$reporter->report_error_add
			(
			 {
			  context_path => $self->get_context_path(),
			  description => $preparation_name,
			  error => $preparation_error,
			  module_name => $module_name,
			  subdescription => $subdescription,
			 },
			);

		$preparation_harness->{state} = 'In error ($preparation_error)';
	    }
	    else
	    {
		$preparation_harness->{state} = 'Executed';
	    }
	}
    }

    # return result

    return $preparation_result;
}


sub new
{
    my $package = shift;

    my $model_library_shas = shift;

    my $expected_test_total = shift;

    $global_console_window_configuration->{progress_bar}->{formatter_options}->{total} = $expected_test_total;

    # for an unknown total testing of the progress bar
    # $global_console_window_configuration->{progress_bar}->{formatter_options}->{total} = 0;

    my $reporter_class = $global_reporter_classes->{$option_console_type}->{class};

    my $reporter
	= $reporter_class->new(
			       {
				configuration => $global_console_window_configuration,
				expected_total => $expected_test_total,
				fd_output => $global_fd_output,
			       },
			      );

    my $self
	= {
	   path => [],
	   preparation_result => [],
	   reporter => $reporter,
	  };

    bless $self, $package;

    $self->{external_model_libraries_shas} = $model_library_shas;

    $reporter->start();

    return $self;
}


sub _reparation
{
    my $self = shift;

    my $current = $self->_path_get_current();

    my $module_definition = $current->{current_module_definition};

    my $command_definition = $current->{current_command_definition};

    my $command_test = $current->{current_command_test};

    my $all_reparation_harnesses = $current->{current_harness_list};

    my $preparation_result = $self->_pop_preparation_result();

    # command_tests with a harnessing clause are unsupported

    if ($command_test)
    {
	return undef;
    }

    my $active_element
	= (defined $command_test
	   ? $command_test
	   : (defined $command_definition
	      ? $command_definition
	      : $module_definition));

    my $module_name = $module_definition->{name};

    # process the harnessing reparation clause

    my $harnessing
	= ($command_definition
	   ? $command_definition->{harnessing}
	   : $module_definition->{harnessing});

    use Clone 'clone';

    my $reparation = clone($harnessing->{reparation});

    my $reparation_error;

    #t I have the impression this should be implemented through an
    #t method call rather than an if clause, see also identical comments.

    if ($global_test_report->{output_format} eq 'executor')
    {
	foreach my $reparation_harness (@$all_reparation_harnesses)
	{
	    my $reference = ref $reparation_harness;

	    # execute the preparation clause

	    my $reparation_name
		= ($command_definition
		   ? "command '$command_definition->{command}'"
		   : "module '$module_definition->{name}'");

	    $reparation_error = $reparation_harness->hs_reparer($self, $reparation_name, $preparation_result);

	    # process errors

	    if ($reparation_error)
	    {
		my $module_name = $module_definition->{name};

		my $reparation_description = $reparation->{description};

		my $subdescription
		    = ($command_definition
		       ? $command_definition->{description}
		       : $module_definition->{description});

		my $reporter = $self->{reporter};

		$reporter->report_error_add
			(
			 {
			  context_path => $self->get_context_path(),
			  description => $reparation_description,
			  error => $reparation_error,
			  module_name => $module_name,
			  subdescription => $subdescription,
			 },
			);
	    }
	}
    }

    return $reparation_error;
}


#
# sub ec_examine
#
# Apply selection criteria to the current context.
# Prepare the test environment by execution of the preparation clause.
#
# This is called for a module definition, a command definition and a
# test.
#

sub ec_examine
{
    my $self = shift;

    my $module_definition = shift;

    my $command_definition = shift;

    my $command_test = shift;

    # set default result: everything ok

    my $result;

    # if this element is selected by active options

    if (not $self->ec_is_selected($module_definition, $command_definition, $command_test))
    {
	return "not selected";
    }

    # if this test is disabled

    if ($self->is_disabled($module_definition, $command_definition, $command_test))
    {
	# return to skip it

	return "is disbled";
    }

    # if this test has been flagged with an error

    #t when output pdf or html the error flag message should be
    #t included in the output but error counting should be skipped

    if ($self->has_error_flag($module_definition, $command_definition, $command_test))
    {
	# return to skip it

	return "has the error flag";;
    }

    # give diagnostics

    #t I have the impression this should be implemented through an
    #t method call rather than an if clause, see also identical comments.

    if ($global_test_report->{output_format} eq 'executor')
    {
	my $message_level;

	my $comment;

	my $description;

	my $name;

	if (defined $command_test)
	{
	    $message_level = "message_test";

	    $comment = $command_test->{comment};

	    $description = $command_test->{description} ? "*** Test: $command_test->{description}" : "(Warning: no description of this command_test when examining the execution context)";

	    $name = "";
	}
	elsif (defined $command_definition)
	{
	    $message_level = "message_command";

	    $comment = $command_definition->{comment};

	    $description = $command_definition->{description} ? "command $command_definition->{description}" : "(Warning: no description of this command_definition when examining the execution context)";

	    $name = " ($command_definition->{command})";
	}
	else
	{
	    $message_level = "message_module";

	    $comment = $module_definition->{comment};

	    $description = "module $module_definition->{description}";

	    $name = " ($module_definition->{name})";
	}

	my $reporter = $self->{reporter};

	if (defined $command_test)
	{
	    $reporter->report_message("message_test", $description);
	}
	else
	{
	    $reporter->report_message_start($message_level, "Running tests of $description$name");
	}

	if ($comment)
	{
	    $reporter->report_message("message_details", "*** Comment: $comment");
	}
    }

    # update the path of execution

    $self->_path_push_current
	(
	 {
	  current_module_definition => $module_definition,
	  current_command_definition => $command_definition,
	  current_command_test => $command_test,
	 },
	);

    # prepare the test environment

    my $preparation_result = $self->_preparation();

    $self->_push_preparation_result($preparation_result);

    # return result: should be undef here

    return $result;
}


sub ec_terminate
{
    my $self = shift;

    my $path = $self->{path};

    my $reporter = $self->{reporter};

    if (scalar @$path)
    {
	my $module_definition = $self->get_module_definition();

	my $description = "module $module_definition->{description}";

	my $module_name = $module_definition->{name};

	$reporter->report_error_add
	    (
	     {
	      context_path => $self->get_context_path(),
	      description => "execution context invalid",
	      error => "left over elements in the execution context after it was terminated",
	      module_name => $module_name,
	     },
	    );
    }

    # end the console reporting

    $reporter->end();
}


sub wait
{
    my $self = shift;

    my $wait = shift;

    # wait

    if ($wait)
    {
	my $reporter = $self->{reporter};

	$reporter->report_message("message_details", "*** Wait: $wait seconds\n");

	select(undef, undef, undef, $wait);
    }
}


package Heterarch::Test::ExecutionContext::Harness;


# return a harness object.
#
# The object is identified by the harnessing_identifier which is
# externally generated and here given as an argument.
#
# It is fetched from a cache or created if it does not exist yet.
#

sub create_or_fetch
{
    my $harnessing_class = shift;

    my $harnessing_identifier = shift;

    my $result;

    # $DB::single = 1;

    if (defined $option_debugging
	and $option_debugging eq 'harnessing')
    {
	use YAML;

	print Dump(
		   {
		    create_or_fetch => {
					global_active_harness_identifiers => $global_active_harness_identifiers,
					global_harnessing_identifiers => $global_harnessing_identifiers,
					harnessing_identifier => $harnessing_identifier,
				       },
		   },
		  );
    }

    # if this harnessing_identifier was not yet created

    if (not exists $global_harnessing_identifiers->{$harnessing_identifier})
    {
	my $harnessing_type = $harnessing_class->{type};

	my $known_harnessing_types
	    = {
	       'Heterarch::Test::ExecutionContext::Harness::Builtin::Empty' => 'builtin',
	       'Heterarch::Test::ExecutionContext::Harness::Builtin::Preparer' => 'builtin',
	       'Heterarch::Test::ExecutionContext::Harness::Docker' => 'builtin',
	       'Heterarch::Test::ExecutionContext::Harness::Docker::Image' => 'builtin',
	      };

	if (exists $known_harnessing_types->{$harnessing_type}
	    and $known_harnessing_types->{$harnessing_type})
	{
	    my $harness = $harnessing_type->new($harnessing_class, $harnessing_identifier);

	    if (not $harness)
	    {
		die "$0: *** Error: Cannot instantiate harnessing_identifier ($harnessing_identifier) with type ($harnessing_type).";
	    }

	    $global_harnessing_identifiers->{$harnessing_identifier} = $harness;
	}
	else
	{
	    die "$0: *** Error: Cannot instantiate harnessing_identifier ($harnessing_identifier) with type ($harnessing_type).";
	}
    }

    # the harnessing identifier already existed or has now been created

    $result = $global_harnessing_identifiers->{$harnessing_identifier};

    # return the result

    return $result;
}


# sub hs_construct_command_line
# {
#     my $self = shift;

#     my $command_definition = shift;

#     my $execution_context = shift;

# #     my $command_prefix = $self->_generate_command_prefix($command_definition, $execution_context);

#     # retrieve the shell command and its arguments

#     my ($command, $arguments) = $command_definition->cd_construct_command_line();

#     # return result

#     return ($command, $arguments);
# }


package Heterarch::Test::ExecutionContext::Harness::Builtin::Empty;

our @ISA = ("Heterarch::Test::ExecutionContext::Harness");


sub hs_preparer
{
    my $self = shift;

    my $execution_context = shift;

    my $preparation_name = shift;

    # return no errors

    my $preparation_result = '';

    $self->{preparation_result} = $preparation_result;

    # # make the empty harness available by pushing it

    # my $harness_class = $self->{class};

    # my $harnessing_identifier = $harness_class->{identifier};

    # $execution_context->harness_identifier_push($harnessing_identifier);

    return $preparation_result;
}


sub hs_reparer
{
    my $self = shift;

    my $execution_context = shift;

    my $preparation_name = shift;

    my $preparation_result = shift;

    # my $harnessing_identifier = $execution_context->harness_identifier_pop();

    # my $harness_class = $self->{class};

    # if ($harnessing_identifier ne $harness_class->{identifier})
    # {
    # 	die "$0: *** Error: package Heterarch::Test::ExecutionContext::Harness::Builtin::Empty pops a harnessing_identifier ($harnessing_identifier) that is different from what it previously pushed ($harness_class->{identifier}).";
    # }

    # return no errors

    return '';
}


sub new
{
    my $class = shift;

    my $harnessing_class = shift;

    my $harnessing_identifier = shift;

    use Clone 'clone';

    my $harness
	= {
	   class => clone($harnessing_class),
	   identifier => $harnessing_identifier,
	   preparation => {
			   description => "create an empty harness",
			  },
	   reparation => {
			  description => "leave the empty harness",
			 },
	   state => 'Instantiated',
	  };

    bless $harness;

    return $harness;
}


package Heterarch::Test::ExecutionContext::Harness::Builtin::Preparer;

our @ISA = ("Heterarch::Test::ExecutionContext::Harness");


sub hs_preparer
{
    my $self = shift;

    my $execution_context = shift;

    my $preparation_name = shift;

    my $preparation = $self->{preparation};

    # give diagnostics

    my $reporter = $execution_context->{reporter};

    $reporter->report_message("message_harnessing", "*** Preparing $preparation_name ($preparation->{description})");

    # execute the preparation clause

    my $preparer = $preparation->{preparer};

    my $preparation_result = $execution_context->prepare_engine($preparer, 'preparation');

    $self->{preparation_result} = $preparation_result;

    # make the harness available by pushing it

    my $harness_class = $self->{class};

    my $harnessing_identifier = $harness_class->{identifier};

    $execution_context->harness_identifier_push($harnessing_identifier);

    return $preparation_result;
}


sub hs_reparer
{
    my $self = shift;

    my $execution_context = shift;

    my $preparation_name = shift;

    my $preparation = $self->{preparation};

    # give diagnostics

    my $reparation = $self->{reparation};

    my $reparation_description = $reparation->{description};

    my $reporter = $execution_context->{reporter};

    $reporter->report_message("message_harnessing", "*** Reparing ($reparation_description)");

    # execute the reparation clause

    my $reparer = $reparation->{reparer};

    my $reparation_error = $execution_context->prepare_engine($reparer, 'reparation', $self->{preparation_result});

    # remove the harness identifier from the active harnesses

    my $harnessing_identifier = $execution_context->harness_identifier_pop();

    my $harness_class = $self->{class};

    #t how can any of these not be defined?

    if ((defined $harnessing_identifier)
	and (defined $harness_class->{identifier})
	and $harnessing_identifier ne $harness_class->{identifier})
    {
	die "$0: *** Error: package Heterarch::Test::ExecutionContext::Harness::Builtin::Preparer pops a harnessing_identifier ($harnessing_identifier) that is different from what it previously pushed ($harness_class->{identifier}).";
    }

    return $reparation_error;
}


sub new
{
    my $class = shift;

    my $harnessing_class = shift;

    my $harnessing_identifier = shift;

    use Clone 'clone';

    my $harness
	= {
	   # provide defaults

	   identifier => $harnessing_identifier,
	   preparation => {
			   description => "create a harness with preparer code",
			  },
	   reparation => {
			  description => "leave the harness with reparer code",
			 },
	   state => 'Instantiated',

	   # overwrite the defaults with what was given

	   %{ clone($harnessing_class) },
	  };

    bless $harness;

    return $harness;
}


package Heterarch::Test::ExecutionContext::Harness::Docker;

# this package assumes that a docker image must be built from a
# dockerfile with pathname $self->{class}->{docker}->{dockerfile}.


our @ISA = ("Heterarch::Test::ExecutionContext::Harness");


our $docker_snapshot_count = 1;

our $docker_command_no_redirect = 'docker';
our $docker_command_with_redirect = "$docker_command_no_redirect >/dev/null 2>&1 ";

our $docker_command_selected;

our $docker_network_created;

our $docker_network_exists;


sub _docker_compute_next_ip_address
{
    my $network_definition = shift;

    my $occupied_ip_addresses = shift || [];

    use Net::IP;

    $occupied_ip_addresses
	= {
	   map
	   {
	       my $ip_with_mask = $_;

	       my $ip_without_mask = $ip_with_mask;

	       $ip_without_mask =~ s(/.*$)();

	       $ip_without_mask => $_;
	   }
	   @$occupied_ip_addresses,
	  };

    my $network_name = $network_definition->{name};

    my $network_subnet = $network_definition->{subnet};

    my $net_ip_network = Net::IP->new($network_subnet);

    my $first_ip = $net_ip_network->ip();

    my $last_ip = $net_ip_network->last_ip();

    my $ip_iterator = Net::IP->new("$first_ip - $last_ip");

    my $result;

    #! Docker likes to use some of the early addresses without these
    #! being easily accessible from a docker inspect.
    #!
    #! Let's just skip a few (ten).

    # note: skip the first ip, it is the network address, not a device address

    ++$ip_iterator;
    ++$ip_iterator;
    ++$ip_iterator;
    ++$ip_iterator;
    ++$ip_iterator;
    ++$ip_iterator;
    ++$ip_iterator;
    ++$ip_iterator;
    ++$ip_iterator;
    ++$ip_iterator;
    ++$ip_iterator;

    while (++$ip_iterator)
    {
	my $ip = $ip_iterator->ip();

	if (not exists $occupied_ip_addresses->{$ip})
	{
	    $result = $ip;

	    last;
	}
    }

    return $result;
}


sub _docker_preparer
{
    my $self = shift;

    #! for consistency with the reparer code, should always be undef

    my $previous_result = shift;

    # build the container

    my $harness_class = $self->{class};

    if (exists $harness_class->{build})
    {
	my $build = $harness_class->{build};

	system "$build";

	if ($?)
	{
	    return \ '_docker_preparer build command failed';
	}
    }
    elsif (exists $harness_class->{docker}
	   and exists $harness_class->{docker}->{dockerfile}
	   and exists $harness_class->{docker}->{name_image})
    {
	my $dockerfile = $harness_class->{docker}->{dockerfile};

	my $name_image = $harness_class->{docker}->{name_image};

	system "$docker_command_selected image prune -f";

	if ($?)
	{
	    return \ '_docker_preparer image prune failed';
	}

	system "$docker_command_selected build --tag $name_image --file $dockerfile .";

	if ($?)
	{
	    return \ '_docker_preparer build and tag failed';
	}
    }
    else
    {
	if ($?)
	{
	    return \ '_docker_preparer did not find a build method and failed';
	}

    }

    # try to stop and remove a previous container of the same name

    my $docker_network
	= {
	   # containers => {
	   # 		  default => "172.18.0.22",
	   # 		 },
	   name => "harness_network",
	   subnet => "172.18.0.0/16",
	  };

    my $name_container = $harness_class->{docker}->{name_container};

    my $ip_address_container = exists $harness_class->{ip_address_container} ? $harness_class->{ip_address_container} : "dynamic"; # "172.18.0.22";

    if ($ip_address_container eq 'dynamic')
    {
	# my $assigned_ip_addresses = `docker inspect '$network_name' | jq -r 'map(.Containers[].IPv4Address)[]'`;

	my $assigned_ip_addresses_containers
	    = [
	       map
	       {
		   chomp; $_;
	       }
	       sort
	       `docker inspect '$docker_network->{name}' | jq -r 'map(.Containers[].IPv4Address)[]'`,
	      ];

	my $assigned_ip_addresses_gateway
	    = [
	       map
	       {
		   chomp; $_;
	       }
	       sort
	       `docker inspect bridge | jq -r 'map(.IPAM.Config[].Gateway)[]'`,
	      ];

	$ip_address_container = _docker_compute_next_ip_address(
								$docker_network,
								[
								 @$assigned_ip_addresses_containers,
								 @$assigned_ip_addresses_gateway,
								]
							       );
    }

    system "$docker_command_selected container stop -t 3 $name_container";
    system "$docker_command_selected container rm $name_container";

    # see: https://stackoverflow.com/questions/27937185/assign-static-ip-to-docker-container

    my $docker_ip_address = $ip_address_container;

    my $assigned_ip_network = `docker inspect harness_network | jq -r 'map(.IPAM.Config[].Subnet)[]'`;

    chomp $assigned_ip_network;

    if ($assigned_ip_network eq $docker_network->{subnet})
    {
	$docker_network_exists = "detected from `docker inspect harness_network | jq -r 'map(.IPAM.Config[].Subnet)[]'`";
    }

    if (!$docker_network_created
        && !$docker_network_exists)
    {
	# system "yes | docker network prune";

	system "docker network create --subnet=$docker_network->{subnet} $docker_network->{name}";

	# print "docker network: $!, $?\n";

	$docker_network_created = 'yes';
    }

    # start the built container

    my $name_image = $harness_class->{docker}->{name_image};

    # system "$docker_command_selected run --net $docker_network->{name} --ip $docker_ip_address -d -t --name $name_container $name_image";

    system "$docker_command_selected run --net $docker_network->{name} -d -t --name $name_container $name_image";

    my $this_ip_address = `docker inspect '$name_container' | jq -r 'map(.NetworkSettings.Networks.harness_network.IPAddress)[]'`;

    chomp $this_ip_address;

    my $variable_actions
	= {
	   __DOCKER_HOST_IP_ADDRESS__ => $this_ip_address,
	  };

    # return no errors

    #! the sub should return a user role object that
    #! has the interface to generate the necessary prefix
    #! for the command that is executed for the test.

    return {
	    variable_actions => $variable_actions,
	    docker_preparer_result => '_docker_preparer: executed',
	   };
}


sub _docker_reparer
{
    my $self = shift;

    my $preparation_result = shift;

    my $harness_class = $self->{class};

    my $name_container = $harness_class->{docker}->{name_container};

    # return no errors

    return '';
}


sub _generate_command_prefix
{
    my $self = shift;

    my $command_definition = shift;

    my $execution_context = shift;

    if (defined $option_debugging
	and $option_debugging eq 'generate_command_prefix')
    {
	use YAML;

	print Dump(
		   {
		    option_debugging => {
					 harness => $self,
					},
		   },
		  );
    }

    my $prefix_docker
	= [
	   $docker_command_no_redirect,
	   'exec',
	   '-it',
	  ];

    my $user
	= (exists $command_definition->{command_user}
	   ? $command_definition->{command_user}
	   : $self->{class}->{docker}->{default_user});

    my $prefix_user
	= [
	   '--user',
	   $user,
	  ];

    my $container_name = $self->{class}->{docker}->{name_container};

    my $prefix_command
	= [
	   'bash',
	   '-ic',
	  ];

    my $command_prefix = [ @$prefix_docker, @$prefix_user, $container_name, @$prefix_command, ];

    return $command_prefix;
}


sub _docker_snapshot
{
    my $self = shift;

    my $command_line = shift;

    my $option_snapshot_container_name;
    my $option_snapshot_image_name;

    our $snapshot_options
      = {
	 "snapshot-container-name=s" => \$option_snapshot_container_name,
	 "snapshot-image-name=s" => \$option_snapshot_image_name,
	};

    use Getopt::Long qw(GetOptionsFromArray);;

    my $result = GetOptionsFromArray($command_line->{arguments}, %$snapshot_options);

    if (!$result)
    {
        die "$0: *** Error in option processing (docker-snapshot) (--snapshot-container-name, --snapshot-image-name)";
    }

    my $name_container = (defined $option_snapshot_container_name) ? $option_snapshot_container_name : $self->{class}->{docker}->{name_container};

    my $name_image = (defined $option_snapshot_image_name) ? $option_snapshot_image_name : "$self->{class}->{docker}->{name_image}-$docker_snapshot_count";

    # see https://docs.docker.com/reference/cli/docker/container/commit/ for how to expose a port during the commit
    # docker commit --change='CMD ["apachectl", "-DFOREGROUND"]' -c "EXPOSE 80" c3f279d17e0a  svendowideit/testimage:version4

    my $command = "$docker_command_selected commit $name_container $name_image";

    $docker_snapshot_count++;

    my $snapshot_id = `$command`;

    if ($?)
    {
        die "$0: *** Error: docker-snapshot failed (image-name $name_image, container-name $name_container).";
    }

    return $snapshot_id;
}


sub hs_construct_command_line
{
    my $self = shift;

    my $command_definition = shift;

    my $execution_context = shift;

    my $command_line;

    # if this is a command specific to this harness

    #t when no command entry is present: Use of uninitialized value in pattern match (m//) at /usr/local/bin/neurospaces_harness line 5343.

    if ($command_definition->{command} =~ m'^docker-snapshot')
    {
	# construct the regular command line

	$command_line = $command_definition->cd_construct_command_line();

	# process the command line

	my $snapshot_id = $self->_docker_snapshot($command_line);

	# tell the exeuction context that the command was internally processed

	$command_line
	    = {
	       internal => "_docker_snapshot, result is ($snapshot_id)",
	      };
    }

    # for regular commands

    else
    {
	# generate the prefix for this harness

	my $command_prefix = $self->_generate_command_prefix($command_definition, $execution_context);

	# retrieve the shell command and its arguments

	$command_line = $command_definition->cd_construct_command_line($command_prefix);
    }

    # return result

    return $command_line;
}


sub hs_preparer
{
    my $self = shift;

    my $execution_context = shift;

    my $preparation_name = shift;

    my $preparation = $self->{preparation};

    # give diagnostics

    my $reporter = $execution_context->{reporter};

    $reporter->report_message("message_harnessing", "*** Preparing the Docker Container $preparation_name ($preparation->{description})");

    # execute the preparation clause

    # $DB::single = 1;

    my $preparation_result = $self->_docker_preparer();

    if (ref $preparation_result eq 'SCALAR')
    {
	my $error = $$preparation_result;

	my $module_definition = $execution_context->get_module_definition();

	my $module_name = $module_definition->{name};

	$reporter->report_error_add
	    (
	     {
	      context_path => $execution_context->get_context_path(),
	      description => "Docker container $preparation_name: $error",
	      error => $error,
	      module_name => $module_name,
	     },
	    );

	$preparation_result
	    = {
	       docker_preparer_result => "Error ($$preparation_result)",
	      };
    }

    my $variable_actions = exists $preparation_result->{variable_actions} ? $preparation_result->{variable_actions} : {};

    $execution_context->ec_variable_actions_push($variable_actions);

    # make the docker harness available by pushing it

    my $harness_class = $self->{class};

    my $harnessing_identifier = $harness_class->{identifier};

    $execution_context->harness_identifier_push($harnessing_identifier);

    $self->{preparation_result} = $preparation_result->{docker_preparer_result};

    return $preparation_result->{docker_preparer_result};
}


sub hs_reparer
{
    my $self = shift;

    my $execution_context = shift;

    my $preparation_name = shift;

    my $preparation_result = shift;

    my $preparation = $self->{preparation};

    my $reparation_description = $preparation->{description};

    my $reporter = $execution_context->{reporter};

    $reporter->report_message("message_harnessing", "*** Reparing the Docker Container ($reparation_description)");

    # execute the reparation clause

    # $DB::single = 1;

    my $reparation_error = $self->_docker_reparer($preparation_result);

    if (ref $reparation_error eq 'SCALAR')
    {
	my $error = $$reparation_error;

	my $module_definition = $execution_context->get_module_definition();

	my $module_name = $module_definition->{name};

	$reporter->report_error_add
	    (
	     {
	      context_path => $execution_context->get_context_path(),
	      description => "Docker container $preparation_name: $error",
	      error => $error,
	      module_name => $module_name,
	     },
	    );
    }
    else
    {
	my $variable_actions = $execution_context->ec_variable_actions_pop();
    }

    my $container_name = $self->{class}->{docker}->{name_container};

    $reporter->report_message("message_harnessing", "*** Reparing (The Docker container is still running, you can enter it by executing '$docker_command_no_redirect exec -it $container_name bash'.)");

    # remove the docker harness identifier from the active harnesses

    my $harnessing_identifier = $execution_context->harness_identifier_pop();

    my $harness_class = $self->{class};

    if ($harnessing_identifier ne $harness_class->{identifier})
    {
	die "$0: *** Error: package Heterarch::Test::ExecutionContext::Harness::Docker pops a harnessing_identifier ($harnessing_identifier) that is different from what it previously pushed ($harness_class->{identifier}).";
    }

    return $reparation_error;
}


sub new
{
    my $class = shift;

    my $harnessing_class = shift;

    my $harnessing_identifier = shift;

    # prepare the docker image and container

    use Clone 'clone';

    my $harness
	= {
	   class => clone($harnessing_class),
	   preparation => {
			   description => "create the Docker image and start it as a container for running the tests",
			  },
	   reparation => {
			  description => "leave the Docker container for running manual tests",
			 },
	   state => 'Instantiated',
	  };

    bless $harness;

    return $harness;
}


sub select_docker_command
{
    my $console_type = shift;

    if ($console_type eq 'linear')
    {
	$docker_command_selected = $docker_command_no_redirect;
    }
    else
    {
	$docker_command_selected = $docker_command_with_redirect;
    }
}


package Heterarch::Test::ExecutionContext::Harness::Docker::Image;

# this package assumes the existence of a pre-built image with name
# $self->{class}->{docker}->{name_image}.

our @ISA = ("Heterarch::Test::ExecutionContext::Harness::Docker");


sub _docker_preparer
{
    my $self = shift;

    #! for consistency with the reparer code, should always be undef

    my $previous_result = shift;

    # build the container

    my $harness_class = $self->{class};

    if (exists $harness_class->{build})
    {
	return \ 'The Heterarch::Test::ExecutionContext::Harness::Docker::Image::_docker_preparer\'s build clause must not be used because the image must already have been built.';
    }
    elsif (exists $harness_class->{docker}
	   and exists $harness_class->{docker}->{dockerfile}
	   and exists $harness_class->{docker}->{name_image})
    {
	return \ 'The Heterarch::Test::ExecutionContext::Harness::Docker::Image::_docker_preparer\'s docker clause must not be used because the image must already have been built.';
    }

    # try to stop and remove a previous container of the same name

    my $name_container = $harness_class->{docker}->{name_container};

    system "$docker_command_selected container stop -t 3 $name_container";
    system "$docker_command_selected container rm $name_container";

    # start the built container

    my $name_image = $harness_class->{docker}->{name_image};

    #t need more options to assign a static IP address,
    #t see: https://stackoverflow.com/questions/27937185/assign-static-ip-to-docker-container

    system "$docker_command_selected run -d -t --name $name_container $name_image";

    # return no errors

    #! the sub should return a user role object that
    #! has the interface to generate the necessary prefix
    #! for the command that is executed for the test.

    return {
	    docker_preparer_result => '_docker_preparer: executed',
	   };
}


sub new
{
    my $class = shift;

    my $harnessing_class = shift;

    my $harnessing_identifier = shift;

    # prepare the docker image and container

    use Clone 'clone';

    my $harness
	= {
	   class => clone($harnessing_class),
	   preparation => {
			   description => "start the Docker container for running the tests (the image must already exist)",
			  },
	   reparation => {
			  description => "leave the Docker container for running manual tests",
			 },
	   state => 'Instantiated',
	  };

    bless $harness;

    return $harness;
}


package Heterarch::Test::Executor;

#
# This is the default Heterarch::Test::Executor.  It provides a link
# with the execution context and implements ->ex_mo_prepare(),
# ->ex_cd_start() and ->ex_ct_run() methods that call the appropriate
# module, command_definition and command_test methods for implementing
# test execution.
#


sub new
{
    my $package = shift;

    my $execution_context = shift;

    my $options = shift || {};

    my $self
	= {
	   %$options,
	   execution_context => $execution_context,
	   # fd_output => $fd_output,
	  };

    bless $self, $package;

    return $self;
}


#
# Create the infrastructure for keeping module test results.
#
# For a base executor, this is currently a no-op.
#
# There is currently a global infrastructure for storing real test
# results, rather than a local one.
#

sub ex_mo_prepare
{
    my $self = shift;

}


#
# ->run() is called to execute one command test.
#
# this executor trivially delegates this call to the command_test object
#
# A derived class can inspect the elements found in the test
# specification and, for instance, print them to a file.
#

sub ex_ct_run
{
    my $self = shift;

    my $command_test = shift;

    my $execution_context = $self->{execution_context};

    return $command_test->ct_run_command($execution_context, $self);
}


#
# ->start() is called to start the tests of a single command definition.
#
# It instantiate the tester:
#
# 1. an object given its class.
# 2. a piece of perl code that is run.
# 3. an interactive system shell command.
#

sub ex_cd_start
{
    my $self = shift;

    my $execution_context = $self->{execution_context};

    my $module_definition = $execution_context->get_module_definition();

    my $command_definition = $execution_context->get_command_definition();

    $command_definition->cd_start($self);

    # process the command_definition specific clauses

    #! this sloppy implementation works around a too elaborate
    #! object-oriented based implementation that would require
    #! to call SUPER class methods inside ->cd_start().

    $command_definition->process_clauses($execution_context);
}


sub ex_terminate
{
    my $self = shift;

    my $test_module_library_contents = shift;

    # # yaml out the test report

    # my $report_yaml
    # 	= {
    # 	   description => $global_test_report->{description},
    # 	  };

    # # add output specific to the output selection

    # if ($option_report_disabled)
    # {
    # 	$report_yaml->{disabled} = $global_test_report->{disabled};
    # }

    # $report_yaml->{errors} = $global_test_report->{errors};
    # $report_yaml->{global} = $global_test_report->{global};

    # use YAML;

    # my $report_text = "\n" . Dump($report_yaml);

    my $execution_context = $self->{execution_context};

    my $reporter = $execution_context->{reporter};

    $reporter->report_message("message_info", "
Total of $global_test_report->{global}->{test_counters}->{current}->{command_test} test(s) (encountered $global_error_count error(s) in total)
 Started at: $global_test_report->{global}->{time_start},
Finished at: $global_test_report->{global}->{time_end}.
");
    # $reporter->report_message("message_info", "$report_text\n");

    #! this could be an error message

    return undef;
}


package Heterarch::Test::Executor::ModuleUpdater;


our @ISA = ("Heterarch::Test::Executor");


sub ex_terminate
{
    my $self = shift;

    my $test_module_library_contents = shift;

    $self->SUPER::ex_terminate(@_);

    # update the tests using the generated errors

    my $error_module_names = $global_test_report->{errors}->{modules};

    foreach my $error_module_name (sort keys %$error_module_names)
    {
	my $error_counts = $error_module_names->{$error_module_name};

	foreach my $error_count (sort keys %$error_counts)
	{
	    my $error_report = $error_counts->{$error_count};

	    my $context_path = $error_report->{context_path};

	    my $context_path_separator = "___/___";

	    my $decorated_context_path = '';

	    if ($decorated_context_path)
	    {
		# context_path: 1___/___./tests/specifications/70_harness/10_help/summary.yml___/___1___/___bin/neurospaces_harness___/___1___/___NONE
		# context_path: 2___/___90_yaml/70_harness/10_help.t___/___1___/___bin/neurospaces_harness___/___1___/___NONE

		my $number_matcher = "([0-9]+)";

		my $filename_and_command_matcher = "([a-z0-9_/\.]+)";

		$context_path =~ m(([0-9]+?)${context_path_separator}([a-z0-9_/\.]+?)${context_path_separator}([0-9]+?)${context_path_separator}([a-z0-9_/\.]+?)${context_path_separator}([0-9]+?)${context_path_separator}([a-z0-9_/\.]+?));

		$context_path =~ m(([0-9]+?)${context_path_separator}([a-z0-9_/\.]+?)${context_path_separator});

		my $module_counter = $1;
		my $module_filename = $2;
		my $command_definition_counter = $3;
		my $command_definition_command = $4;
		my $command_test_counter = $5;
		my $command_test_tester = $6;
	    }
	    else
	    {
		# process the context path of the current error ...

		# context_path: 1___/___1___/___1
		# context_path: 2___/___1___/___1

		my $matcher = "^([-0-9]+)${context_path_separator}([-0-9]+)${context_path_separator}([-0-9]+)\$";

		$context_path =~ m(([-0-9]+)${context_path_separator}([-0-9]+)${context_path_separator}([-0-9]+));

		# .., and extract the counters of module, command definition and command test

		my $module_counter = $1;
		my $command_definition_counter = $2;
		my $command_test_counter = $3;

		# walk the library to get to the appropriate test definition

		my $module_definitions = $test_module_library_contents->{test_modules};

		my $module_definition = $module_definitions->[$module_counter - 1];

		my $command_definitions = $module_definition->{command_definitions};

		my $command_definition = $command_definitions->[$command_definition_counter - 1];

		my $command_tests = $command_definition->{command_tests};

		my $command_test = $command_tests->[$command_test_counter - 1];

		# walk the error reports to obtain the text seen during testing

		my $error_report = $global_test_report->{errors}->{error_reports}->{$error_count};

		my $differences_report = $error_report->{differences_report};

		my $seen = $differences_report->{seen};

		# fill the seen text in in the test definition

		$command_test->{read} = $seen;

		# obtain a canonical module_pathname

		my $module_pathname = $error_report->{module_name};

		$module_pathname =~ s(/summary.yml$)();

		$module_pathname =~ s(^$global_config->{tests_directory}/)();

		# remove the existing module definition

		`rm -fr '$global_config->{tests_directory}/$module_pathname'`;

		# write the module definition to structure yaml

		my $execution_context = $self->{execution_context};

		my $reporter = $execution_context->{reporter};

		my $result = Heterarch::Test::Library::module_definition_dump_file_structured_yaml($module_pathname, $module_definition, $global_config->{tests_directory}, $reporter, 'yaml');

		if ($result =~ /error/i)
		{
		    print "$0: Error updating test module $module_pathname in $global_config->{tests_directory} ($result).\n";
		}
		else
		{
		    print "$0: Updated test module $module_pathname in $global_config->{tests_directory}, please check the result carefully.\n";
		}
	    }
	}
    }

    #! this could be an error message

    return undef;
}


package Heterarch::Test::Library;


#
# given the directory with the test specifications, construct a list
# of filenames containing the test specifications.
#

sub construct
{
    my $self = shift;

    my $tests_directory = $self->{tests_directory};

    # find the test specifications

    my $module_definitions
	= [
	   map
	   {
	       chomp; $_;
	   }
	   sort
	   `find $tests_directory 2>/dev/null -name "*.t"`,
	   `find $tests_directory 2>/dev/null -name "summary.yml"`,
	  ];

    $self->{module_definition_filenames} = $module_definitions;

    return $module_definitions;
}


#
# given a list of filenames of test specifications, read the test
# specifications as a list of executable test definitions.
#

sub expand
{
    my $self = shift;

    my $reporter = $self->{reporter};

    my $library = $self->{module_definition_filenames};

    my $test_modules = [];

    # parse all modules

    foreach my $test_module (@$library)
    {
	#! note that this matches against against the full pathname.
	#! as a consequence 'specific' matches all the test specifications in the specifications/ directory.

	if ($test_module !~ /$option_regex_selector/i)
	{
	    next;
	}

	my $module_definition = module_read($reporter, $test_module);

	if ($module_definition)
	{
	    module_read_process_options($reporter, $module_definition, $test_module);

	    push @$test_modules, $module_definition;
	}
    }

    if ($option_flattenout)
    {
	$test_modules = flatten_out($test_modules);
    }

    $self->{test_modules} = $test_modules;
}


sub flatten_out
{
    my $test_modules = shift;

    # sort modules

    #t first need to transform: select command_definitions, flatten
    #t out, keep the module names (for referencing errors).

    my $transformator
	= Data::Transformator->new
	  (
	   apply_identity_transformation => 0,
	   name => 'test-module-selector',
	   contents => $test_modules,
	   separator => '`',
	   array_filter =>
	   sub
	   {
	       my ($context, $component) = @_;

	       # never filter for the first two component in the path

	       my $depth = $context->{array};

	       $depth = $#$depth;

	       if ($depth < 2)
	       {
		   return 1;
	       }

	       # extract the data: command definitions with test commands

	       $context->{path} =~ m|^[^/]*/([^/]*)/([^/]*)|;

	       my $content = Data::Transformator::_context_get_current_content($context);

	       # push it onto the result

	       my $result = Data::Transformator::_context_get_main_result($context);

	       if (!$result->{content})
	       {
		   $result->{content} = [];
	       }

	       push @{$result->{content}}, $content;

	       # add the module name

	       my $module_name = $context->{array}->[1]->{content}->{name};

	       $content->{module_name} = $module_name;

	       # add the module description

	       my $module_description = $context->{array}->[1]->{content}->{description};

	       $content->{module_description} = $module_description;

	       # result is known, everything gets filtered

	       0;
	   },
	  );

    #t for an empty array as content, the transformator returns an
    #t undef, this is a bug that still needs fixing.

    my $tests = $transformator->transform() || [];

    # sort the flattened test definitions

    $tests
	= [
	   sort
	   {
	       my $module1 = $a;
	       my $module2 = $b;

	       my $command1 = $module1->{command};
	       my $command2 = $module2->{command};

	       my $command1_arguments = $module1->{arguments} || [];
	       my $command2_arguments = $module2->{arguments} || [];

	       my $command1_string = join ' ', $command1, @$command1_arguments;
	       my $command2_string = join ' ', $command2, @$command2_arguments;

	       my $comparison = $command1_string cmp $command2_string;

	       if ($module1->{tester_head})
	       {
		   $comparison = -1;
	       } elsif ($module2->{tester_head})
	       {
		   $comparison = 1;
	       }

	       $comparison;
	   }
	   @$tests,
	  ];

    # transform back to the regular test module format by putting
    # every command definition in its own module

    $tests
	= [
	   map
	   {
	       my $command_definition = $_;

	       (
		{
		 command_definitions => [
					 $command_definition,
					],
		 description => $command_definition->{module_description},
		 name => $command_definition->{module_name},
		}
	       );
	   }
	   @$tests,
	  ];

    # set result

    return $tests;
}


sub is_json
{
    my $filename = shift;

    my $result;

    use IO::File;

    my $fh = IO::File->new();

    if ($fh->open("< $filename"))
    {
	my $first_line = <$fh>;

	$first_line =~ s/(\s)*//g;

	if ($first_line =~ m'^\{')
	{
	    $result = 'is_json';
	}

	$fh->close;
    }

    return $result;
}


sub is_yaml
{
    my $filename = shift;

    my $result;

    use IO::File;

    my $fh = IO::File->new();

    if ($fh->open("< $filename"))
    {
	my $first_line = <$fh>;

	$first_line =~ s/(\s)*//g;

	if ($first_line eq '---')
	{
	    $result = 'is_yaml';
	}

	$fh->close;
    }

    return $result;
}


sub merge_commands
{
}


sub merge_command_tests
{
}


sub merge_modules
{
    my $self = shift;

    my $input_module_directories = shift || [];

    my $original_test_modules = $self->{test_modules};

    use Data::Merger 'merger';

    # loop over all the input_module_directories

    foreach my $input_module_directory (@$input_module_directories)
    {
	use Data::Dumper;

	my $test_library = Heterarch::Test::Library->new($input_module_directory, $self->{reporter}, );

	$test_library->construct();

	$test_library->expand();

	my $new_test_modules = $test_library->{test_modules};

	merger($original_test_modules, $new_test_modules);

	if (defined $option_debugging
	    and $option_debugging eq 'library')
	{
	    print Dumper(
			 {
			  new_test_modules => $new_test_modules,
			  original_test_modules => $original_test_modules,
			 },
			);
	}

    }

    # return the result

    return $original_test_modules;
}


sub new
{
    my $package = shift;

    my $tests_directory = shift;

    my $reporter = shift;

    my $self
	= {
	   reporter => $reporter,
	   tests_directory => $tests_directory,
	  };

    bless $self, $package;

    return $self;
}


sub path_create
{
    my $path_name = shift;

    my $created;

    if ( !-d $path_name )
    {
	use File::Path qw( make_path );

	$created = make_path($path_name);
    }
    else
    {
	$created = "exists";
    }

    return $created;
}


sub randomize_order
{
    my $test_modules = shift;

    my $option_random_order = shift;

    my $reporter = shift;

    if ($::option_verbose)
    {
	$reporter->report_message("message_info", "$0: Randomizing test specifications, random seed is $option_random_order\n");
    }

    # by default the randomizer will choose a random_seed

    my $random_seed;

    if ($option_random_order =~ /^[0-9]*$/
	and $option_random_order ne 1)
    {
	$random_seed = $option_random_order
    }

    # by default the randomizer will choose a random_seed

    if (not defined $random_seed)
    {
	$random_seed = time() ^ $$ ^ unpack "%L*", `ps axww | gzip`;
    }

    # set the random_seed

    srand($random_seed);

    # and shuffle the modules

    require List::Util;

    return ( [ List::Util::shuffle(@$test_modules), ], $random_seed );
}


sub read_html
{
    my $self = shift;

    my $options = shift;

    my $html_introduction_filename = $options->{introduction_filename};

    # read the introduction

    my $html_introduction;

    if (defined $html_introduction_filename
	and -e $html_introduction_filename)
    {
	local $/; # enable 'slurp' mode

	my $file = IO::File->new("<$html_introduction_filename");

	$html_introduction = <$file>;

	$file->close();
    }
    else
    {
	$html_introduction = '';
    }

    $self->{html_introduction} = $html_introduction;
}


sub module_read
{
    my $reporter = shift;

    my $pathname = shift;

    my $module_definition;

    if ($pathname =~ /\.t$/)
    {
	$module_definition = module_read_perl($reporter, $pathname);
    }
    elsif ($pathname =~ /summary\.yml$/)
    {
	$module_definition = module_read_yml($reporter, $pathname);
    }
    else
    {
	$reporter->report_error_add
	    (
	     {
	      context_path => 'module_read',
	      description => 'invalid module definition pathname syntax',
	      error => 'invalid module definition pathname syntax',
	      module_name => $pathname,
	     },
	    );
    }

    return $module_definition;
}


sub module_read_perl
{
    my $reporter = shift;

    my $pathname = shift;

    my $result;

    if (is_yaml($pathname))
    {
	use YAML;

	$result = YAML::LoadFile($pathname);

	if ($@)
	{
	    $reporter->report_error_add
		(
		 {
		  context_path => 'module_read_perl',
		  description => $@,
		  error => $@,
		  module_name => $pathname,
		 },
		);
	}
    }
    elsif (is_json($pathname))
    {
	local $/; # enable 'slurp' mode

	my $file = IO::File->new("<$pathname");

	my $json_text = <$file>;

	$file->close();

	use JSON;

	my $json = JSON->new();

	#! allow code refs, they are converted to nulls

	$json->allow_unknown(1);

	$result = $json->decode($json_text);

	if ($@)
	{
	    $reporter->report_error_add
		(
		 {
		  context_path => 'module_read_perl',
		  description => $@,
		  error => $@,
		  module_name => $pathname,
		 },
		);
	}
    }
    else
    {
	$result = do $pathname;

	if ($@)
	{
	    $reporter->report_error_add
		(
		 {
		  context_path => 'module_read_perl',
		  description => $@,
		  error => $@,
		  module_name => $pathname,
		 },
		);
	}
    }

    return $result;
}


#
# process the options
#
# option_dump_json
# option_dump_perl
# option_dump_yaml
# option_dump_file_structured_json
# option_dump_file_structured_yaml
# option_check_test_names
#

sub module_read_process_options
{
    my $reporter = shift;

    my $module_definition = shift;

    my $pathname = shift;

    my $error;

    $pathname =~ m((.*)/(.*));

    my $filename = $2;

    if ($option_dump_json)
    {
	my $filename = ">/tmp/$filename.js";

	JSON_DumpFile($filename, $module_definition);
    }

    if ($option_dump_perl)
    {
	use Data::Dumper;

	my $file = IO::File->new(">/tmp/$filename.pl");

	print $file Dumper($module_definition);

	$file->close();
    }

    if ($option_dump_yaml)
    {
	YAML::DumpFile("/tmp/$filename.yml", $module_definition);
    }

    if ($option_dump_file_structured_json)
    {
	module_definition_dump_file_structured_yaml($pathname, $module_definition, "/tmp", $reporter, 'json');
    }

    if ($option_dump_file_structured_yaml)
    {
	module_definition_dump_file_structured_yaml($pathname, $module_definition, "/tmp", $reporter, 'yaml');
    }

    # check if the name of the test and the pathname match

    if ($option_check_test_names)
    {
	if ($pathname ne "$global_config->{tests_directory}/$module_definition->{name}")
	{
	    $error = "the pathname ($pathname) and the test name ($module_definition->{name}) are different";

	    $reporter->report_error_add
		(
		 {
		  context_path => 'module_read_process_options',
		  description => "the pathname ($pathname) and the test name ($module_definition->{name}) are different",
		  error => $error,
		  module_name => $pathname,
		 },
		);

	}
    }

    return $error;
}


sub strings_remove
{
    my $strings = shift;

    my $options = shift;

    my $sentence = shift;

    if ($options eq 'with-dash-keep')
    {
	foreach my $string (@$strings)
	{
	    $sentence =~ s(-$string-)(-)g;
	    $sentence =~ s(^$string-)()g;
	    $sentence =~ s($string$)()g;
	}
    }
    elsif ($options eq 'without-dash')
    {
	foreach my $string (@$strings)
	{
	    $sentence =~ s($string)()g;
	}
    }
    else
    {
	die "$0: Internal error in strings_remove()";
    }

    return $sentence;
}


sub sentence_summarize
{
    my $sentence = shift;

    my $result = "$sentence";

    $result =~ s( )(-)g;

    my $remove_these_words = [ 'the', 'a', 'an', 'that', 'this', 'to', 'of', ];

    $result = strings_remove($remove_these_words, 'with-dash-keep', $result);

    my $remove_these_chars = [ '<', '>', ];

    $result = strings_remove($remove_these_chars, 'without-dash', $result);

    return $result;
}


sub JSON_DumpFile
{
    my $filename = shift;

    my $perl_data = shift;

    use JSON;

    my $json = JSON->new();

    #! allow code refs, they are converted to nulls

    $json->allow_unknown(1);

    $json->canonical(1);

    my $file = IO::File->new(">$filename");

    print $file $json->pretty->encode($perl_data);

    $file->close();
}


sub directory_filenames
{
    my $directory = shift;

    my $matcher = shift;

    #t use File::Find;
    #
    #t https://metacpan.org/dist/App-find2perl/view/script/find2perl

    my $filenames;

    if (-d $directory)
    {
	$filenames
	    = [
	       map
	       {
		   chomp; $_;
	       }
	       sort
	       `find "$directory" -iname "$matcher"`,
	      ];
    }
    else
    {
	$filenames = "directory $directory does not exist";
    }

    return $filenames;
}


sub directory_next_filename_prefix
{
    my $directory = shift;

    my $increment = shift || 10;

    my $filenames = directory_filenames($directory, "*.yml");

    if (not ref $filenames)
    {
	return undef;
    }

    my $result = 100;

    foreach my $filename (sort @$filenames)
    {
	if ($filename =~ m(/${result}_)
	    or $filename =~ m(^${result}_))
	{
	    $result += $increment;
	}
	else
	{
	    last;
	}
    }

    return $result;
}


sub command_definition_dump_file_structured_yaml
{
    my $command_definition = shift;

    my $command_definition_pathname = shift;

    my $file_type = shift;

    # https://metacpan.org/release/ANDYA/Data-Structure-Util-0.16/source/Util.xs#L239

    # use Data::Structure::Util qw( unbless );

    # unbless($command_definition);

    my $unblessed_command_definition = { %$command_definition, };

    #t I am not sure what the consequences are of unblessing all the command tests ...

    my $command_tests = $command_definition->{command_tests};

    my $command_tests_unblessed = [];

    foreach my $command_test (@$command_tests)
    {
	$command_test = { %$command_test, };

	push @$command_tests_unblessed, $command_test;
    }

    $command_definition->{command_tests} = $command_tests_unblessed;

    if ($file_type eq 'yaml')
    {
	YAML::DumpFile($command_definition_pathname, $unblessed_command_definition);
    }
    else
    {
	JSON_DumpFile($command_definition_pathname, $unblessed_command_definition);
    }
}


sub module_definition_summary_dump_file_structured_yaml
{
    my $module_definition = shift;

    my $module_summary_filename = shift;

    my $file_type = shift;

    # https://metacpan.org/release/ANDYA/Data-Structure-Util-0.16/source/Util.xs#L239

    # use Data::Structure::Util qw( unbless );

    # unbless($module_definition);

    my $unblessed_module_definition = { %$module_definition, };

    if ($file_type eq 'yaml')
    {
	YAML::DumpFile($module_summary_filename, $unblessed_module_definition);
    }
    else
    {
	JSON_DumpFile($module_summary_filename, $unblessed_module_definition);
    }
}


sub module_definition_dump_file_structured_yaml
{
    my $pathname = shift;

    my $module_definition = shift;

    my $path_prefix = shift;

    my $reporter = shift;

    my $file_type = shift;

    my $result = 'created';

    use Clone 'clone';

    $module_definition = clone($module_definition);

    my $command_definitions = $module_definition->{command_definitions};

    delete $module_definition->{command_definitions};

    my $module_pathname = "$path_prefix/$pathname";

    $module_pathname =~ s(//)();
    $module_pathname =~ s(\.t$)();

    my $path_name = "$module_pathname/command_definitions";

    my $created = path_create($path_name);

    if ($created)
    {
	my $module_summary_filename = "$module_pathname/summary" . ($file_type eq 'yaml' ? ".yml" : ".json");

	if (! -f $module_summary_filename)
	{
	    my $module_name = $module_pathname;

	    $module_name =~ s($path_prefix/)();

	    $module_definition->{name} = "$module_name/summary" . ($file_type eq 'yaml' ? ".yml" : ".json");

	    module_definition_summary_dump_file_structured_yaml($module_definition, $module_summary_filename, $file_type);

	    my $directory = "$module_pathname/command_definitions";

	    my $prefix = directory_next_filename_prefix($directory);

	    if (defined $prefix)
	    {
		foreach my $command_definition (@$command_definitions)
		{
		    my $description = $command_definition->{description};

		    my $command_definition_filename = $prefix . "_" . sentence_summarize($description) . ($file_type eq 'yaml' ? ".yml" : ".json");

		    my $command_definition_pathname = "$module_pathname/command_definitions/$command_definition_filename";

		    if (! -f $command_definition_pathname)
		    {
			command_definition_dump_file_structured_yaml($command_definition, $command_definition_pathname, $file_type);
		    }
		    else
		    {
			$result = "Error: $command_definition_pathname already exists";
		    }

		    $prefix += 10;
		}
	    }
	    else
	    {
		$result = "Error: directory_next_filename_prefix does not return a prefix (does the directory $directory exist?).";
	    }
	}
	else
	{
	    $result = "Error: $module_summary_filename already exists";
	}
    }
    else
    {
	$reporter->report_error_add
	    (
	     {
	      context_path => 'module_definition_dump_file_structured_yaml',
	      description => "error creating the output module_pathname ($created)",
	      error => "error creating the output module_pathname",
	      module_name => "module_definition_dump_file_structured_yaml",
	      subdescription => "error creating the module_pathname ($created)",
	     },
	    );

	$result = '';
    }

    return $result;
}


sub module_read_yml
{
    my $reporter = shift;

    my $summary_pathname = shift;

    my $error;

    my $result;

    # read the meta information of the module definition

    use YAML;

    eval
    {
	local $SIG{'__DIE__'};

	$result = YAML::LoadFile($summary_pathname);
    };

    if ($@)
    {
	$error = $@;
    }

    if (!$error)
    {
	# read the command defintions of the module definition

	$result->{command_definitions} = [];

	my $command_definitions = $result->{command_definitions};

	$summary_pathname =~ m((.*)/summary\.yml$);

	my $directory = $1;

	my $command_definition_filenames = directory_filenames("$directory/command_definitions", "*.yml");

	if (ref $command_definition_filenames)
	{
	    foreach my $command_definition_filename (@$command_definition_filenames)
	    {
		my $command_definition
		    = eval
		      {
			  local $SIG{'__DIE__'};

			  YAML::LoadFile($command_definition_filename);
		      };

		if ($@)
		{
		    $error = $@;

		    last;
		}
		else
		{
		    push @$command_definitions, $command_definition;
		}
	    }
	}
	else
	{
	    $error = "Error: $command_definition_filenames";
	}
    }

    if ($error)
    {
	$reporter->report_error_add
	    (
	     {
	      context_path => 'module_read_yml',
	      description => $error,
	      error => $error,
	      module_name => $summary_pathname,
	     },
	    );
    }

    return $result
}


sub validate
{
    my $test_library = shift;

    #t should call here: check_description(), check_name(), and more.

    my $error;

    my $module_definitions = $test_library->{test_modules};

    if (not scalar @$module_definitions)
    {
	$error = "no module_definitions found";
    }

    return $error;
}


package Heterarch::Test::Module;


our @ISA = ("Heterarch::Test::Element");


sub check_description
{
    my $module_definition = shift;

    my $reporter = shift;

    my $module_name = $module_definition->{name};

    if (!defined $module_definition->{description})
    {
	$module_definition->{description} = $module_definition->{name};

	$reporter->report_error_add
		(
		 {
		  context_path => "check_description($module_name)",
		  description => 'no module description',
		  error => 'no module description',
		  module_name => $module_name,
		 },
		);
    }

    return $module_definition->{description};
}


sub check_name
{
    my $module_definition = shift;

    my $reporter = shift;

    if (!defined $module_definition->{name})
    {
	$module_definition->{name} = 'unnamed';

	$reporter->report_error_add
		(
		 {
		  context_path => "check_name, unnamed module",
		  description => 'unnamed module',
		  error => 'unnamed module',
		  module_name => 'unnamed module',
		 },
		);
    }

    return $module_definition->{name};
}


# check if this module is ready to run its tests.
# execute all the command definitions.
# execute all the command tests in these command definitions.

sub md_run
{
    my $self = shift;

    my $execution_context = shift;

    my $executor = shift;

    my $reporter = $execution_context->{reporter};

    my $module_name = $self->check_name($reporter);

    my $module_description = $self->check_description($reporter);

    # do selection and prepare the test environment

    my $not_started = $execution_context->ec_examine($self);

    if ($not_started)
    {
	return "module_definition start failed ($not_started)";
    }

    # create the infrastructure for keeping module test results

    #! for a base executor, this is currently a no-op.

    $executor->ex_mo_prepare();

    # loop over commands for this module

    my $command_definitions = $self->{command_definitions};

    foreach my $command_definition (@$command_definitions)
    {
	bless $command_definition, "Heterarch::Test::CommandDefinition";

	# lookup the class for this command definition

	$command_definition->rebless();

	my $error = $command_definition->cd_run($execution_context, $executor);
    }

    # repair the test environment

    $execution_context->ec_end($self);

    # register if this command had side effects

    #! don't think this make sense, but anyway ...

    $global_previous_command_side_effects ||= $self->{side_effects} || 0;

    # if there are modeling libraries

    if (defined $global_config->{external_model_libraries})
    {
	# compute the shas of the modeling libraries

	my $model_library_shas_after = ModelLibrary::shas($global_config->{external_model_libraries});

	my $external_model_libraries = $global_config->{external_model_libraries};

	foreach my $external_modeling_library (@$external_model_libraries)
	{
	    my $library_sha_before = $execution_context->{external_model_libraries_shas}->{$external_modeling_library}->{sha};

	    my $library_sha_after = $model_library_shas_after->{$external_modeling_library};

	    # if the shas are different

	    if ($library_sha_after ne $library_sha_before)
	    {
		# generate an error

		my $error = "$external_modeling_library model library checksum mismatch (model library $external_modeling_library has changed from $library_sha_before to $library_sha_after)";

		my $description = $self->{description};

		$reporter->report_error_add
		    (
		     {
		      context_path => $execution_context->get_context_path(),
		      description => $description,
		      error => $error,
		      module_name => $module_name,
		     },
		    );
	    }
	}
    }

    # increment module definition count

    $global_test_report->{global}->{test_counters}->{current}->{module_definition}++;

    # return result: execution completed

    return '';
}


package Heterarch::Test::ModuleUpdater;


our @ISA = ("Heterarch::Test::Module");


package Heterarch::Test::Output;

#
# An Heterarch::Test::Output is an Heterarch::Test::Executor that
# generates output rather than executing tests.  The
# Heterarch::Test::Executor provides a link with the execution context
# and implements ->ex_mo_prepare(), ->ex_cd_start() and ->ex_ct_run()
# methods that call the appropriate module, command_definition and
# command_test methods for implementing test execution.
#
# The Heterarch::Test::Output implements ->ex_mo_prepare(),
# ex_cd_start() and ex_ct_run() methods to select content and prepare
# a structure for generating output of different format (HTML, XML,
# Yaml, Ascii).
#

our @ISA = ("Heterarch::Test::Executor");


package Heterarch::Test::Output::Summarizer;

#
# A Heterarch::Test::Output::Summarizer implements ->ex_mo_prepare(),
# ex_cd_start() and ex_ct_run() methods that select content and
# prepare a structure for generating a summary in YAML of this
# selection.
#

our @ISA = ("Heterarch::Test::Output");


package Heterarch::Test::Output::Formatter;

#
# A Heterarch::Test::Output::Formatter implements ->ex_mo_prepare(),
# ->ex_cd_start() and ->ex_ct_run() methods that prepare structure
# content for the output formatter to convert to its target format.
#
# The result of the conversion is stored in the hash
# $global_test_report->{selected}.
#
# This hash has the selected module names as keys.  Each value is a
# hash with the contents of the module and a key
# ->{command_definitions} with as value an array for the contents of
# the command_definitions.  Each command_definition value has again
# the content of a command_definition and a key ->{command_tests}.
#
# Each element in the result receives a key ->{context_path} that is
# unique and identifies the path from the root to the element.
#

our @ISA = ("Heterarch::Test::Output");


#
# Create the infrastructure for keeping module test results.
#

sub ex_mo_prepare
{
    my $self = shift;

    # create an output entry for the module

    my $execution_context = $self->{execution_context};

    my $module_definition = $execution_context->get_module_definition();

    my $module_name = $module_definition->{name};

    if (not $global_test_report->{selected}->{$module_name})
    {
	my $module_counter = $execution_context->get_module_definition_counter();

	my $context_path = $execution_context->get_context_path();;

	if ($option_verbose)
	{
	    my $reporter = $execution_context->{reporter};

	    $reporter->report_message_info("message_info", "$0: Preparing $context_path\n");
	}

	$global_test_report->{selected}->{$module_name}
	    = {
	       command_definitions => [],
	       comment => $module_definition->{comment},
	       context_path => $context_path,
	       count => $module_counter,
	       description => $module_definition->{description},
	       documentation => $module_definition->{documentation},
	       harnessing => {
			      preparation => $module_definition->{harnessing}->{preparation}->{description},
			      reparation => $module_definition->{harnessing}->{reparation}->{description},
			     },
	       name => $module_name,
	      };
    }
    else
    {
	die "$0: *** Error: module_name $module_name is defined twice.";
    }
}


#
# Adds the current test description to the summary, constructs a
# structure to keep results.
#

sub ex_ct_run
{
    my $self = shift;

    my $command_test = shift;

    my $execution_context = $self->{execution_context};

    my $command_definition = $execution_context->get_command_definition();

    my $module_definition = $execution_context->get_module_definition();

    my $module_name = $module_definition->{name};

    # get the current module summary

    my $selected_module = $global_test_report->{selected}->{$module_name};

    # get the current test summary

    my $module_command_definitions = $selected_module->{command_definitions};

    my $command_definition_counter = $execution_context->get_counter_command_definition_per_module();

    my $selected_command_definition = $module_command_definitions->[$command_definition_counter - 1];

    # get the current command test

    if (not exists $selected_command_definition->{command_tests})
    {
	$selected_command_definition->{command_tests} = [];
    }

    my $selected_test_definitions = $selected_command_definition->{command_tests};

    my $test_definition_counter = $execution_context->get_counter_command_test_per_command_definition();

    # if (not $selected_test_definitions->[$test_definition_counter])
    # {
    # 	$selected_test_definitions->[$test_definition_counter] = {};
    # }

    # just clone the current command test and add to the result

    use Clone 'clone';

    my $cloned_command_test = clone($command_test);

    # add the context_path

    my $context_path = $execution_context->get_context_path();;

    if ($option_verbose)
    {
	my $reporter = $execution_context->{reporter};

	$reporter->report_message_info("message_info", "$0: Preparing $context_path\n");
    }

    $cloned_command_test->{context_path} = $context_path;

    push @$selected_test_definitions, $cloned_command_test;

    # my $selected_test_definition = $selected_test_definitions->[$test_definition_counter];

    # # add the current test description to the summary

    # $selected_test_definition->{description} = $command_test->{description};

    # always succeeds

    my $test_result
	= {
	   after_match => "",
	   before_match => "",
	   error => "",
	   expected => "",
	   matched_pattern_position => "",
	   successfully_matching_string => "",
	  };

    return $test_result;
}


#
# Adds the current command definition to the summary, constructs a
# structure to keep results.
#

sub ex_cd_start
{
    my $self = shift;

    # get the execution context

    my $execution_context = $self->{execution_context};

    # create an output entry for the module

    my $module_definition = $execution_context->get_module_definition();

    my $module_name = $module_definition->{name};

    # create an output entry for the current command definition

    my $selected_module = $global_test_report->{selected}->{$module_name};

    my $selected_command_definitions = $selected_module->{command_definitions};

    my $command_definition = $execution_context->get_command_definition();

    # just clone the current command_definition

    use Clone 'clone';

#     push @$selected_command_definitions, { description => $command_definition->{description}, tests => [], };

    my $cloned_command_definition = clone($command_definition);

    delete $cloned_command_definition->{command_tests};

    # add the context_path

    my $context_path = $execution_context->get_context_path();;

    if ($option_verbose)
    {
	my $reporter = $execution_context->{reporter};

	$reporter->report_message_info("message_info", "$0: Preparing $context_path\n");
    }

    $cloned_command_definition->{context_path} = $context_path;

    # add to the result

    push @$selected_command_definitions, $cloned_command_definition;
}


sub ex_terminate
{
    my $self = shift;

    my $test_module_library_contents = shift;

    my $selected_output_levels = $Heterarch::Test::Element::selected_output_levels;

    my $extension = join '-', sort keys %$selected_output_levels;

    my $output_directory = "/tmp/test_report_$global_config->{package}->{name}";

    my $created;

    if ( !-d $output_directory )
    {
	use File::Path qw( make_path );

	$created = make_path($output_directory);
    }
    else
    {
	$created = "exists";
    }

    if ($created)
    {
	my $output_filename = "test_report_$global_config->{package}->{name}_$extension";

	my $output_pathname = "$output_directory/$output_filename";

	$self->process($output_pathname, $test_module_library_contents, $global_test_report);

	# my $testing = 1;

	# if ($testing)
	# {
	# 	my $output_filename = "/tmp/test_report_$global_config->{package}->{name}";

	# 	$self->process($output_filename, $test_module_library_contents, $global_test_report);
	# }
    }
    else
    {
	my $execution_context = $self->{execution_context};

	my $reporter = $execution_context->{reporter};

	$reporter->report_error_add
		(
		 {
		  context_path => $execution_context->get_context_path(),
		  description => "error creating the output_directory ($created)",
		  error => "this test was tagged with the error flag",
		  module_name => "END",
		  subdescription => "error creating the output_directory ($created)",
		 },
		);
    }
}


package Heterarch::Test::Output::Formatter::HTMLTable;

# the Formatter:: HTMLTable package converts the test specifications
# to HTML tables.


our @ISA = ("Heterarch::Test::Output::Formatter");


#
# sub start
#
# Incomplete.
#

sub ex_cd_start
{
    my $self = shift;

    my $execution_context = $self->{execution_context};

    my $module_definition = $execution_context->get_module_definition();

    my $command_definition = $execution_context->get_command_definition();

    # we have to either instantiate an object that produces output ...

    if ($command_definition->{class})
    {
	# instantiate the object

	my $class = $command_definition->{class};

	my $filename = $class . ".pm";

	$filename =~ s(::)(/)g;

	# require $filename;

	# $self->{command_object} = eval "$class->new()";
    }

    # ... or run perl code that produces output

    elsif (ref $command_definition->{command} eq 'CODE')
    {
	# code is already instantiated, nothing to do here
    }

    # ... or run a command that produces output

    else
    {
	# start the command and connect with its I/O channels

	# my ($exp, $test_startup) = $command_definition->spawn_new($execution_context, $fd_output);

	# remember to spawn a new command

	my $spawn_new = not $command_definition->{recycle};

	# retrieve the shell command and its arguments

	my $command_line = $command_definition->cd_construct_command_line();

	# if the command can be executed

	if (exists $command_line->{command})
	{
	    if ($spawn_new)
	    {
	    }
	    else
	    {
		# print $fd_output "*** Recycling $command " . (join ' ', map { "'$_'" } @$arguments) . "\n";
	    }
	}
    }
}


package Heterarch::Test::Output::Formatter::Latex;

# The Heterarch::Test::Output::Formatter::Latex package converts the test specifications
# to a Latex document.


our @ISA = ("Heterarch::Test::Output::Formatter");


our $output_file;


sub _output_latex
{
    my $outputfile = shift;

    my $contents = shift;

    $contents =~ s/_/\\_/g;
    $contents =~ s/&/\\&/g;

    print $outputfile $contents;
}


sub _output_latex_table
{
    my $outputfile = shift;

    my $contents = shift;

    my $prompt = shift;

    _output_latex_environment_prompt
	(
	 $output_file,
	 {
	  content_type => "Verbatim",
	  prompt => $prompt,
	  suffix => "\n\n",
	 },
	);

    _output_latex($output_file, '\begin{longtable}{p{13cm}}' . "\n");

    _output_latex($output_file, '\hline' . "\n");

    _output_latex_environment_prompt
	(
	 $output_file,
	 {
	  content_type => "Verbatim",
	  content => $contents,
	 }
	);

    _output_latex($output_file, '\\\\' . "\n");

    _output_latex($output_file, '\hline' . "\n");

    _output_latex($output_file, '\end{longtable}' . "\n");

}


sub _output_latex_environment_prompt
{
    my $outputfile = shift;

    my $content_options = shift;

    my $content_line_limit = $content_options->{content_line_limit};
    my $content_type = $content_options->{content_type};
    my $content_type_options = $content_options->{content_type_options} || "";
    my $content = $content_options->{content} || "";
    my $prompt = $content_options->{prompt} || "";
    my $suffix = $content_options->{suffix} || "";

    # if there is content

    if (defined $content)
    {
	# cut the content at the content limit

	if ($content_line_limit)
	{
	    my $line_count = $content =~ tr/\n//;

	    if ($line_count > $content_line_limit)
	    {
		my $first_lines = join "\n", ( split /\n/, $content )[0 .. $content_line_limit];

		$content = $first_lines . "\n ... < cut at $content_line_limit lines, more follows > ...\n";
	    }
	}

	# output the prompt

	_output_latex($output_file, $prompt);

	# output the content enclosed with the begin and end markers

	if ($content_type)
	{
	    _output_latex($output_file, '\begin{' . $content_type . "}$content_type_options\n");
	}

	_output_latex($output_file, $content);

	if ($content !~ /\n$/)
	{
	    _output_latex($output_file, "\n");
	}

	if ($content_type)
	{
	    _output_latex($output_file, '\end{' . $content_type . "}\n");
	}
    }

    # output the suffix

    _output_latex($output_file, $suffix);
}


sub _output_latex_environment_minipage
{
    my $outputfile = shift;

    my $content_options = shift;

    my $content_line_limit = $content_options->{content_line_limit};
    my $content_type = $content_options->{content_type};
    my $content_type_embedding = $content_options->{content_type_embedding} || "";
    my $content_type_options = $content_options->{content_type_options} || "";
    my $content = $content_options->{content};
    my $prompt = $content_options->{prompt} || "";
    my $prompt_type = $content_options->{prompt_type};
    my $suffix = $content_options->{suffix} || "";

    # if there is content

    if (defined $content)
    {
	# cut the content at the content limit

	if ($content_line_limit)
	{
	    my $line_count = $content =~ tr/\n//;

	    if ($line_count > $content_line_limit)
	    {
		my $first_lines = join "\n", ( split /\n/, $content )[0 .. $content_line_limit];

		$content = $first_lines . "\n ... < cut at $content_line_limit lines, more follows > ...\n";
	    }
	}

	# output the content begin marker

	if ($content_type)
	{
	    print $output_file '\vspace{3ex}
\begin{' . $content_type . "}$content_type_options\n";
	}

	# output the embedding start

	if ($content_type_embedding)
	{
	    print $outputfile "\\$content_type_embedding\{";
	}

	# output the prompt

	_output_latex_prompt($output_file, $prompt_type, $prompt, "", "");

	# output the content

	_output_latex($output_file, $content);

	if ($content !~ /\n$/)
	{
	    _output_latex($output_file, "\n");
	}

	# output the embedding end

	if ($content_type_embedding)
	{
	    print $outputfile "\}\n";
	}

	# output the content end marker

	if ($content_type)
	{
	    print $output_file '\end{' . $content_type . "}\n" . '\vspace{3ex}
';
	}
    }

    # output the suffix

    _output_latex($output_file, $suffix);
}


sub _output_latex_figure_generate_insert
{
    my $figure = shift;

    my $figure_class = exists $figure->{class} ? $figure->{class} : "simple";

    my $output_filename = shift;

    my $command_test = shift;

    my $figure_references = shift;

    my $read = shift;

    my $figure_class_2_package
	= {
	   hh_gates_A_B => "Heterarch::Test::Output::Formatter::Figure::HHGatesAB",
	   hh_gates_alpha_beta => "Heterarch::Test::Output::Formatter::Figure::HHGatesAlphaBeta",
	   hh_gates_internal => "Heterarch::Test::Output::Formatter::Figure::HHGatesInternal",
	   hh_gates_steady_state_tau => "Heterarch::Test::Output::Formatter::Figure::HHGatesSteadyStateTau",
	   simple => "Heterarch::Test::Output::Formatter::Figure::Simple",
	  };

    my $figure_package = $figure_class_2_package->{$figure_class};

    # create the figure object, link it with the generated references

    my $figure_object = $figure_package->new($figure, $output_filename, $command_test, $figure_references, $read);

    # generate its reference

    my $label_error = $figure_object->generate_label('latex');

    # render the graph

    my $render_error = $figure_object->render();

    # insert the figure filename in the latex file

    my $insert_error = $figure_object->insert($figure);

    if ($label_error or $render_error or $insert_error)
    {
	#! note that this does not generate a label for referencing

	_output_latex_environment_minipage
	    (
	     $output_file,
	     {
	      content => "Please install GD::Graph to render figures",
	      content_type => "minipage",
	      content_type_options => '{14cm}',
	      content_type_embedding => "small",
	      prompt => "ERROR\\::",
	      prompt_type => 'textbf',
	      suffix => "\n\n",
	     },
	    );
    }
}


sub _output_latex_figure_references_insert
{
    my $figure_references = shift;

    my $ss = shift;

    my $cd_1 = $ss->{cd_1};

    # my $fr_0 = $ss->{fr_0};

    # my $fr_1 = $ss->{fr_1};

    if ($cd_1)
    {
	print $output_file '\item [$\bullet$]';
    }

    if (scalar @$figure_references eq 1)
    {
	print $output_file 'See figure~\ref{' . $figure_references->[0] . "}";
    }
    else
    {
	print $output_file 'See figures';

	while (my $figure_reference = shift @$figure_references)
	{
	    if (scalar @$figure_references eq 0)
	    {
		print $output_file '~\ref{' . $figure_reference . '}';
	    }
	    elsif (scalar @$figure_references eq 1)
	    {
		print $output_file '~\ref{' . $figure_reference . '} and';
	    }
	    else
	    {
		print $output_file '~\ref{' . $figure_reference . '},';
	    }
	}
    }

    print $output_file ".\n\n";
}


sub _output_latex_module_comments
{
    my $module_definition = shift;

    _output_latex_environment_minipage
	(
	 $output_file,
	 {
	  content => $module_definition->{comment},
	  content_type => "minipage",
	  content_type_options => '{14cm}',
	  content_type_embedding => "small",
	  prompt => "NOTE\\::",
	  prompt_type => 'textbf',
	  suffix => "\n\n",
	 },
	);
}


sub _output_latex_module_documentation
{
    my $module_definition_documentation = shift;

    if ($module_definition_documentation)
    {
	_output_latex($output_file, "$module_definition_documentation->{purpose}\n\n");

	_output_latex($output_file, "$module_definition_documentation->{explanation}\n\n");

	# _output_latex($output_file, "Test commands follow.\n\n");
    }
    else
    {
	_output_latex($output_file, "\n\n");
    }
}


sub _output_latex_module_filename_insert
{
    my $module_definition = shift;

    my $module_definition_documentation = shift;

    my $ss = shift;

    my $cd_0 = $ss->{cd_0};

    my $cd_1 = $ss->{cd_1};

    if ($cd_0)
    {
	_output_latex($output_file, 'File ');

	_output_latex_prompt($output_file, "textit", $module_definition->{name}, "", "");

	if ($module_definition_documentation)
	{
	    _output_latex($output_file, ':  ');
	}
	else
	{
	    _output_latex($output_file, '.');
	}
    }
    elsif ($cd_1)
    {
	_output_latex($output_file, 'The file ');

	_output_latex_prompt($output_file, "textit", $module_definition->{name}, "", "");

	_output_latex($output_file, " defines the test that is explained in this section.\n\n");
    }
    else
    {
	_output_latex($output_file, 'The file ');

	_output_latex_prompt($output_file, "textit", $module_definition->{name}, "", "");

	_output_latex($output_file, " defines the tests that are explained in this section.\n\n");
    }
}


sub _output_latex_module_harnessing
{
    my $module_definition = shift;

    my $ss = shift;

    my $cd_0 = $ss->{cd_0};

    if ($cd_0)
    {
	my $harnessing = $module_definition->{harnessing};

	if ($harnessing->{preparation})
	{
	    _output_latex($output_file, '\begin{' . "itemize" . "}\n");

	    _output_latex($output_file, '\item ');

	    _output_latex_prompt($output_file, "textit", $module_definition->{harnessing}->{preparation}, "Preparation: ", "\n");

	    _output_latex($output_file, '\item ');

	    _output_latex_prompt($output_file, "textit", $module_definition->{harnessing}->{reparation}, "Reparation: ", "\n");

	    _output_latex($output_file, '\end{' . "itemize" . "}\n");
	}
    }
}


sub _output_latex_postamble
{
    my $postamble
	= '\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
';

#    $output_file = IO::File->new(">>$output_filename");

    print $output_file $postamble;
}


sub _output_latex_preamble
{
    my $output_filename = shift;

    my $html_introduction = shift;

    my $main_figures_directory = "$output_filename/figures";

    {
	use File::Basename qw( fileparse );
	use File::Path qw( make_path );
	use File::Spec;

	my $created = make_path($main_figures_directory);

	use File::Copy;

	my $logo_source_filename = "/usr/local/neurospaces/images/images/ns-main-logo-dark2.jpg";

	copy($logo_source_filename, "$main_figures_directory")
	    or die "Copy of $logo_source_filename failed: $!";
    }

    $output_file = IO::File->new(">$output_filename.tex");

    my $title_paragraphs = _output_latex_preamble_construct($html_introduction);

    my $preamble1
	= '\documentclass[10pt,a4paper,landscape]{article}
\usepackage[a4paper, total={6in, 9in}]{geometry}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{color}
\usepackage[colorlinks=true]{hyperref}
% \usepackage[dvips]{epsfig}
\usepackage{enumitem} % [noitemsep,nolistsep] compact itemize/enumerate etc.
\usepackage{graphicx}
\usepackage{longtable}
% \usepackage[margin=2cm]{geometry}
\usepackage{subcaption}
\usepackage{url}
\usepackage{verbatim}
\usepackage{fancyvrb}
\usepackage{relsize}

\usepackage{footmisc}	% ADC: Added footnote referencing capacity for text editing comments

% Typeface
\usepackage[condensed,math]{iwona}
\usepackage[T1]{fontenc}

% A4 portrait

% \setlength{\textwidth}{15.7cm}
% \setlength{\textheight}{22cm}

% \setlength{\topmargin}{0cm}
% \setlength{\headheight}{1cm}
% \setlength{\headsep}{0.5cm}
% \setlength{\topskip}{0cm}

% A4 landscape

\setlength{\textwidth}{25cm}
\setlength{\textheight}{15cm}

\setlength{\topmargin}{0cm}
\setlength{\headheight}{0cm}
\setlength{\headsep}{0cm}
\setlength{\topskip}{0cm}

\setlength{\oddsidemargin}{0pt}

';

    print $output_file $preamble1;

    my $use_title_page = $option_output_title_page;

    if ($use_title_page)
    {
	_output_latex_preamble_configure_title_page($title_paragraphs);
    }

    my $preamble2
	= '
\begin{document}
';

    $preamble2
	.= '
\begin{center}
   \includegraphics[scale=0.5]{' . $main_figures_directory . '/ns-main-logo-dark2.jpg}
%   \caption{{\bf A Dummy Figure:} Example of \LaTeX\,\,\,code to incorporate a figure into documentation.}
  \label{fig:logo}
\end{center}
\vspace{-10ex}

';

    if ($use_title_page)
    {
	$preamble2 .= '
       \maketitle

';
    }

    print $output_file $preamble2;

    if (not $use_title_page)
    {
	_output_latex($output_file, '\section*{\center \Huge ' . $title_paragraphs->{title} . "}\n\n");

	_output_latex($output_file, '\vspace{-6ex}' . "\n\n");

	_output_latex($output_file, '\section*{\center \scriptsize ' . "Automatically generated draft document" . "}\n\n");

	_output_latex($output_file, '\vspace{-6ex}' . "\n\n");

	_output_latex($output_file, '\section*{\center \small \textbf ' . $title_paragraphs->{author} . "}\n\n");

	_output_latex($output_file, '\vspace{-6ex}' . "\n\n");

	use POSIX qw(strftime);

	# my $now_string = strftime("%a %b %e %H:%M:%S %Y", localtime());

	my $now_string = strftime("%a %b %e, %Y", localtime());

	my ( $day, $month_number, $year ) = ( localtime ) [3,4,5];

	$year += 1900;

	my $month = (
		     qw/ January   February  March
			 April     May       June
			 July      August    September
			 October   November  December  /
		    ) [$month_number];

	$now_string = "$day $month, $year";

	_output_latex($output_file, '\section*{\center \small \textbf ' . $now_string . "}\n\n");
    }

    _output_latex_preamble_abstract($title_paragraphs);

    _output_latex_preamble_summary($title_paragraphs);

    my $use_table_of_contents = $option_output_table_of_contents;

    my $preamble3 = "";

    if ($use_table_of_contents)
    {
	$preamble3 .= '

\tableofcontents

\newpage

';
    }

    print $output_file $preamble3;
}


sub _output_latex_preamble_abstract
{
    my $title_paragraphs = shift;

}


sub _output_latex_preamble_construct
{
    my $html_introduction_original = shift;

    my $html_introduction = $html_introduction_original;

    # extract email address

    $html_introduction =~ m(<address>(.*)</address>)gs;

    my $email_anchored = $1;

    my $author = $email_anchored || "";

    $author =~ m(<a.*?>(.*)</a>)gs;

    $author = $1 || "";

    my $thanks = $email_anchored || "";

    $thanks =~ m("mailto:(.*)")gs;

    $thanks = $1 || "";

    # remove trailing part

    $html_introduction =~ s(<address>(.*))()gs;

    # extract title

    $html_introduction =~ s(<h1>(.*)</h1>)()gs;

    my $title = $1 || "";

    # enumeration tags

    $html_introduction =~ s(<ul>)(\\begin{itemize}\n  \\setlength\\itemsep{-0.35em}\n)gs;

    $html_introduction =~ s(</ul>)(\\end{itemize})gs;

    $html_introduction =~ s(<li>)(\\item )gs;

    # remove irrelevant html tags

    $html_introduction =~ s(<p/?>)()gs;

    $html_introduction =~ s(<hr/?>)()gs;

    # split in paragraphs

    my $paragraphs = [ split "\n\n", $html_introduction, ];

    # construct and return result

    my $result
	= {
	   author => $author,
	   email_anchored => $email_anchored,
	   original_contents => $html_introduction_original,
	   paragraphs => $paragraphs,
	   thanks => $thanks,
	   title => $title,
	  };

    return $result
}


sub _output_latex_preamble_summary
{
    my $title_paragraphs = shift;

    my $paragraphs = $title_paragraphs->{paragraphs};

    if (scalar @$paragraphs)
    {
	# output the description as a section title

	_output_latex($output_file, '\section*{\center ' . "Summary" . "}\n\n");

	# write paragraphs

	foreach my $paragraph (@$paragraphs)
	{
	    _output_latex($output_file, "$paragraph\n\n");
	}
    }
}


sub _output_latex_preamble_configure_title_page
{
    my $title_paragraphs = shift;

    # write title

    _output_latex($output_file, '\title{' . $title_paragraphs->{title} . "}\n\n");

    _output_latex($output_file, '\date{' . localtime() . "}\n\n");

    _output_latex($output_file, '\author{' . $title_paragraphs->{author} . "}\n\n");

}


sub _output_latex_command_definition_command_arguments
{
    my $command_definition = shift;

    my $ss = shift;

    my $cd_1 = $ss->{cd_1};

    my $ct_1 = $ss->{ct_1};

    # retrieve the shell command and its arguments

    my $command_line = $command_definition->cd_construct_command_line();

    my $arguments = $command_line->{arguments};

    my $command = $command_line->{command};

    my $command_string = join ' ', $command, @$arguments;

    if ($cd_1)
    {
	print $output_file '\item [$\bullet$]';
    }

    if ($ct_1)
    {
	_output_latex($output_file, 'The test is started with the system shell command: ');
    }
    else
    {
	_output_latex($output_file, 'The tests are started with the system shell command: ');
    }

    _output_latex_prompt($output_file, "textbf", $command_string, "", "\n\n");
}


sub _output_latex_command_definition_comments
{
    my $command_definition = shift;

    my $ss = shift;

    my $cd_1_comment = $ss->{cd_1_comment};

    if ($cd_1_comment)
    {
	print $output_file '\item [$\bullet$]';

	_output_latex_environment_minipage
	    (
	     $output_file,
	     {
	      content => $command_definition->{comment},
	      content_type => "minipage",
	      content_type_options => '{14cm}',
	      content_type_embedding => "small",
	      prompt => "NOTE\\::",
	      prompt_type => 'textbf',
	      suffix => "\n\n",
	     },
	    );
    }
}


sub _output_latex_command_definition_description
{
    my $command_definition = shift;

    my $ss = shift;

    my $cd_1 = $ss->{cd_1};

    my $ct_1 = $ss->{ct_1};

    my $description = $command_definition->{description};

    my $command_tests = $command_definition->{command_tests};

    if ($cd_1)
    {
	print $output_file '\item [$\bullet$]';

	_output_latex($output_file, "The following test is described as: $description\n");
    }
    else
    {
	if ($ct_1)
	{
	    my $subdescription = $command_tests->[0]->{description};

	    $description .= ": $subdescription";
	}

	_output_latex($output_file, '\subsection{' . ucfirst $description . "}\n\n");
    }
}


sub _output_latex_command_definition_disabled
{
    my $command_definition = shift;

    my $ss = shift;

    my $cd_1 = $ss->{cd_1};

    my $ct_1 = $ss->{ct_1};

    #! this seems to be wrong, cannot have the disabled
    #! clause of each command test in a isolated bullet,
    #! maybe this also needs a $ct_1?

#     print "TESTING\n";

    if ($cd_1
	and $command_definition->{disabled})
#     if ($command_definition->{disabled})
    {
# 	print "TESTING MORE\n";

	print $output_file '\item [$\bullet$]';

	_output_latex_prompt($output_file, "textbf", $command_definition->{disabled}, "note that this command definition was disabled: \n", "\n\n");
    }
}


sub _output_latex_command_definition_harnessing
{
    my $command_definition = shift;

    my $ss = shift;

    my $cd_1 = $ss->{cd_1};

    my $harnessing = $command_definition->{harnessing};

    if ($harnessing->{preparation})
    {
	if ($cd_1)
	{
	    print $output_file '\item [$\bullet$]';
	}

	_output_latex($output_file, '\begin{' . "itemize" . "}\n");

	_output_latex($output_file, '\item ');

	_output_latex_prompt($output_file, "textit", $command_definition->{harnessing}->{preparation}, "Preparation: ", "\n");

	_output_latex($output_file, '\item ');

	_output_latex_prompt($output_file, "textit", $command_definition->{harnessing}->{reparation}, "Reparation: ", "\n");

	_output_latex($output_file, '\end{' . "itemize" . "}\n");
    }
}


sub _output_latex_command_test_comments
{
    my $command_test = shift;

    my $ss = shift;

    my $cd_1 = $ss->{cd_1};

    if ($command_test->{comments})
    {
	if ($cd_1)
	{
	    print $output_file '\item [$\bullet$]';
	}

	_output_latex_environment_minipage
	    (
	     $output_file,
	     {
	      content => $command_test->{comment},
	      content_type => "minipage",
	      content_type_options => '{14cm}',
	      content_type_embedding => "small",
	      prompt => "NOTE\\::",
	      prompt_type => 'textbf',
	      suffix => "\n\n",
	     },
	    );
    }
}


sub _output_latex_command_test_description
{
    my $command_test = shift;

    my $ss = shift;

    my $ct_1 = $ss->{ct_1};

    my $description = $command_test->{description};

    if ($ct_1)
    {
	# _output_latex($output_file, "This test is described as: $description\n\n");
    }
    else
    {
	_output_latex($output_file, '\subsubsection{' . ucfirst $description . "}\n\n");
    }
}


sub _output_latex_command_test_disabled
{
    my $command_test = shift;

    my $ss = shift;

    my $cd_1 = $ss->{cd_1};

    #! this seems to be wrong, cannot have the disabled
    #! clause of each command test in a isolated bullet,
    #! maybe this also needs a $ct_1?

    # print "TESTING\n";

    if ($cd_1
	and $command_test->{disabled})
    {
	# print "TESTING MORE\n";

	print $output_file '\item [$\bullet$]';

	_output_latex_prompt($output_file, "textbf", $command_test->{disabled}, "note that this test was disabled: \n", "\n\n");
    }
}


sub _output_latex_command_test_read
{
    my $command_test = shift;

    my $ss = shift;

    my $cd_1 = $ss->{cd_1};

    my $read = $command_test->{read} || "";

    if ($read)
    {
	if ($cd_1)
	{
	    print $output_file '\item [$\bullet$]';
	}

	_output_latex_environment_prompt
	    (
	     $output_file,
	     {
	      content => $read,
	      content_line_limit => $option_output_content_line_limit,,
	      content_type => "Verbatim",
	      content_type_options => '[fontsize=\relsize{-2}]',
	      prompt => "Expected application output:\n",
	      suffix => "\n\n",
	     },
	    );
    }
}


sub _output_latex_command_test_write
{
    my $command_test = shift;

    my $ss = shift;

    my $cd_1 = $ss->{cd_1};

    my $write = $command_test->{write} || "";

    if ($write)
    {
	if ($cd_1)
	{
	    print $output_file '\item [$\bullet$]';
	}

	_output_latex_environment_prompt
	    (
	     $output_file,
	     {
	      content => $write,
	      content_line_limit => $option_output_content_line_limit,,
	      content_type => "Verbatim",
	      content_type_options => '[fontsize=\relsize{-2}]',
	      prompt => "The input to the application is:\n",
	      suffix => "\n\n",
	     },
	    );
    }
}


sub _output_latex_process
{
    my $output_filename = shift;

    my $test_report = shift;

    my $module_definitions = $test_report->{selected};

    my $ss = Heterarch::Test::Output::StructureSummary->new();

    foreach my $module_definition_key (sort
				       {
					   my $selected_a = $a;
					   my $selected_b = $b;

					   my $counter_a = $module_definitions->{$selected_a}->{count};
					   my $counter_b = $module_definitions->{$selected_b}->{count};

					   $counter_a <=> $counter_b;
				       }
				       keys %$module_definitions)
    {
	my $module_definition = $module_definitions->{$module_definition_key};

	my $module_definition_description = $module_definition->{description};

	my $module_definition_documentation = $module_definition->{documentation} || "";

	my $command_definitions = $module_definition->{command_definitions};

	# output the description as a section title

	_output_latex($output_file, '\section{' . ucfirst $module_definition_description . "}\n\n");

	# create indexes into the styling table

	$ss->ss_command_definitions($command_definitions);

	# output the filename

	_output_latex_module_filename_insert($module_definition, $module_definition_documentation, $ss);

	# output the documentation and explanation

	_output_latex_module_documentation($module_definition_documentation);

	# output the preparation and reparation

	_output_latex_module_harnessing($module_definition, $ss);

	# output comments / notes

	_output_latex_module_comments($module_definition);

	# output the command definitions

	foreach my $command_definition (@$command_definitions)
	{
	    # create indexes into the styling table

	    my $command_tests = $command_definition->{command_tests};

	    $ss->ss_command_tests($command_tests);

	    if ($ss->{cd_1})
	    {
		print $output_file '\begin{enumerate}[noitemsep,nolistsep]' . "\n";
	    }

	    # output the disabled clause

	    _output_latex_command_definition_disabled($command_definition, $ss);

	    # output the command_definition description

	    _output_latex_command_definition_description($command_definition, $ss);

	    # output the command and its arguments

	    _output_latex_command_definition_command_arguments($command_definition, $ss);

	    # output the command comments

	    _output_latex_command_definition_comments($command_definition, $ss);

	    # output the preparation and reparation

	    _output_latex_command_definition_harnessing($command_definition, $ss);

	    # loop over all the command tests

	    foreach my $command_test (@$command_tests)
	    {
		# output the disabled clause

		_output_latex_command_test_disabled($command_test, $ss);

		# output the description clause

		_output_latex_command_test_description($command_test, $ss);

		# output the write clause

		_output_latex_command_test_write($command_test, $ss);

		# output the read clause

		_output_latex_command_test_read($command_test, $ss);

		# if figures should be generated

		if ($option_output_figures)
		{
		    # loop over all the figures for this command test

		    my $figures = $command_test->{figures};

		    my $figure_references = [];

		    my $read = $command_test->{read} || "";

		    foreach my $figure (@$figures)
		    {
			_output_latex_figure_generate_insert($figure, $output_filename,  $command_test, $figure_references, $read);
		    }

		    if (scalar @$figure_references)
		    {
			$ss->ss_figure_references($figure_references);

			_output_latex_figure_references_insert($figure_references, $ss);
		    }
		}

		# output the comments clause

		_output_latex_command_test_comments($command_test, $ss);
	    }

	    if ($ss->{cd_1})
	    {
		print $output_file '\end{enumerate}' . "\n";
	    }
	}
    }
}


sub _output_latex_prompt
{
    my $outputfile = shift;

    my $content_type = shift;

    my $content = shift;

    my $prompt = shift;

    my $suffix = shift;

    if (defined $content)
    {
	_output_latex($output_file, $prompt);

	if ($content_type)
	{
	    print $output_file '\\' . $content_type . '{';
	}

	_output_latex($output_file, " $content ");

	if ($content_type)
	{
	    print $output_file "}";
	}
    }

    _output_latex($output_file, $suffix);
}


sub process
{
    my $self = shift;

    my $output_filename = shift;

    my $test_module_library_contents = shift;

    my $global_test_report = shift;

    _output_latex_preamble
	(
	 $output_filename,
	 $test_module_library_contents->{html_introduction},
	);

    _output_latex_process($output_filename, $global_test_report);

    _output_latex_postamble();
}


package Heterarch::Test::Output::Formatter::Figure;


sub generate_label
{
    my $self = shift;

    my $type = shift;

    # create the label for this figure

    my $figure_definition = $self->{figure_definition};

    my $context_path = $self->{context_path};

    #! this may be latex specific

    if ($type eq 'latex')
    {
	my $figure_label = "fig:$context_path-$figure_definition->{name}";

	# add it to the list of references

	my $figure_references = $self->{figure_references};

	push @$figure_references, $figure_label;

	# set figure label

	$self->{figure_label} = $figure_label;

	# return: no error

	return undef;
    }
    else
    {
	return  \ "$0: only latex labels have been implemented.";
    }
}


sub insert
{
    my $self = shift;

    my $figure_definition = shift;

    my $full_caption = $figure_definition->{caption}->{full};

    my $short_caption = $figure_definition->{caption}->{short};

    my $filenames = $self->{filenames};

    # insert the figure filename in the latex file

    $self->insert_figure_environment
	(
	 $output_file,
	 {
	  caption => [ $full_caption, ],
	  caption_short => [ $short_caption, ],
	  content_type_options => '[ht]',
	  includegraphics => $filenames,
	  label => $self->{figure_label},
	 },
	);

    # return result: no error

    return undef;
}


sub insert_figure_environment
{
    my $self = shift;

    my $outputfile = shift;

    my $content_options = shift;

    my $content_type_options = $content_options->{content_type_options} || "";
    my $includegraphics = $content_options->{includegraphics};
    my $caption = $content_options->{caption};
    my $caption_short = $content_options->{caption_short} || "";
    my $label = $content_options->{label};

# \begin{figure}
# \fbox{\includegraphics[width=\linewidth]{/tmp/abcdef-output_graph_render.pdf}}
# \end{figure}

# % \begin{figure}[ht]
# %   \includegraphics*[scale=0.1]{/tmp/abcdef-output_graph_render.pdf}
# % %  \resizebox{2cm}{!} {\includegraphics{/tmp/abcdef-output_graph_render.pdf}}
# %   \caption[Ten passive compartments voltage clamped]{\small Ten passive compartments clamped with command voltage of 0.1V using a perfect clamp object.}
# %   \label{fig:perfectclamp}
# % \end{figure}

    # if there is content

    if (defined $includegraphics)
    {
	# output the content begin marker

	print $output_file '\begin{figure}' . "$content_type_options\n";

# 	print $output_file '  \center'. "\n";

	my $width_divider = 1 / scalar @$includegraphics;

	my $includegraphics_options = "[width=$width_divider" . '\linewidth]';

	foreach my $includegraphic (@$includegraphics)
	{
	    print $output_file '  \includegraphics' . $includegraphics_options . "{$includegraphic}\n";
	}

	for (my $index = 0 ; $index < scalar @$caption ; $index++)
	{
# 	    print $output_file '  \begin{minipage}' . '{' . $width_divider . '\linewidth}' . "\n";

	    print $output_file '    \caption[' . $caption_short->[$index] . ']{\small \textbf{' . $caption->[$index] . '}}' . "\n";

# 	    print $output_file '  \end{minipage}' . "\n";
	}

	if ($label)
	{
	    print $output_file '  \label{'. $label . '}' . "\n";
	}

# \begin{figure}[ht]
#   \center
#   \includegraphics[scale=0.6]{figures/mstep.eps}
#   \caption[Staggered Time Grid]{\small \index{staggered
#       time grid} Mid step evaluation of membrane potential and
#     Hodgkin-Huxley equations.  To calculate the conductance at time
#     point 2, we need the membrane potential at time point 1.  To
#     calculate the membrane potential at time point 3, we need the
#     conductance at time point 2.  The membrane potential at time point
#     2 is never computed, neither the conductance at time point 3.}
#   \label{fig:midstep}
# \end{figure}

	# output the content end marker

	print $output_file '\end{figure}' . "\n\n";
    }

    # return result: no error

    return undef;
}


sub new
{
    my $package = shift;

    my $figure_definition = shift;

    my $filename_prefix = shift;

    my $command_test = shift;

    my $figure_references = shift;

    my $data_string = shift;

    my $context_path = $command_test->{context_path};

    $context_path =~ s(/)(___)g;
    $context_path =~ s(\.)(__)g;

    my $pathname_prefix = "$filename_prefix$context_path-$figure_definition->{name}";

    my $self
	= {
	   context_path => $context_path,
	   data_string => $data_string,
	   figure_definition => $figure_definition,
	   figure_references => $figure_references,
	   filename_prefix => $filename_prefix,
	   pathname_prefix => $pathname_prefix,
	  };

    bless $self, $package;

    return $self;
}


sub render_raw_data
{
    my $self = shift;

    my $output_filename = shift;

    my $data_string = shift;

    # create the data file

    my $figure_definition = $self->{figure_definition};

    my $pathname_prefix = $self->{pathname_prefix};

    my $data_filename = $pathname_prefix . "_output_graph_render_data";

    my $fh_data = IO::File->new("> $data_filename");

    if (not defined $fh_data)
    {
	return \ "$0: render_raw_data(): error opening result data file";
    }

    # write the data

    print $fh_data $data_string;;

    $fh_data->close();

    # create the figure_definition file

    my $figure_definition_filename = $pathname_prefix . "_output_graph_render_figure_definition.yml";

    YAML::DumpFile($figure_definition_filename, $figure_definition);

    # create the figure graph

    my $command = "data_2_figure --figure-filename '$figure_definition_filename' --input-data '$data_filename' --output-filename '$output_filename'";

    # if ($option_verbose)
    # {
    # 	print $global_fd_output "$0: Executing '$command'\n";
    # }

    system $command;

    if ($?)
    {
	return \ "$0: render_raw_data: '$command' failed";
    }
    else
    {
	return undef;
    }
}


sub render_array
{
    my $self = shift;

    my $output_filename = shift;

    my $array = shift;

    my $start = shift;

    my $end = shift;

    my $step = shift;

    # convert the array to raw_data

    my $raw_data = "";

    foreach my $entry (@$array)
    {
	$raw_data .= "$start $entry\n";

	$start += $step;
    }

    # render the raw data, result is the figure filename

    my $error = $self->render_raw_data($output_filename, $raw_data);

    if ($error)
    {
	return $error;
    }
    else
    {
	return $output_filename;
    }
}


package Heterarch::Test::Output::Formatter::Figure::HHGatesAB;


our @ISA = ("Heterarch::Test::Output::Formatter::Figure");


package Heterarch::Test::Output::Formatter::Figure::HHGatesAlphaBeta;


our @ISA = ("Heterarch::Test::Output::Formatter::Figure");


sub insert
{
    my $self = shift;

    my $figure_definition = shift;

    my $full_caption = $figure_definition->{caption}->{full};

    my $short_caption = $figure_definition->{caption}->{short};

    my $filenames = $self->{filenames};

    # insert the figure filename in the latex file

    $self->insert_figure_environment
	(
	 $output_file,
	 {
	  caption_main => $full_caption,
	  caption_main_short => $short_caption,
	  content_type_options => '[ht]',
	  includegraphics => $filenames,
	  label => $self->{figure_label},
	 },
	);
}


sub insert_figure_environment
{
    my $self = shift;

    my $outputfile = shift;

    my $content_options = shift;

    my $content_type_options = $content_options->{content_type_options} || "";
    my $includegraphics = $content_options->{includegraphics};
    my $caption = $content_options->{caption};
    my $caption_main = $content_options->{caption_main} || "";
    my $caption_main_short = $content_options->{caption_main_short} || "";
    my $caption_short = $content_options->{caption_short} || "";
    my $label = $content_options->{label};

    # if there is content

    if (defined $includegraphics)
    {
	# output the content begin marker

	print $output_file '\begin{figure}' . "$content_type_options\n";

	my $width_divider = 2 / scalar @$includegraphics;

	for (my $index = 0 ; $index < scalar @$includegraphics ; $index++)
	{
	    my $includegraphic = $includegraphics->[$index];

	    print $output_file '  \begin{subfigure}' . '{' . $width_divider . '\textwidth}' . "\n";

	    print $output_file '  \centering' . "\n";

	    my $includegraphics_options = "[width=.9" . '\linewidth]';

	    print $output_file '    \includegraphics' . $includegraphics_options . "{$includegraphic}\n";

# 	    print $output_file '    \caption[' . $caption_short->[$index] . ']{\small \textbf{' . $caption->[$index] . '}}' . "\n";

 	    print $output_file '  \end{subfigure}' . "\n";
	}

	if ($caption_main)
	{
	    print $output_file '    \caption[' . $caption_main_short . ']{\small \textbf{' . $caption_main . '}}' . "\n";
	}

	if ($label)
	{
	    print $output_file '  \label{'. $label . '}' . "\n";
	}

	# output the content end marker

	print $output_file '\end{figure}' . "\n\n";
    }

    # return result: no error

    return undef;
}


sub new
{
    my $self = shift;

    $self = $self->SUPER::new(@_);

    my $variables
	= [
	   {
	    name => "Activation",
	    regex_parser => '-?[0-9]+\.[-e0-9]+ (-?[0-9]+\.[-e0-9]+)',
	   },
	  ];

    $self->{figure_definition}->{variables} = $variables;

    return $self;
}


sub render
{
    my $self = shift;

    # convert the data string to a data structure

    use YAML;

    my $data_string = $self->{data_string};

    # remove object class references

    $data_string =~ s(!!.*?\n)(\n)g;

    # load all documents

    my $data_structured = [ Load($data_string), ];

    # split the data into its two components

    my $data_structured_forward = $data_structured->[0];

    my $data_structured_backward = $data_structured->[1];

    # render the values: forward kinetics

    my $data_a_forward = $data_structured_forward->{alpha};

    my $hi_forward = $data_structured_forward->{hi};

    my $pathname_prefix = $self->{pathname_prefix};

    my $output_filename_a_forward = "$pathname_prefix-a-forward-output_graph_render.png";

    my $figure_filename_a_forward = $self->render_array($output_filename_a_forward, $data_a_forward, $hi_forward->{start}, $hi_forward->{end}, $hi_forward->{step});

    if (ref $figure_filename_a_forward)
    {
	return $figure_filename_a_forward;
    }

    my $data_b_forward = $data_structured_forward->{beta};

    my $output_filename_b_forward = "$pathname_prefix-b-forward-output_graph_render.png";

    my $figure_filename_b_forward = $self->render_array($output_filename_b_forward, $data_b_forward, $hi_forward->{start}, $hi_forward->{end}, $hi_forward->{step});

    if (ref $figure_filename_b_forward)
    {
	return $figure_filename_b_forward;
    }

    # render the values: backward kinetics

    my $data_a_backward = $data_structured_backward->{alpha};

    my $hi_backward = $data_structured_backward->{hi};

    my $output_filename_a_backward = "$pathname_prefix-a-backward-output_graph_render.png";

    my $figure_filename_a_backward = $self->render_array($output_filename_a_backward, $data_a_backward, $hi_backward->{start}, $hi_backward->{end}, $hi_backward->{step});

    if (ref $figure_filename_a_backward)
    {
	return $figure_filename_a_backward;
    }

    my $data_b_backward = $data_structured_backward->{beta};

    my $output_filename_b_backward = "$pathname_prefix-b-backward-output_graph_render.png";

    my $figure_filename_b_backward = $self->render_array($output_filename_b_backward, $data_b_backward, $hi_backward->{start}, $hi_backward->{end}, $hi_backward->{step});

    if (ref $figure_filename_b_backward)
    {
	return $figure_filename_b_backward;
    }

    # set the filenames of the rendered graphs

    my $filenames = [ $figure_filename_a_forward, $figure_filename_b_forward, $figure_filename_a_backward, $figure_filename_b_backward, ];

    $self->{filenames} = $filenames;

    # return: no error

    return undef;
}


package Heterarch::Test::Output::Formatter::Figure::HHGatesInternal;


our @ISA = ("Heterarch::Test::Output::Formatter::Figure");


sub generate_label
{
    my $self = shift;

    return $self->SUPER::generate_label(@_);
}


sub insert
{
    my $self = shift;

    my $figure_definition = shift;

    my $full_caption = $figure_definition->{caption}->{full};

    my $short_caption = $figure_definition->{caption}->{short};

    my $filenames = $self->{filenames};

    # insert the figure filename in the latex file

    $self->insert_figure_environment
	(
	 $output_file,
	 {
	  caption => [
		      $figure_definition->{caption_A}->{full},
		      $figure_definition->{caption_B}->{full},
		     ],
	  caption_main => $figure_definition->{caption}->{full},
	  caption_main_short => $figure_definition->{caption}->{short},
	  caption_short => [
			    $figure_definition->{caption_A}->{short},
			    $figure_definition->{caption_B}->{short},
			   ],
	  content_type_options => '[ht]',
	  includegraphics => $filenames,
	  label => $self->{figure_label},
	 },
	);
}


sub insert_figure_environment
{
    my $self = shift;

    my $outputfile = shift;

    my $content_options = shift;

    my $content_type_options = $content_options->{content_type_options} || "";
    my $includegraphics = $content_options->{includegraphics};
    my $caption = $content_options->{caption};
    my $caption_main = $content_options->{caption_main} || "";
    my $caption_main_short = $content_options->{caption_main_short} || "";
    my $caption_short = $content_options->{caption_short} || "";
    my $label = $content_options->{label};

    # if there is content

    if (defined $includegraphics)
    {
	# output the content begin marker

	print $output_file '\begin{figure}' . "$content_type_options\n";

	my $width_divider = 1 / scalar @$includegraphics;

	for (my $index = 0 ; $index < scalar @$includegraphics ; $index++)
	{
	    my $includegraphic = $includegraphics->[$index];

	    print $output_file '  \begin{subfigure}' . '{' . $width_divider . '\textwidth}' . "\n";

	    print $output_file '  \centering' . "\n";

	    my $includegraphics_options = "[width=.9" . '\linewidth]';

	    print $output_file '    \includegraphics' . $includegraphics_options . "{$includegraphic}\n";

	    print $output_file '    \caption[' . $caption_short->[$index] . ']{\small \textbf{' . $caption->[$index] . '}}' . "\n";

 	    print $output_file '  \end{subfigure}' . "\n";
	}

	if ($caption_main)
	{
	    print $output_file '    \caption[' . $caption_main_short . ']{\small \textbf{' . $caption_main . '}}' . "\n";
	}

	if ($label)
	{
	    print $output_file '  \label{'. $label . '}' . "\n";
	}

	# output the content end marker

	print $output_file '\end{figure}' . "\n\n";
    }

    # return result: no error

    return undef;
}


sub new
{
    my $self = shift;

    $self = $self->SUPER::new(@_);

    my $variables
	= [
	   {
	    name => "Activation",
	    regex_parser => '-?[0-9]+\.[-e0-9]+ (-?[0-9]+\.[-e0-9]+)',
	   },
	  ];

    $self->{figure_definition}->{variables} = $variables;

    return $self;
}


sub render
{
    my $self = shift;

    # convert the data string to a data structure

    use YAML;

    my $data_string = "---
$self->{data_string}";

    # remove object class references

    $data_string =~ s(!!.*?\n)();

    my $data_structured = Load($data_string);

    # split the data into its two components

    my $data_a = $data_structured->{A};

    my $hi = $data_structured->{hi};

    my $pathname_prefix = $self->{pathname_prefix};

    my $output_filename_a = "$pathname_prefix-a-output_graph_render.png";

    my $figure_filename_a = $self->render_array($output_filename_a, $data_a, $hi->{start}, $hi->{end}, $hi->{step});

    if (ref $figure_filename_a)
    {
	return $figure_filename_a;
    }

    my $data_b = $data_structured->{B};

    my $output_filename_b = "$pathname_prefix-b-output_graph_render.png";

    my $figure_filename_b = $self->render_array($output_filename_b, $data_b, $hi->{start}, $hi->{end}, $hi->{step});

    if (ref $figure_filename_b)
    {
	return $figure_filename_b;
    }

    # set the filenames of the rendered graphs

    my $filenames = [ $figure_filename_a, $figure_filename_b, ];

    $self->{filenames} = $filenames;

    # return: no error

    return undef;
}


package Heterarch::Test::Output::Formatter::Figure::HHGatesSteadyStateTau;


our @ISA = ("Heterarch::Test::Output::Formatter::Figure");


package Heterarch::Test::Output::Formatter::Figure::Simple;


our @ISA = ("Heterarch::Test::Output::Formatter::Figure");


sub generate_label
{
    my $self = shift;

    return $self->SUPER::generate_label(@_);
}


sub new
{
    my $self = shift;

    return $self->SUPER::new(@_);
}


sub render
{
    my $self = shift;

    my $pathname_prefix = $self->{pathname_prefix};

    my $output_filename = "$pathname_prefix-output_graph_render.png";

    my $error = $self->SUPER::render_raw_data($output_filename, $self->{data_string});

    if ($error)
    {
	return $error;
    }
    else
    {
	# set the filenames of the rendered graphs

	my $filenames = [ $output_filename, ];

	$self->{filenames} = $filenames;

	# return: no error

	return undef;
    }
}


package Heterarch::Test::Output::Formatter::PDF;

# The Heterarch::Test::Output::Formatter::Latex package converts the test specifications
# to a Latex document.


our @ISA = ("Heterarch::Test::Output::Formatter::Latex");


sub _output_pdf_process
{
    use File::Basename qw( fileparse );
    use File::Path qw( make_path );
    use File::Spec;

    my $output_filename = shift;

    my ( $logfile, $directory ) = fileparse($output_filename);

    my $command = "cd '$directory' && pdflatex '$output_filename' && pdflatex '$output_filename'";

    system $command;
}


sub process
{
    # my $result = Heterarch::Test::Output::Formatter::PDF->SUPER::process(@_);

    my $self = shift;

    my $output_filename = shift;

    my $test_module_library_contents = shift;

    my $global_test_report = shift;

    my $result
	= $self->SUPER::process
	(
	 $output_filename,
	 $test_module_library_contents,
	 $global_test_report
	);

    _output_pdf_process($output_filename);
}


package Heterarch::Test::Output::Formatter::YAML::Summary;

# The Formatter:YAML::Summary package converts the test specifications
# to a YAML formatted summary.


our @ISA = ("Heterarch::Test::Output::Summarizer");


#
# Create the infrastructure for keeping module test results.
#

sub ex_mo_prepare
{
    my $self = shift;

    # get the execution context

    my $execution_context = $self->{execution_context};

    # create an output entry for the module

    my $module_definition = $execution_context->get_module_definition();

    my $module_name = $module_definition->{name};

    if (not $global_test_report->{selected}->{$module_name})
    {
	$global_test_report->{selected}->{$module_name} = [];
    }
    else
    {
	die "$0: *** Error: module_name $module_name is defined twice.";
    }
}


# add the current test description to the summary

sub ex_ct_run
{
    my $self = shift;

    my $command_test = shift;

    my $execution_context = $self->{execution_context};

    my $command_definition = $execution_context->get_command_definition();

    my $module_definition = $execution_context->get_module_definition();

    my $module_name = $module_definition->{name};

    # get the current module summary

    my $selected_module = $global_test_report->{selected}->{$module_name};

    # get the current test summary

    my $selected_command_definitions = $selected_module->[$#$selected_module]->{tests};

    # add the current test description to the summary

    push @$selected_command_definitions, $command_test->{description};

    # always succeeds

    my $test_result
	= {
	   after_match => "",
	   before_match => "",
	   error => "",
	   expected => "",
	   matched_pattern_position => "",
	   successfully_matching_string => "",
	  };

    return $test_result;
}


# create an output entry for the current command definition

sub ex_cd_start
{
    my $self = shift;

    # get the execution context

    my $execution_context = $self->{execution_context};

    # create an output entry for the module

    my $module_definition = $execution_context->get_module_definition();

    my $module_name = $module_definition->{name};

    # create an output entry for the current command definition

    my $selected_module = $global_test_report->{selected}->{$module_name};

    my $command_definition = $execution_context->get_command_definition();

    push @$selected_module, { description => $command_definition->{description}, tests => [], };
}


# note that this implementation is the same as the one of ex_terminate() in
# Heterarch::Test::Output::Formatter::YAML::CommandTests

sub ex_terminate
{
    my $self = shift;

    my $test_module_library_contents = shift;

    # yaml out the test report

    my $report_yaml
	= {
	   description => $global_test_report->{description},
	  };

    # add output specific to the output selection

    if ($option_report_disabled)
    {
	$report_yaml->{disabled} = $global_test_report->{disabled};
    }

    $report_yaml->{selected} = $global_test_report->{selected};

    use YAML;

    my $report_text = "\n" . Dump($report_yaml);

    my $execution_context = $self->{execution_context};

    my $reporter = $execution_context->{reporter};

    $reporter->report_message_info_no_rulers("message_info", "$report_text");
}


package Heterarch::Test::Output::Formatter::YAML::CommandTests;

# The Formatter:YAML::CommandTests package converts the test
# specifications to a YAML formatted list of commands and their input
# in the write clauses, that would be executed if the tests are run.


our @ISA = ("Heterarch::Test::Output::Summarizer");


#
# Create the infrastructure for keeping module test results.
#

sub ex_mo_prepare
{
    my $self = shift;

}


# create an output entry for the current command definition
# add the current test description to the summary

sub ex_ct_run
{
    my $self = shift;

    my $command_test = shift;

    my $execution_context = $self->{execution_context};

    my $command_definition = $execution_context->get_command_definition();

    my $module_definition = $execution_context->get_module_definition();

    my $module_name = $module_definition->{name};

    # only if there is something to add

    if (exists $command_test->{write}
        and defined $command_test->{write})
    {
	# get the current module summary

	my $selected_module = $global_test_report->{selected}->{$module_name};

	# get the current test summary

	if (not exists $selected_module->[$#$selected_module]->{tests})
	{
	    $selected_module->[$#$selected_module]->{tests} = [];
	}

	my $selected_command_definitions = $selected_module->[$#$selected_module]->{tests};

	# add the current test write clause to the summary

	push @$selected_command_definitions, $command_test->{write};
    }

    # always succeeds

    my $test_result
	= {
	   after_match => "",
	   before_match => "",
	   error => "",
	   expected => "",
	   matched_pattern_position => "",
	   successfully_matching_string => "",
	  };

    return $test_result;
}


sub ex_cd_start
{
    my $self = shift;

    # get the execution context

    my $execution_context = $self->{execution_context};

    # create an output entry for the module

    #t we could add a counter here to keep the order of execution in the final yaml output

    my $module_definition = $execution_context->get_module_definition();

    my $module_name = $module_definition->{name};

    my $command_definition = $execution_context->get_command_definition();

    if (exists $command_definition->{command})
    {
	if (not $global_test_report->{selected}->{$module_name})
	{
	    $global_test_report->{selected}->{$module_name} = [];
	}

	# create an output entry for the current command definition

	my $selected_module = $global_test_report->{selected}->{$module_name};

	# retrieve the shell command and its arguments

	my $command_line = $command_definition->cd_construct_command_line();

	my $arguments = $command_line->{arguments};

	my $command = $command_line->{command};

	my $command_string = $command . ' ' . join ' ', @ { $arguments || [] };

	push @$selected_module, { command => $command_string, };
    }
}


# note that this implementation is the same as the one of ex_terminate() in
# Heterarch::Test::Output::Formatter::YAML::Summary

sub ex_terminate
{
    my $self = shift;

    my $test_module_library_contents = shift;

    # yaml out the test report

    my $report_yaml
	= {
	   description => $global_test_report->{description},
	  };

    # add output specific to the output selection

    if ($option_report_disabled)
    {
	$report_yaml->{disabled} = $global_test_report->{disabled};
    }

    $report_yaml->{selected} = $global_test_report->{selected};

    use YAML;

    my $report_text = "\n" . Dump($report_yaml);

    my $execution_context = $self->{execution_context};

    my $reporter = $execution_context->{reporter};

    $reporter->report_message_info_no_rulers("message_info", "$report_text");
}


package Heterarch::Test::Output::Definitions;

# The Heterarch::Test::Output::Definitions package should list all the
# supported constructs that can be used in the test specifications.
#
# This list has been developed in a separate emacs-org document.
#

#t unclear how this was supposed to be used.

our @ISA = ("Heterarch::Test::Output::Summarizer");


package Heterarch::Test::Output::List;

# this package should list the constructs used in the selected test
# specifications.

# inherit from the yaml summary to automate text context tracking through its start sub

our @ISA = ("Heterarch::Test::Output::Formatter::YAML::Summary");


sub ex_ct_run
{
    my $self = shift;

    my $command_test = shift;

    my $execution_context = $self->{execution_context};

    my $command_definition = $execution_context->get_command_definition();

    my $module_definition = $execution_context->get_module_definition();

}


package Heterarch::Test::Output::StructureSummary;


sub ss_command_definitions
{
    my $self = shift;

    my $command_definitions = shift;

    $self->{cd_0} = scalar @$command_definitions eq 0 ? 1 : 0;
    $self->{cd_1} = scalar @$command_definitions eq 1 ? 1 : 0;
    $self->{cd_1_comment} = $self->{cd_1} && exists $command_definitions->[0]->{comment};
}


sub ss_command_tests
{
    my $self = shift;

    my $command_tests = shift;

    $self->{ct_0} = defined $command_tests && scalar @$command_tests eq 0 ? 1 : 0;
    $self->{ct_1} = defined $command_tests && scalar @$command_tests eq 1 ? 1 : 0;
}


sub ss_figure_references
{
    my $self = shift;

    my $figure_references = shift;

    # $self->{fr_0} = scalar @$figure_references eq 0 ? 1 : 0;
    # $self->{fr_1} = scalar @$figure_references eq 1 ? 1 : 0;
}


sub new
{
    my $package = shift;

    my $self
	= {
	   cd_0 => undef,
	   cd_1 => undef,
	   cd_1_comment => undef,
	   ct_0 => undef,
	   ct_1 => undef,
	   # fr_0 => undef,
	   # fr_1 => undef,
	  };

    bless $self, $package;

    return $self
}


package Heterarch::Test::Reporting;


our $console_types
    = {
       linear => 'linearly flowing text',
       status => 'single line status bars',
      };


sub end
{
    my $self = shift;
}


sub new
{
    my $package = shift;

    my $options = shift || {};

    my $self
	= {
	   %$options,
	  };

    bless $self, $package;

    return $self;
}


sub message
{
    my $self = shift;

    my $line = shift;

    my $arguments = shift;

    Heterarch::Test::Reporting::ConsoleWindow::message($self->{configuration}, $line, $arguments);
}


sub _differences_process
{
    my $fd_output = shift;

    my $arguments = shift;

    my $expected = $arguments->{expected};
    my $seen = $arguments->{seen};

    my $differences_report
	= {
	   expected => $expected,
	   seen => $seen,
	  };

    if (defined $expected
	and defined $seen)
    {
	use IO::File;

	my $expected_filename = "/tmp/text_$global_config->{package}->{name}_$global_error_count.expected";

	$differences_report->{expected_filename} = $expected_filename;

	my $expected_file = IO::File->new(">$expected_filename");

	if ($expected_file)
	{
	    print $expected_file $expected;

	    $expected_file->close();
	}
	else
	{
	    print $fd_output "*** Warning: cannot open $expected_filename for writing\n";
	}

	my $seen_filename = "/tmp/text_$global_config->{package}->{name}_$global_error_count.seen";

	$differences_report->{seen_filename} = $seen_filename;

	my $seen_file = IO::File->new(">$seen_filename");

	if ($seen_filename)
	{
	    print $seen_file $seen;

	    $seen_file->close();
	}
	else
	{
	    print $fd_output "*** Warning: cannot open $seen_filename for writing\n";
	}

	my $diff = `diff "$expected_filename" "$seen_filename"`;

	$differences_report->{diff} = $diff;

	my $diff_filename = "/tmp/text_$global_config->{package}->{name}_$global_error_count.diff";

	$differences_report->{diff_filename} = $diff_filename;

	my $diff_file = IO::File->new(">$diff_filename");

	if ($diff_file)
	{
	    print $diff_file $diff;

	    $diff_file->close();
	}
	else
	{
	    print $fd_output "*** Warning: cannot open $diff_filename for writing\n";
	}


	{
	    my $processed_expected = [ split "\n", $expected, ];

	    $processed_expected = join "\n*** Error $global_error_count: expected: ", "", @$processed_expected, "\n";

	    $differences_report->{processed_expected} = $processed_expected;

	    my $processed_seen = [ split "\n", $seen, ];

	    $processed_seen = join "\n*** Error $global_error_count: seen: ", "", @$processed_seen, "\n";

	    $differences_report->{processed_seen} = $processed_seen;

	    my $processed_diff = [ split "\n", $diff, ];

	    $processed_diff = join "\n*** Error $global_error_count: diff: ", "", @$processed_diff, "\n";

	    $differences_report->{processed_diff} = $processed_diff;
	}
    }

    return $differences_report;
}


sub _global_error_add
{
    my $error_report = shift;

    my $context_path = $error_report->{context_path};
    my $description = $error_report->{description};
    my $error = $error_report->{error};
    my $message = $error_report->{message};
    my $module_name = $error_report->{module_name};
    my $subdescription = $error_report->{subdescription};

    $global_error_count++;

    # fill in the error report

    $global_test_report->{global}->{error_count} = $global_error_count;

    my $error_report_brief
	= {
	   context_path => $context_path,
	   error => $error,
	   (defined $subdescription) ? ($subdescription => { description => $description, }, ) : (description => $description),
	  };

    if (defined $message)
    {
	#! if message is defined, then a subdescription must be defined too.

	$error_report_brief->{$subdescription}->{report} = $message;
    }

    $global_test_report->{errors}->{modules}->{$module_name}->{$global_error_count} = $error_report_brief;

    $global_test_report->{errors}->{error_reports}->{$global_error_count} = $error_report;
}


sub _report_error_add
{
    my $self = shift;

    my $arguments = shift;

    use Clone 'clone';

    my $error_report = clone($arguments);

    if (defined $option_debugging
	and $option_debugging eq 'errors')
    {
	use Carp;

	warn "$0: DEBUG errors";

	print Carp::cluck(@_);
    }

    my $fd_output = $self->{fd_output};

    my $differences_report = _differences_process($fd_output, $error_report);

    $error_report->{differences_report} = $differences_report;

    _global_error_add($error_report);

    return $error_report;
}


sub start
{
    my $self = shift;
}


# A console window implementation to display diagnostic messages.

package Heterarch::Test::Reporting::ConsoleWindow;


my $cursor_up = "\033[A";
my $cursor_down = "\033[B";
my $cursor_forced_down = "\n";
my $erase_line = "\33[2K";


sub message
{
    my $self = shift;

    my $line = shift;

    my $arguments = shift;

    my $enabled = $self->{$line}->{enabled} || 'by default';

    if ($enabled)
    {
	$self->{has_been_used} = 'yes';

	my $formatter_options = $self->{$line};

	my $line_number = $formatter_options->{line_number};

	my $control_prefix = $cursor_forced_down x $line_number . $erase_line;

	$control_prefix .= "\r$formatter_options->{prompt}";

	my $formatter = $formatter_options->{formatter};

        my $user_message = &$formatter($formatter_options, $arguments);

	my $control_suffix = ($line ne "end") ? ("\r" . ($cursor_up x $line_number)) : "\n";

	_emit($control_prefix, $user_message, $control_suffix);

	if ($line ne "end")
	{
	    # see https://stackoverflow.com/questions/33812618/can-you-force-flush-output-in-perl

	    select()->flush();
	}
    }
}


sub _emit
{
    my $control_prefix = shift;

    my $user_message = shift;

    my $control_suffix = shift;

    # make sure we end the cursor where we started with it

    my $newline_count = $user_message =~ tr/\n/\n/;

    my $message = $user_message . ($cursor_up x $newline_count);

    # print the message at the correct location and move the cursor back to the origin

    print $control_prefix . $message . $control_suffix;
}


sub note
{
    my $line_options = shift;

    my $arguments = shift;

    my $length = $line_options->{length};

    my $message = $arguments->{message};

    if (length $message > $length)
    {
	$message = substr($message, 0, $length);
    }

    return $message;
}


# print iterations progress.
#
# modified from https://stackoverflow.com/questions/3173320/text-progress-bar-in-terminal-with-block-characters
#

#     """
#     Call in a loop to create terminal progress bar
#     @params:
#         iteration   - Required  : current iteration (Int)
#         total       - Required  : total iterations (Int)
#         prefix      - Optional  : prefix string (Str)
#         suffix      - Optional  : suffix string (Str)
#         decimals    - Optional  : positive number of decimals in percent complete (Int)
#         length      - Optional  : character length of bar (Int)
#         fill        - Optional  : bar fill character (Str)
#     """

my $black   = "\033[0;30m";
my $red     = "\033[0;31m";
my $green   = "\033[0;32m";
my $yellow  = "\033[0;33m";
my $white   = "\033[0;37m";
my $nocolor = "\033[0m";

my $simple_bar_spinner = [ '<->', '<\>', '<|>', '</>', ];

# based on https://stackoverflow.com/questions/2685435/cooler-ascii-spinners

my $arrow_spinner = [ '←', '↖', '↑', '↗', '→', '↘', '↓', '↙', ];
my $impatient_clock_hands_spinner = [ '◴', '◷', '◶', '◵', ];
my $impatient_pie_clock_spinner = [ '◐', '◓', '◑', '◒', ];
my $jumping_block_spinner = [ '▖', '▘', '▝', '▗', ];
my $overdoing_braille_spinner = [ '⣾', '⣽', '⣻', '⢿', '⡿', '⣟', '⣯', '⣷', ];
my $right_angle__spinner = [ '┤', '┘', '┴', '└', '├', '┌', '┬', '┐', ];
my $rising_block_spinner = ['▁','▃','▄','▅','▆','▇','█','▇','▆','▅','▄','▃', ];
my $simple_braille_spinner = [ '⠁', '⠂', '⠄', '⡀', '⢀', '⠠', '⠐', '⠈', ];
my $square_corner_spinner = [ '◰', '◳', '◲', '◱', ];
my $triangle_spinner = [ '◢', '◣', '◤', '◥', ];
my $tworolling_eyes_spinner = [ '◡◡', '⊙⊙', '◠◠', ];
my $vertical_line_spinner = [ '▉', '▊', '▋', '▌', '▍', '▎', '▏', '▎', '▍', '▌', '▋', '▊', '▉', ];

my $careted_rising_block_spinner = ['<▁▁▁>','<▃▃▃>','<▄▄▄>','<▅▅▅>','<▆▆▆>','<▇▇▇>','<███>','<▇▇▇>','<▆▆▆>','<▅▅▅>','<▄▄▄>','<▃▃▃>', ];

my $colored_careted_rising_block_spinner
    = [
        "<$green▁▁▁$nocolor>",
        "<$green▃▃▃$nocolor>",
       "<$yellow▄▄▄$nocolor>",
       "<$yellow▅▅▅$nocolor>",
       "<$yellow▆▆▆$nocolor>",
          "<$red▇▇▇$nocolor>",
          "<$red███$nocolor>",
          "<$red▇▇▇$nocolor>",
          "<$red▆▆▆$nocolor>",
       "<$yellow▅▅▅$nocolor>",
       "<$yellow▄▄▄$nocolor>",
        "<$green▃▃▃$nocolor>",
      ];

my $long_block_spinner = [ '█████', ];

# more can be found here:
# https://antofthy.gitlab.io/info/ascii/Spinners.txt
# https://gist.github.com/asika32764/19956edcc5e893b2cbe3768e91590cf1

my $spinners
    = {
       arrow_spinner => $arrow_spinner,
       careted_rising_block_spinner => $careted_rising_block_spinner,
       colored_careted_rising_block_spinner => $colored_careted_rising_block_spinner,
       impatient_clock_hands_spinner => $impatient_clock_hands_spinner,
       impatient_pie_clock_spinner => $impatient_pie_clock_spinner,
       jumping_block_spinner => $jumping_block_spinner,
       long_block_spinner => $long_block_spinner,
       overdoing_braille_spinner => $overdoing_braille_spinner,
       right_angle__spinner => $right_angle__spinner,
       rising_block_spinner => $rising_block_spinner,
       simple_bar_spinner => $simple_bar_spinner,
       simple_braille_spinner => $simple_braille_spinner,
       square_corner_spinner => $square_corner_spinner,
       triangle_spinner => $triangle_spinner,
       tworolling_eyes_spinner => $tworolling_eyes_spinner,
       vertical_line_spinner => $vertical_line_spinner,
     };

my $global_spinner = $spinners->{careted_rising_block_spinner};
my $global_scalar_spinner = scalar @$global_spinner;

my $global_iteration_no_total = 0;

sub progress
{
    my $line_options = shift;

    my $arguments = shift;

    my $iteration = $arguments->{iteration};

    my $total = $arguments->{total};

    my $prefix = $arguments->{prefix} || '';

    my $suffix = $arguments->{suffix} || '';

    if (!defined $iteration)
    {
	$iteration = -1;
    }

    if (!defined $total)
    {
	$total = -1;
    }

    my $options = $line_options->{formatter_options};

    if ($total eq -1)
    {
        $total = $options->{total};
    }

    if ($prefix eq '')
    {
        $prefix = $options->{prefix} || '';
    }

    if ($suffix eq '')
    {
        $suffix = $options->{suffix} || '';
    }

    my $length = $line_options->{length};

    my $without_bar = "$prefix||  $suffix";

    my $without_bar_length = length($without_bar);

    my $message;

    if ($total == 0)
    {
	if ($iteration == -1)
	{
	    $global_iteration_no_total++;

	    $iteration = $global_iteration_no_total;
	}

	my $bar_prefix = '-';

        my $bar_cursor = $global_spinner->[$iteration % ($global_scalar_spinner)];

        my $bar_suffix = '-';

	my $bar_prefix_length = $iteration;

        my $bar_length = $length - $without_bar_length - length($bar_cursor);

        my $bar_wrap_arounds = int($iteration / $bar_length);

        my $bar_direction = $bar_wrap_arounds % 2; # 0: to the right and requires addition, 1: to the left and requires subtraction

        my $bar_cursor_position = $bar_prefix_length % $bar_length;

        if ($bar_direction == 1)
	{
            $bar_cursor_position = $bar_length - $bar_cursor_position;

            $bar_cursor = $global_spinner->[($global_scalar_spinner) - $iteration % ($global_scalar_spinner) - 1];
	}

        # bar_cursor = f"<{iteration},{bar_wrap_arounds},{bar_direction},{bar_prefix_length},{bar_cursor_position},{bar_length}>"
        my $bar = ($options->{empty} x $bar_cursor_position) . $bar_cursor . ($options->{empty} x ($bar_length - $bar_cursor_position));

        $message = "$prefix|$bar| $suffix";
    }
    else
    {
	my $percent = '';

	my $needs_percentage = exists $options->{percentage} ? $options->{percentage} : 'by default';

	if ($needs_percentage)
	{
	    $percent = sprintf("%.$options->{decimals}f", 100 * ($iteration / $total));

	    $percent = "$percent% ";

	    $without_bar_length += 5
	}

	my $bar_length = $line_options->{length} - $without_bar_length;

	my $filledLength = int($bar_length * $iteration / $total);

	my $bar = ($options->{fill} x $filledLength) . ($options->{empty} x ($bar_length - $filledLength));

	$message = "$prefix|$bar| $percent$suffix";
    }

    return $message;
}


package Heterarch::Test::Reporting::Linear;


our @ISA = ("Heterarch::Test::Reporting");


sub _error_report_differences
{
    my $fd_output = shift;

    my $error_report = shift;

    if (exists $error_report->{differences_report})
    {
	my $differences_report = $error_report->{differences_report};

	my $processed_expected = $differences_report->{processed_expected};
	my $processed_seen = $differences_report->{processed_seen};
	my $processed_diff = $differences_report->{processed_diff};

	if (defined $processed_expected
	    and defined $processed_seen)
	{
	    print $fd_output $processed_expected;

	    print $fd_output $processed_seen;

	    print $fd_output $processed_diff;
	}
    }
}


sub report_error_add
{
    my $self = shift;

    my $arguments = shift;

    my $error_report = $self->SUPER::_report_error_add($arguments);

    my $fd_output = $self->{fd_output};

    my $description = $arguments->{description};
    my $error = $arguments->{error};
    my $module_name = $arguments->{module_name};

    my $package_name = $global_test_report->{description}->{package}->{name};

    print $fd_output "*** Error $global_error_count: $error ($description, package $package_name, $module_name, error_count $global_error_count)\n";

    my $context_path = $arguments->{context_path};

    print $fd_output "*** Error $global_error_count: $context_path\n";

    _error_report_differences($fd_output, $error_report);

    return $error_report;
}


my $rulers_not_used
    = {
       end => { bottom => 2, top => 1, },
       info => { bottom => 1, top => 1, },
       start => { bottom => 1, top => 2, },
      };

sub report_message
{
    my $self = shift;

    my $type = shift;

    my $message = shift;

    my $fd_output = $self->{fd_output};

    print $fd_output "$message\n";
}


sub report_message_end
{
    my $self = shift;

    my $type = shift;

    my $message = shift;

    my $fd_output = $self->{fd_output};

    return _report_message_with_rulers($fd_output, 1, 2, $message);
}


sub report_message_info
{
    my $self = shift;

    my $type = shift;

    my $message = shift;

    my $fd_output = $self->{fd_output};

    return _report_message_with_rulers($fd_output, 1, 1, $message);
}


sub report_message_info_no_rulers
{
    my $self = shift;

    my $type = shift;

    my $message = shift;

    my $fd_output = $self->{fd_output};

    return _report_message_with_rulers($fd_output, -1, -1, $message);
}


sub report_message_start
{
    my $self = shift;

    my $type = shift;

    my $message = shift;

    my $fd_output = $self->{fd_output};

    return _report_message_with_rulers($fd_output, 2, 1, $message);
}


sub report_progress
{
    my $self = shift;

    my $type = shift;

    my $iteration = shift;
}


sub _report_message_with_rulers
{
    my $fd_output = shift;

    my $top_ruler = shift;

    my $bottom_ruler = shift;

    my $message = shift;

    my $lines = [ split '\n', $message, ];

    my $longest = 0;

    map
    {
	($longest < length) && ($longest = length)
    }
	@$lines;

    my $line = '-' x $longest;

    if ($top_ruler > -1)
    {
	print $fd_output "\n";
	print $fd_output "$line\n" for 0 .. $top_ruler;
	print $fd_output "\n";
    }

    print $fd_output "$message\n";

    if ($bottom_ruler > -1)
    {
	print $fd_output "$line\n" for 0 .. $bottom_ruler;
	print $fd_output "\n";
    }
}


package Heterarch::Test::Reporting::Status;


our @ISA = ("Heterarch::Test::Reporting");


sub end
{
    my $self = shift;

    my $iteration = $global_console_window_configuration->{progress_bar}->{formatter_options}->{total};

    $self->message('progress_bar', { iteration => $iteration, }, );

    $self->message('end', { message => 'Done', }, );
}


sub new
{
    my ($class, @args) = @_;

    my $self = $class->SUPER::new(@args);
}


sub report_error_add
{
    my $self = shift;

    my $arguments = shift;

    my $error_report = $self->SUPER::_report_error_add($arguments);

    my $fd_output = $self->{fd_output};

    my $description = $arguments->{description};
    my $error = $arguments->{error};
    my $module_name = $arguments->{module_name};

    my $package_name = $global_test_report->{description}->{package}->{name};

    my $message = "*** Error $global_error_count: $error ($description, package $package_name, $module_name, error_count $global_error_count)";

    $self->message("message_error", { message => $message, }, );

    return $error_report;
}


sub report_message
{
    my $self = shift;

    my $type = shift;

    my $message = shift;

    chomp $message;

    $self->message($type, { message => $message, }, );
}


sub report_message_end
{
    my $self = shift;

    my $type = shift;

    my $message = shift;

    $self->message("message_info", { message => $message, }, );
}


sub report_message_info
{
    my $self = shift;

    my $type = shift;

    my $message = shift;

    $self->message($type, { message => $message, }, );
}


sub report_message_info_no_rulers
{
    my $self = shift;

    my $type = shift;

    my $message = shift;

    $self->message($type, { message => $message, }, );
}


sub report_message_start
{
    my $self = shift;

    my $type = shift;

    my $message = shift;

    $self->report_message($type, $message, @_);
}


sub report_progress
{
    my $self = shift;

    my $type = shift;

    my $iteration = shift;

    $self->message($type, { iteration => $iteration, }, );

    # for an unknown total testing of the progress bar
    # $self->message($type, { iteration => -1, }, );
}


sub start
{
    my $self = shift;

    my $iteration = 0;

    $self->message('progress_bar', { iteration => $iteration, }, );
}


package main;


main();


