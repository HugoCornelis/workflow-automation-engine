#!/usr/bin/perl -w

use strict;

use warnings;

use Data::Dumper;

$Data::Dumper::Sortkeys = 'always';

use Getopt::Long qw(GetOptionsFromArray);;


$SIG{'__DIE__'}
    = sub
      {
	  require Carp;

	  print STDERR Carp::longmess(@_);
      };


$SIG{'INT'}
    = sub
      {
	  require Carp;

	  print STDERR Carp::longmess(@_);

	  exit 1;
      };


our $option_bash_completion;
our $option_branch = "master";
our $option_build_server;
our $option_built_image_directory;
our $option_commands = [];
our $option_dry_run = '';
our $option_dump_all_interaction_roles;
our $option_dump_interaction_roles;
our $option_dump_module_interaction_roles;
our $option_dump_schedule;
our $option_dump_specific_workflow_roles;
our $option_export_remote;
our $option_export_sh;
our $option_export_sudo;
our $option_export_times;
our $option_export_verbose;
our $option_force_rebuild;
our $option_forward_destination_server;
our $option_forward_source_server;
our $option_help;
our $option_help_build_servers;
our $option_help_commands;
our $option_help_field_project_name;
our $option_help_module;
our $option_help_module_all;
our $option_help_options;
our $option_help_packages;
our $option_help_projects;
our $option_help_targets;
our $option_incremental = 1;
our $option_interactions;
our $option_interactions_all;
our $option_interactions_module;
our $option_interactions_module_all_roles;
our $option_packages = [];
our $option_remote = "gitlab";
our $option_ssh_server;
our $option_ssh_port;
our $option_ssh_user;
our $option_tftp_directory;
our $option_target;
our $option_verbose;

our $global_options
    = {
       "bash-completion=s" => \$option_bash_completion,
       "branch=s" => \$option_branch,
       "build-server=s" => \$option_build_server,
       "built-image-directory=s" => \$option_built_image_directory,
       "command=s" => $option_commands,
       "dry-run!" => \$option_dry_run,
       "dump-all-interaction-roles!" => \$option_dump_all_interaction_roles,
       "dump-interaction-roles!" => \$option_dump_interaction_roles,
       "dump-module-interaction-roles!" => \$option_dump_module_interaction_roles,
       "dump-schedule!" => \$option_dump_schedule,
       "export-remote=s" => \$option_export_remote,
       "export-sh:s" => \$option_export_sh,
       "export-sudo" => \$option_export_sudo,
       "export-times!" => \$option_export_times,
       "export-verbose!" => \$option_export_verbose,
       "force-rebuild!" => \$option_force_rebuild,
       "forward-destination-server=s" => \$option_forward_destination_server,
       "forward-source-server=s" => \$option_forward_source_server,
       "help!" => \$option_help,
       "help-build-servers!" => \$option_help_build_servers,
       "help-commands!" => \$option_help_commands,
       "help-field-project-name!" => \$option_help_field_project_name,
       "help-module!" => \$option_help_module,
       "help-module-all!" => \$option_help_module_all,
       "help-options!" => \$option_help_options,
       "help-packages!" => \$option_help_packages,
       "help-projects!" => \$option_help_projects,
       "help-targets!" => \$option_help_targets,
       "incremental!" => \$option_incremental,
       "interactions!" => \$option_interactions,
       "interactions-all!" => \$option_interactions_all,
       "interactions-module!" => \$option_interactions_module,
       "interactions-module-all-roles!" => \$option_interactions_module_all_roles,
       "package=s" => $option_packages,
       "ssh-port=s" => \$option_ssh_port,
       "ssh-server=s" => \$option_ssh_server,
       "ssh-user=s" => \$option_ssh_user,
       "target=s" => \$option_target,
       "tftp-directory=s" => \$option_tftp_directory,
       "v|verbose+" => \$option_verbose,

       # see https://stackoverflow.com/questions/56418722/handle-repeated-options-like-v-vv-vvv-idiomatically-with-perl-getopt

       "vv" => sub { $option_verbose += 2 },
       "vvv" => sub { $option_verbose += 3 },
       "vvvv" => sub { $option_verbose += 4 },
       "vvvvv" => sub { $option_verbose += 5 },
       "vvvvvv" => sub { $option_verbose += 6 },
       "vvvvvvv" => sub { $option_verbose += 7 },
       "vvvvvvvv" => sub { $option_verbose += 8 },
       "vvvvvvvvv" => sub { $option_verbose += 9 },
      };

our $global_command_line = join " ", $0, @ARGV;
our $global_overriden_packages;
our $global_program_abs_directory;
our $global_program_rel_directory;
our $global_program_name;
our $global_scheduled_commands = [];

my $global_builtin_commands
    = {
       add_target => 1,
       archive_configuration => 1,
       install_scripts => 1,
       print_configuration_directory => 1,
       start_project => 1,
      };

my $global_known_command_packages_builtin
    = {
       'Command::Buildroot' => {
				description => 'workflows for working with Buildroot',
				documentation => 'These workflows implement convenience interactions with Buildroot.',
			       },
       'Command::Git' => {
			  description => 'workflows for working with Git',
			  documentation => 'These workflows implement convenience interactions with Git.',
			 },
       'Command::Git::RepositorySet' => {
					 description => 'workflows for working with Git repositories',
					 documentation => 'These workflows implement convenience interactions with a set of Git repositories..',
					},
       'Command::GitLab' => {
			     description => 'workflows for working with GitLab',
			     documentation => 'These workflows implement convenience interactions to push and pull source code from GitLab.',
			    },
       'Command::Linux' => {
			    description => 'workflows for working with the Linux kernel source code',
			    documentation => 'The sub _config_compare_items in this package helps determine if Linux config items have been renamed between two Linux kernel versions.',
			   },
       'Command::Net::IPerf' => {
				 description => 'workflows for measuring the performance of a network connection',
				 documentation => 'The sub _iperf_test() implements command for execution on different machines to determine the performance of the network connection between those machines.  It takes arguments for a test file, an iperf server machine and an iperf client machine that are referenced by name in the target_servers configuration.  An argument \'local\' refers to the local machine',
				},
      };


{
    use Cwd;

    ($0 =~ m((.*)/(\S+)));

    $global_program_rel_directory = $1;
    # $global_program_name = $2;

    my $program_name_full = $0;

    my $program_name_full_abs = Cwd::abs_path($program_name_full);

    ($program_name_full_abs =~ m((.*)/(\S+)));

    $global_program_abs_directory = $1;

    ($0 =~ m((.*)/(\S+)));

    $global_program_name = $2;
}


our $all_path_globals
    = {
       global_command_line => $global_command_line,
       global_program_abs_directory => $global_program_abs_directory,
       global_program_rel_directory => $global_program_rel_directory,
       global_program_name => $global_program_name,
      };


our $global_target_command;

our $global_field_project_configuration;

our $global_technical_project_configuration;


package Command;


sub _all_install_scripts_execute_shell_command_array
{
    # use Data::Dumper;

    # print Dumper( { _all_install_scripts_execute_shell_command_array => \@_, }, );

    my $install_force = shift;

    my $install_report = shift;

    my $description = shift;

    my $commands = shift;

    if ($install_force)
    {
	if ($install_report)
	{
	    print $description;
	}
	else
	{
	    execute_shell_command_array($commands);
	}
    }
}


#
# add the given command filename to the list in the configuration.
#
# The type and target_name arguments are only there for diagnostics.
#

sub _builtin_add_command_filename
{
    my $field_project_configuration = shift;

    my $type = shift;

    my $target_name = shift;

    my $new_command_filename = shift;

    my $error;

    my $sources_configuration_directory = $field_project_configuration->{sources_configuration_directory};

    my $field_project_name = $field_project_configuration->{field_project_name};

    my $configuration_data_directory = "$sources_configuration_directory/$field_project_name-configuration-data";

    # read the commands configuration file

    my $command_filenames;

    my $command_filenames_configuration_filename = "$configuration_data_directory/command_filenames.yml";

    if (not $error)
    {
	$command_filenames = YAML::LoadFile($command_filenames_configuration_filename);
    }

    # add the commands filename corresponding to the new target name

    my $command_filenames_array = $command_filenames->{command_filenames};

    if (not $error)
    {
	push @$command_filenames_array, $new_command_filename;
    }

    # remove possible duplicate filenames, this allows updates of the description to be written

    my $command_filenames_hash
	= {
	   map
	   {
	       $_ => $_;
	   }
	   @$command_filenames_array,
	  };

    $command_filenames_array = [ sort keys %$command_filenames_hash, ];

    $command_filenames->{command_filenames} = $command_filenames_array;

    # write the commands configuration file

    if (not $error)
    {
	YAML::DumpFile($command_filenames_configuration_filename, $command_filenames);

	print "$global_program_name: registered the $type command file name $new_command_filename for target $target_name\n";
    }

    return $error;
}


sub _builtin_configuration_browser_code
{
    my $code = '($0 =~ m(.*/(\S+)));

my $program_name = $1;


if (defined $ARGV[0] and ($ARGV[0] eq \'--debug\'))
{
    use Data::Dumper;

    print Dumper($configuration);
}


if ($program_name =~ m(configuration$))
{
    # loop over the command line arguments

    while (@ARGV)
    {
	my $argument = shift @ARGV;

	# "--" means list keys

	if ($argument eq "--")
	{
	    $configuration = [ sort keys %$configuration, ];
	}

	# "-1" means list keys one level deep

	elsif ($argument eq "-1")
	{
	    if (ref $configuration eq "HASH")
	    {
		$configuration
		    = {
		       map
		       {
			   my $result;

			   if (ref $configuration eq "HASH")
			   {
			       $result = "$configuration->{$_}";
			   }
			   elsif (ref $configuration eq "ARRAY")
			   {
			       $result = join ", ", map { "$_" } @$configuration;
			   }
			   else
			   {
			       $result = "$configuration";
			   }

			   $_ => $result;
		       }
		       keys %$configuration,
		      };
	    }
	}

	# "-2" means list keys two levels deep

	elsif ($argument eq "-2")
	{
	    $configuration
		= {
		   map
		   {
		       my $result;

		       my $configuration_snippet = $configuration->{$_};

		       if (ref $configuration_snippet eq "HASH")
		       {
			   $result
			       = {
				  map
				  {
				      my $result;

				      if (ref $configuration_snippet eq "HASH")
				      {
					  $result = "$configuration_snippet->{$_}";
				      }
				      elsif (ref $configuration_snippet eq "ARRAY")
				      {
					  $result = join ", ", map { "$_" } @$configuration_snippet;
				      }
				      else
				      {
					  $result = "$configuration_snippet";
				      }

				      $_ => $result;
				  }
				  keys %$configuration_snippet,
				 };
		       }
		       else
		       {
			   $result = "$configuration";
		       }

		       $_ => $result;
		   }
		   keys %$configuration,
		  };
	}

	# "-3" means list keys three levels deep

	elsif ($argument eq "-3")
	{
	    $configuration
		= {
		   map
		   {
		       my $result;

		       my $configuration_snippet_a = $configuration->{$_};

		       if (ref $configuration_snippet_a eq "HASH")
		       {
			   $result
			       = {
				  map
				  {
				      my $result;

				      my $configuration_snippet_b = $configuration_snippet_a->{$_};

				      if (ref $configuration_snippet_b eq "HASH")
				      {
					  $result
					      = {
						 map
						 {
						     my $result;

						     if (ref $configuration_snippet_b eq "HASH")
						     {
							 $result = "$configuration_snippet_b->{$_}";
						     }
						     elsif (ref $configuration_snippet_b eq "ARRAY")
						     {
							 $result = join ", ", map { "$_" } @$configuration_snippet_b;
						     }
						     else
						     {
							 $result = "$configuration_snippet_b";
						     }

						     $_ => $result;
						 }
						 keys %$configuration_snippet_b,
						};
				      }
				      else
				      {
					  $result = "$configuration_snippet_b";
				      }

				      $_ => $result;
				  }
				  keys %$configuration_snippet_a,
				 };
		       }
		       else
		       {
			   $result = "$configuration_snippet_a";
		       }

		       $_ => $result;
		   }
		   keys %$configuration,
		  };
	}

	# else use the argument to descend in the hierarchy

	else
	{
	    if (ref $configuration eq "HASH")
	    {
		#! note that regex selection will only work for the
		#! last argument because the rest of the selection code
		#! assumes there is a single result

		if ($argument =~ /\*|\+/)
		{
		    $configuration
			= {
			   map
			   {
			       $_ => $configuration->{$_}
			   }
			   grep
			   {
			       $_ =~ /$argument/
			   }
			   keys %$configuration,
			  };
		}
		else
		{
		    $configuration = $configuration->{$argument};
		}
	    }
	    elsif (ref $configuration eq "ARRAY")
	    {
		# give output consistent with other use cases

		$configuration = $argument;
	    }
	}
    }

    # choose one of "Data::Dumper", "yaml", "json", "json_pretty"

    my $output_format = "yaml";

    if ($output_format eq "yaml")
    {
	require YAML;

	print YAML::Dump($configuration);
    }
    elsif ($output_format eq "json")
    {
	require JSON;

        my $json = JSON->new(); # ->allow_nonref;

	$json->allow_unknown(1);

	my $encoded = $json->encode($configuration);

	print $encoded;
    }
    elsif ($output_format eq "json_pretty")
    {
	require JSON;

        my $json = JSON->new(); # ->allow_nonref;

	$json->allow_unknown(1);

	my $encoded = $json->pretty()->encode($configuration);

	print $encoded;
    }
    else
    {
	require Data::Dumper;

	no warnings;

	$Data::Dumper::Sortkeys = "always";

	print Data::Dumper::Dumper($configuration);
    }
}
else
{
    return $configuration;
}


';

    return $code;
}


sub _builtin_project_bash_completion_create
{
    my $field_project_configuration = shift;

    my $project_name = shift;

    my $project_name_dash = $project_name;

    $project_name_dash =~ s(_)(-)g;

    my $project_name_underscore = $project_name;

    $project_name_underscore =~ s(-)(_)g;

    #! see https://www.gnu.org/software/bash/manual/html_node/Programmable-Completion.html
    #! see https://www.gnu.org/software/bash/manual/html_node/Programmable-Completion-Builtins.html

    my $bash_completion_code
	= "#/usr/bin/env bash
_${project_name_underscore}_configuration_completions()
{
    COMPLETIONS=`${project_name_dash}-workflow --bash-completion \"\$COMP_LINE\" \$COMP_CWORD \$COMP_POINT | sed 's/\x1b\[[0-9;]*m//g'`

    COMPREPLY=(\$(compgen -W \"\$COMPLETIONS\" -- \"\${COMP_WORDS[\$COMP_CWORD]}\"))
}

# complete -F _${project_name_underscore}_configuration_completions ${project_name_dash}-configuration
# complete -F _${project_name_underscore}_configuration_completions ./${project_name_dash}-configuration
complete -F _${project_name_underscore}_configuration_completions ${project_name_dash}-configuration -o bashdefault -o default
complete -F _${project_name_underscore}_configuration_completions ./${project_name_dash}-configuration -o bashdefault -o default


_${project_name_underscore}_workflow_completions()
{
    COMPLETIONS=`${project_name_dash}-workflow --bash-completion \"\$COMP_LINE\" \$COMP_CWORD \$COMP_POINT | sed 's/\x1b\[[0-9;]*m//g'`

    COMPREPLY=(\$(compgen -W \"\$COMPLETIONS\" -- \"\${COMP_WORDS[\$COMP_CWORD]}\"))
}

# complete -F _${project_name_underscore}_workflow_completions ${project_name_dash}-workflow
# complete -F _${project_name_underscore}_workflow_completions ./${project_name_dash}-workflow
complete -F _${project_name_underscore}_workflow_completions ${project_name_dash}-workflow -o bashdefault -o default
complete -F _${project_name_underscore}_workflow_completions ./${project_name_dash}-workflow -o bashdefault -o default

";

    my $error = '';

    use IO::File;

    my $file = IO::File->new("> $project_name-bash-completion.sh");

    if (defined $file)
    {
	print $file $bash_completion_code;

	$file->close();

	chmod 0700, "$project_name-bash-completion.sh";
    }
    else
    {
	$error = "cannot open $project_name-bash-completion.sh";
    }

    return $error;
}


sub _builtin_project_commands_template_create_perl
{
    my $field_project_configuration = shift;

    my $project_name = shift;

    my $target_name = shift;

    my $filename = shift;

    my $commands_template_code
	= "#!/usr/bin/perl -w

use strict;

use warnings;


package main;

our \$option_verbose;

our \$global_technical_project_configuration;


package Command;


sub ${target_name}_single_command
{
    # arguments on the command line and to this sub are unified in the \$arguments array

    my \$arguments = shift || [];

    # a fictitious force argument can be fetched from the (possibly empty) \$arguments array

    my \$force = \$arguments->[0] || \"\";

    my \$command = 'echo an example of the invocation of a single command';

    execute_shell_command(\$command);

    # Some options to command execution:
    #   allow_fail: allow execution of this command to fail.
    #   dry_run: do not execute this command.
    #   remote: a remote that is defined in $project_name-configuration.
    #   quiet: do not provide feedback to the terminal about this command.
    #   sudo: invoke the command prefixed with sudo.
    #   timeout: this command will fail after the given timeout.
    #   use_bash: use bash to invoke the command because it uses specific bash functions or features.
    #
    # execute_shell_command(\$command, { remote => '<name of a remote that is defined in $project_name-configuration>, } );
    #
    # These options can given to any of the functions that execute commands.
}


sub ${target_name}_single_command_completions
{
    my \$complete_command_string = shift;

    my \$complete_arguments_array = shift;

    my \$completions_hash
	= {
	   \"1._<your_completion_without_spaces_here>\" => \"explain_the_purpose_of_the_completion_here\",
	   \"2._<another_completion_here>\" => \"the_numbers_preserve_the_order_for_this_example\",
	   \"3._Don't_use_spaces_in_your_completions,_because_they_confuse_bash\" => \"further_explanation\",
	   \"4._Look_at_the_completion_function_of_${target_name}_single_command_completions_to_understand_how_it_works\" => \"further_explanation\",
	  };

    # the following logic uses bash completion as a help message when there are no arguments to complete
    # allows to dynamically insert other completions when there are arguments to complete.

    if (scalar \@\$complete_arguments_array > 2)
    {
	# insert your completions here as a hash when there are arguments to complete,
	# the workflow engine will select the correct level in your hash of completins.
	# bash will select those that apply to the current argument to be completed.

	return {
		aa => {
		       12 => {
			      cc => 1,
			     },
		       34 => {
			      dd => 1,
			     },
		      },
		bb => {
		       56 => {
			      ee => 1,
			     },
		       78 => {
			      ff => 1,
			     },
		      },
	       };
    }
    else
    {
	return \$completions_hash;
    }

    return \$completions_hash;
}


sub ${target_name}_single_command_help
{
    my \$command = shift;

    return \"\$command: an example of the invocation a single command.

arguments:

    force: command arguments can be parsed from \@ARGV.
\";
}


sub ${target_name}_array_of_commands
{
    my \$arguments = shift || [];

    my \$force = \$arguments->[0] || \"\";

    my \$local_commands
	= [
	   'echo an example of the invocation of an array of commands',
	   'echo this is the second command in the array',
	  ];

    execute_shell_command_array(\$local_commands);
}


sub ${target_name}_array_of_commands_completions
{
    my \$complete_command_string = shift;

    my \$complete_arguments_array = shift;

    my \$completions_hash
	= {
	   \"1.<your_completion_without_spaces_here>\" => \"explain_the_purpose_of_the_completion_here\",
	   \"2.<another_completion_here>\" => \"the_numbers_preserve_the_order_for_this_example\",
	  };

    # the following logic uses bash completion as a help message when there are no arguments to complete
    # allows to dynamically insert other completions when there are arguments to complete.

    if (scalar \@\$complete_arguments_array > 2)
    {
	# insert all your completions here when there are arguments to complete,
	# bash will select those that apply to the current argument to be completed.

	return {};
    }
    else
    {
	return \$completions_hash;
    }

    return \$completions_hash;
}


sub ${target_name}_array_of_commands_help
{
    my \$command = shift;

    return \"\$command: an example of the invocation an array of commands.

arguments:

    force: command arguments can be parsed from \\\@ARGV.
\";
}


our \$target_servers = \$::global_technical_project_configuration->{target_servers};

sub ${target_name}_array_of_commands_remote_execution
{
    my \$arguments = shift || [];

    my \$force = \$arguments->[0] || \"\";

    my \$remote = \$target_servers->{build};

    my \$remote_commands
	= [
	   'echo',
	   'echo an example of the invocation of an array of remote commands',
	   'echo this is the second command in the array',
	   'echo',
	  ];

    execute_shell_command_array
	(
	 \$remote_commands,
	 {
	  remote => \$remote,
	 },
	);

    my \$local_commands
	= [
	   'echo a few locally executed commands',
	   'echo more locally executed commands',
	  ];

    execute_shell_command_array(\$local_commands);

    execute_shell_command_array
	(
	 \$remote_commands,
	 {
	  remote => \$remote,
	 },
	);
}


sub ${target_name}_array_of_commands_remote_execution_completions
{
    my \$complete_command_string = shift;

    my \$complete_arguments_array = shift;

    my \$completions_hash
	= {
	   \"1.<your_completion_without_spaces_here>\" => \"explain_the_purpose_of_the_completion_here\",
	   \"2.<another_completion_here>\" => \"the_numbers_preserve_the_order_for_this_example\",
	  };

    # the following logic uses bash completion as a help message when there are no arguments to complete
    # allows to dynamically insert other completions when there are arguments to complete.

    if (scalar \@\$complete_arguments_array > 2)
    {
	# insert all your completions here when there are arguments to complete,
	# bash will select those that apply to the current argument to be completed.

	return {};
    }
    else
    {
	return \$completions_hash;
    }

    return \$completions_hash;
}


sub ${target_name}_array_of_commands_remote_execution_help
{
    my \$command = shift;

    return \"\$command: an example of the invocation an array of commands that are executed on a remote machine.

arguments:

    none.
\";
}


sub ${target_name}_sequencing_and_composition
{
    my \$arguments = shift || [];

    my \$force = \$arguments->[0] || \"\";

    my \$local_commands
	= [
	   'echo this examples composes other examples into one sequence of commands',
	  ];

    execute_shell_command_array(\$local_commands);

    ${target_name}_single_command();
    ${target_name}_array_of_commands();
}


sub ${target_name}_sequencing_and_composition_completions
{
    my \$complete_command_string = shift;

    my \$complete_arguments_array = shift;

    my \$completions_hash
	= {
	   \"1.<your_completion_without_spaces_here>\" => \"explain_the_purpose_of_the_completion_here\",
	   \"2.<another_completion_here>\" => \"the_numbers_preserve_the_order_for_this_example\",
	  };

    # the following logic uses bash completion as a help message when there are no arguments to complete
    # allows to dynamically insert other completions when there are arguments to complete.

    if (scalar \@\$complete_arguments_array > 2)
    {
	# insert all your completions here when there are arguments to complete,
	# bash will select those that apply to the current argument to be completed.

	return {};
    }
    else
    {
	return \$completions_hash;
    }

    return \$completions_hash;
}


sub ${target_name}_sequencing_and_composition_help
{
    my \$command = shift;

    return \"\$command: an example that composes other examples into one sequence of commands.

arguments:

    none.
\";
}


# return success

1;


";

    my $error = '';

    use IO::File;

    my $sources_configuration_directory = $field_project_configuration->{sources_configuration_directory};

    my $pathname = "$sources_configuration_directory/$filename";

    my $file = IO::File->new("> $pathname");

    if (defined $file)
    {
	print $file $commands_template_code;

	$file->close();

	chmod 0700, "$pathname";
    }
    else
    {
	$error = "cannot open $pathname";
    }

    return $error;
}


sub _builtin_project_commands_template_create_python
{
    my $field_project_configuration = shift;

    my $project_name = shift;

    my $target_name = shift;

    my $filename = shift;

    my $commands_template_code
	= "#!/usr/bin/python3

def ${target_name}_python_command(argv):
    command = \"echo 'python_command from bash (1)'\"
    execute_command(command)
    command_array = [
        \"echo 'python_command from bash (2)'\",
        \"echo 'python_command from bash (3)'\"
    ]
    execute_command_array(command_array)


def ${target_name}_python_command_completions(command, argv):
    completions_hash = {
           \"1._<your_completion_without_spaces_here>\": \"explain_the_purpose_of_the_completion_here\",
           \"2._<another_completion_here>\": \"the_numbers_preserve_the_order_for_this_example\",
           \"3._Don't_use_spaces_in_your_completions,_because_they_confuse_bash\": \"further_explanation\",
           \"4._Look_at_the_completion_function_of_${target_name}_single_command_completions_to_understand_how_it_works\": \"further_explanation\",
          }

    return completions_hash


def ${target_name}_python_command_help(command, perl_argv):
    return f\"python_python_command {command} help page\"

";

    my $error = '';

    use IO::File;

    my $sources_configuration_directory = $field_project_configuration->{sources_configuration_directory};

    my $pathname = "$sources_configuration_directory/$filename";

    my $file = IO::File->new("> $pathname");

    if (defined $file)
    {
	print $file $commands_template_code;

	$file->close();

	chmod 0700, "$pathname";
    }
    else
    {
	$error = "cannot open $pathname";
    }

    return $error;
}


sub _builtin_project_commands_sh_create
{
    my $field_project_configuration = shift;

    my $project_name = shift;

    my $target_name = shift;

    my $command_name = shift;

    my $sh_string = shift;

    my $commands_data_directory = "$project_name-commands-data";

    my $error = '';

    my $sources_configuration_directory = $field_project_configuration->{sources_configuration_directory};

    my $sources_configuration_data_directory = $field_project_configuration->{sources_configuration_data_directory};

    my $directory = "$sources_configuration_data_directory/$target_name";

    $error = Utilities::create_directories($directory);

    if (not $error)
    {
	use IO::File;

	my $filename = "$directory/$command_name.sh";

	my $file = IO::File->new("> $filename");

	if (defined $file)
	{
	    print $file $sh_string;

	    $file->close();

	    chmod 0755, $filename;
	}
	else
	{
	    $error = "cannot open $filename";
	}
    }

    return $error;
}


sub _builtin_project_commands_sh_template_create
{
    my $field_project_configuration = shift;

    my $project_name = shift;

    my $target_name = shift;

    my $error = '';

    my $array_of_commands_remote_execution_sh_example
	= "#!/bin/sh
echo
echo an example of the invocation of an array of remote commands
echo this is the second command in the array
echo
# remote: build
echo a few locally executed commands
echo more locally executed commands
# remote: localhost
echo
echo an example of the invocation of an array of remote commands
echo this is the second command in the array
echo
# remote: build
# help: an example of the invocation of an array of commands that are executed on a remote machine.
";

    if (not $error)
    {
	$error = _builtin_project_commands_sh_create($field_project_configuration, $project_name, $target_name, "sh_remote_execution", $array_of_commands_remote_execution_sh_example);
    }

    my $array_of_commands_sh_example
	= "#!/bin/sh
echo an example of the invocation of an array of commands
echo this is the second command in the array
# allow_fail: describe here the reason why this command is allowed to fail or remove the allow_fail clause
# help: these commands echo a string to the terminal
";

    if (not $error)
    {
	$error = _builtin_project_commands_sh_create($field_project_configuration, $project_name, $target_name, "sh_array_of_commands", $array_of_commands_sh_example);
    }

    my $single_command_sh_example
	= "#!/bin/sh
echo an example of the invocation of a single command
# allow_fail: describe here the reason why this command is allowed to fail or remove the allow_fail clause
# help: this command echos a string to the terminal
";

    if (not $error)
    {
	$error = _builtin_project_commands_sh_create($field_project_configuration, $project_name, $target_name, "sh_single_command", $single_command_sh_example);
    }

    return $error;
}


sub _builtin_project_commands_yml_create
{
    my $field_project_configuration = shift;

    my $project_name = shift;

    my $target_name = shift;

    my $command_name = shift;

    my $yml_string = shift;

    my $commands_data_directory = "$project_name-commands-data";

    my $error = '';

    my $sources_configuration_directory = $field_project_configuration->{sources_configuration_directory};

    my $sources_configuration_data_directory = $field_project_configuration->{sources_configuration_data_directory};

    my $directory = "$sources_configuration_data_directory/$target_name";

    $error = Utilities::create_directories($directory);

    if (not $error)
    {
	use IO::File;

	my $filename = "$directory/$command_name.yml";

	my $file = IO::File->new("> $filename");

	if (defined $file)
	{
	    print $file $yml_string;

	    $file->close();
	}
	else
	{
	    $error = "cannot open $filename";
	}
    }

    return $error;
}


sub _builtin_project_commands_yml_template_create
{
    my $field_project_configuration = shift;

    my $project_name = shift;

    my $target_name = shift;

    my $error = '';

    my $array_of_commands_remote_execution_yml_example
	= "---
- commands:
  - echo
  - echo an example of the invocation of an array of remote commands
  - echo this is the second command in the array
  - echo
  options:
    remote: build
- commands:
  - echo a few locally executed commands
  - echo more locally executed commands
- commands:
  - echo
  - echo an example of the invocation of an array of remote commands
  - echo this is the second command in the array
  - echo
  options:
    remote: build
help: an example of the invocation of an array of commands that are executed on a remote machine.
";

    if (not $error)
    {
	$error = _builtin_project_commands_yml_create($field_project_configuration, $project_name, $target_name, "remote_execution", $array_of_commands_remote_execution_yml_example);
    }

    my $array_of_commands_yml_example
	= "---
commands:
  - echo an example of the invocation of an array of commands
  - echo this is the second command in the array
options:
  allow_fail: describe here the reason why this command is allowed to fail or remove the allow_fail clause
help: these commands echo a string to the terminal
";

    if (not $error)
    {
	$error = _builtin_project_commands_yml_create($field_project_configuration, $project_name, $target_name, "array_of_commands", $array_of_commands_yml_example);
    }

    my $single_command_yml_example
	= "---
command: echo an example of the invocation of a single command
options:
  allow_fail: describe here the reason why this command is allowed to fail or remove the allow_fail clause
help: this command echos a string to the terminal
";

    if (not $error)
    {
	$error = _builtin_project_commands_yml_create($field_project_configuration, $project_name, $target_name, "single_command", $single_command_yml_example);
    }

    return $error;
}


sub _builtin_project_configuration_build_servers_create
{
    my $project_name = shift;

    my $configuration_data_directory = shift;

    my $user = shift;

    my $configuration_file_part
	= "---
build_servers:
  laptop:
    description: local laptop
    name: laptop
    ssh_port: 22
    ssh_server: localhost
    ssh_user: $user
";

    my $error = '';

    use IO::File;

    my $file = IO::File->new("> $configuration_data_directory/build_servers.yml");

    if (defined $file)
    {
	print $file $configuration_file_part;

	$file->close();
    }
    else
    {
	$error = "cannot open $configuration_data_directory/build_servers.yml";
    }

    return $error;
}


sub _builtin_project_configuration_command_filenames_create
{
    my $project_name = shift;

    my $configuration_data_directory = shift;

#     my $configuration_file_part
# 	= "---
# command_filenames:
#   - $project_name-commands
# ";

    my $configuration_file_part
	= "---
command_filenames: []
";

    my $error = '';

    use IO::File;

    my $file = IO::File->new("> $configuration_data_directory/command_filenames.yml");

    if (defined $file)
    {
	print $file $configuration_file_part;

	$file->close();
    }
    else
    {
	$error = "cannot open $configuration_data_directory/command_filenames.yml";
    }

    return $error;
}


sub _builtin_project_configuration_create
{
    my $field_project_configuration = shift;

    my $project_name = shift;

    # create a configuration file

    my $user = `whoami`;

    my $configuration_data_directory = "$project_name-configuration-data";

    # note that the relative pathnames are correct by a matching cd when reading the project configuration

    my $configuration_file_part
	= "#!/usr/bin/perl -w

use strict;

use warnings;

require YAML;

my \$build_servers = eval { YAML::LoadFile('$configuration_data_directory/build_servers.yml'); };

my \$command_filenames = eval { YAML::LoadFile('$configuration_data_directory/command_filenames.yml'); };

my \$node_configuration = eval { YAML::LoadFile('$configuration_data_directory/node_configuration.yml'); };

my \$target_servers = eval { YAML::LoadFile('$configuration_data_directory/target_servers.yml'); };

my \$targets = eval { YAML::LoadFile('$configuration_data_directory/targets.yml'); };

my \$configuration = {
		      \%{ ref \$build_servers eq 'HASH' ? \$build_servers : {}; },
		      \%{ ref \$command_filenames eq 'HASH' ? \$command_filenames : {}; },
		      \%{ ref \$node_configuration eq 'HASH' ? \$node_configuration : {}; },
		      \%{ ref \$target_servers eq 'HASH' ? \$target_servers : {}; },
		      \%{ ref \$targets eq 'HASH' ? \$targets : {}; },
		     };

";

    my $error = '';

    if (not $error)
    {
	$error = Utilities::create_directories($configuration_data_directory);
    }

    if (not $error)
    {
	$error = _builtin_project_configuration_targets_create($project_name, $configuration_data_directory);
    }

    if (not $error)
    {
	$error = _builtin_project_configuration_build_servers_create($project_name, $configuration_data_directory, $user);
    }

    if (not $error)
    {
	$error = _builtin_project_configuration_command_filenames_create($project_name, $configuration_data_directory);
    }

    if (not $error)
    {
	$error = _builtin_project_configuration_node_configuration_create($project_name, $configuration_data_directory);
    }

    if (not $error)
    {
	$error = _builtin_project_configuration_target_servers_create($project_name, $configuration_data_directory, $user);
    }

    use IO::File;

    my $file = IO::File->new("> $project_name-configuration");

    if (defined $file)
    {
	print $file $configuration_file_part;

	my $configuration_browser = _builtin_configuration_browser_code();

	print $file $configuration_browser;

	$file->close();

	chmod 0700, "$project_name-configuration";
    }
    else
    {
	$error = "cannot open $project_name-configuration";
    }

    if (not $error)
    {
	$error = Utilities::create_directories("$configuration_data_directory/cache");
    }

    return $error;
}


sub _builtin_project_configuration_node_configuration_create
{
    my $project_name = shift;

    my $configuration_data_directory = shift;

    my $configuration_file_part
	= "---
node_configuration:
  0_concepts:
    description00: The design goals of this IP address plan is to separate administration networks from operations networks.
";

    my $error = '';

    use IO::File;

    my $file = IO::File->new("> $configuration_data_directory/node_configuration.yml");

    if (defined $file)
    {
	print $file $configuration_file_part;

	$file->close();
    }
    else
    {
	$error = "cannot open $configuration_data_directory/node_configuration.yml";
    }

    return $error;
}


sub _builtin_project_configuration_targets_create
{
    my $project_name = shift;

    my $configuration_data_directory = shift;

    my $configuration_file_part
	= "---
description: The following are example targets, modify/remove/add according to your project needs.
targets:
  all:
    description: used for processing of target files that are produced by other targets
  docker:
    description: interaction with the docker build container
  perl_examples:
    description: these are perl examples that explain how to use the APIs
  python_examples:
    description: these are python examples that explain how to use the APIs
  source_code:
    description: operations on the source code that is used for testing
  wiki_gitlab:
    description: pulls the wiki pages from gitlab (and possibly other sources) and converts them PDF (or other formats)
";

    my $error = '';

    use IO::File;

    my $file = IO::File->new("> $configuration_data_directory/targets.yml");

    if (defined $file)
    {
	print $file $configuration_file_part;

	$file->close();
    }
    else
    {
	$error = "cannot open $configuration_data_directory/targets.yml";
    }

    return $error;
}


sub _builtin_project_configuration_target_servers_create
{
    my $project_name = shift;

    my $configuration_data_directory = shift;

    my $user = shift;

    my $configuration_file_part
	= "---
# Target servers identify roles that execute command on different hosts.
# Each host has a 'remote_policy' that is prefixed to the command to be executed.
# For some roles the remote_policy is dynamically built.  A typical example is an remote ssh server.
#
# A role that has a 'localuser' set to 'yes' has no remote_policy.
#
# A tmux remote_policy requires its name to have a 'tmux_' prefix.
# This is recognized by the workflow engine and, for instance, allows tmux sessions to be automatically created.

target_servers:
  build:
    description: your build server that does builds and is used for testing
    name: build
    ssh_server: build.your.local.domain
    ssh_user: tester
  docker_build:
    description: interaction with the docker build container
    name: docker_build
    remote_policy: 'docker exec -it --workdir ~/projects/digital-engineering/source/build gitlab_interactive '
  laptop:
    description: the local computer of the developer
    localuser: yes
    name: laptop
    ssh_port: 22
    ssh_server: 192.168.4.70
    ssh_user: $user
";

    my $error = '';

    use IO::File;

    my $file = IO::File->new("> $configuration_data_directory/target_servers.yml");

    if (defined $file)
    {
	print $file $configuration_file_part;

	$file->close();
    }
    else
    {
	$error = "cannot open $configuration_data_directory/target_servers.yml";
    }

    return $error;
}


sub _builtin_project_gc_configuration_create
{
    my $field_project_configuration = shift;

    my $project_name = shift;

    my $conf_gc_project_configuration
	= "# this file should be copied to /usr/share/grc/
#
# Colors available for configuration are:
#
#    Black
#    Red
#    Green
#    Yellow
#    Blue
#    Magenta
#    Cyan
#    White
#
# add this at the top of /etc/grc.conf
#
#
# # $project_name configuration
# (^|[/\\w\\.]+/)$project_name-configuration
# conf.$project_name-configuration
#
#
# maintainance laptop according to the documentation
regexp=laptop_slave
colours=yellow
-
# trusted laptop according to the documentation
regexp=laptop_developer
colours=yellow
-
# target
regexp=$project_name
colours=yellow
-
# descriptions
regexp=^ *description:.*\$
colours=green
-
# IP addresses
regexp=([0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3})
colours=green bold
-
# MAC addresses
regexp=(([a-zA-Z0-9][a-zA-Z0-9]:){5}[a-zA-Z0-9][a-zA-Z0-9])
colours=blue
-
# vlans
regexp=(vlan_id: [0-9]{1,4})
colours=cyan bold
-
# interfaces
regexp=(enp[03456]\\w*)
colours=white underline
-
regexp=(eth[012]\\w*)
colours=white underline
-
regexp=(lan[1234]\\w*)
colours=white underline
-
regexp=(enx............)
colours=white underline
-
regexp=wlp1s0
colours=white underline
-
regexp=wlo1
colours=white underline
";

    my $error = '';

    use IO::File;

    my $file = IO::File->new("> conf.$project_name-configuration");

    if (defined $file)
    {
	print $file $conf_gc_project_configuration;

	$file->close();
    }
    else
    {
	$error = "cannot open conf.$project_name-configuration";
    }

    return $error;
}


sub _builtin_project_gc_workflow_create
{
    my $field_project_configuration = shift;

    my $project_name = shift;

    my $conf_gc_project_workflow
	= "# this file should be copied to /usr/share/grc/
#
#    Black: \\u001b[30m.
#    Red: \\u001b[31m.
#    Green: \\u001b[32m.
#    Yellow: \\u001b[33m.
#    Blue: \\u001b[34m.
#    Magenta: \\u001b[35m.
#    Cyan: \\u001b[36m.
#    White: \\u001b[37m.
#
# targets
# -
# regexp=all
# colours=green bold
# -
# regexp=cr(?!-workflow)
# colours=green bold
# -
# commands
regexp=(\\S+) --dry
colours=yellow bold
-
regexp= --dry
colours=white
-
# specific IP addresses
regexp=^.*192\\.168\\.[345]\\..*\$
colours=green bold
-
# MAC addresses
regexp=(([a-zA-Z0-9][a-zA-Z0-9]:){5}[a-zA-Z0-9][a-zA-Z0-9])
colours=blue
-
# vlans
regexp=(vlan_id: [0-9]{1,4})
colours=cyan bold
-
# devices and interfaces
regexp=(enp[03456]\\w*)
colours=white underline
-
regexp=(eth[012]\\w*)
colours=white underline
-
regexp=(lan[1234]\\w*)
colours=white underline
-
regexp=(enx............)
colours=white underline
-
regexp=wlp1s0
colours=white underline
-
regexp=wlo1
colours=white underline
-
regexp=/dev/\\S*
colours=yellow underline
count=more
-
regexp=/mnt/\\S*
colours=magenta underline
count=more
-
regexp=/media/\\S*
colours=magenta underline
count=more
-
# interaction diagram
regexp=ROLE:.*\$
colours=magenta bold underline
-
regexp=COMMAND:.*\$
colours=cyan underline


";

    my $error = '';

    use IO::File;

    my $file = IO::File->new("> conf.$project_name-workflow");

    if (defined $file)
    {
	print $file $conf_gc_project_workflow;

	$file->close();
    }
    else
    {
	$error = "cannot open conf.$project_name-workflow";
    }

    return $error;
}


sub _builtin_project_readme_create
{
    my $field_project_configuration = shift;

    my $project_name = shift;

    my $readme_text = "
# The Workflow Automation Configuration for $project_name

The workflow automation engine helps automating complicated system
shell tasks during the development of a software project.

The scripts in this directory provide the workflow automation
configuration for the $project_name project.


## Overview

The workflow automation engine offers the following functions:

- Easy to start a new _project_, and add new _targets_ and new
  _commands_ to a project.
- Integration with `bash` completion allows exploring and browsing
  project specific _targets_, project specific _commands_ and project
  specific _configuration_.
- Integration with `grc` for project specific _keyword highlighting_.
- The use of different _roles_ allows remote execution of commands
  over an ssh session, in a Docker container or a `tmux` session.
- Modular construction of complex worfklow that combine several
  features of the workflow engine.

## Installation

To use this configuration, install the workflow automation engine
and its prerequisites by following the instructions available at:

https://github.com/HugoCornelis/workflow-automation-engine/blob/master/README.md

Typical prerequisites are `grc`, `yaml` related libraries and
developer tools such as `automake`.

After installation of the workflow engine, use the following command
from this directory to make this project configuration available to
the workflow engine:

`\$ workflow builtin install_scripts -- --engine --commands --aliasses --bash-completion`

The output of the command explains what has been done and it is
recommended to carefully inspect it.  The help page of the command
explains:

```
\$ workflow builtin install_scripts --help
workflow builtin install_scripts : install or upgrade the workflow scripts for this project.

options:

    --aliasses         configure the grc aliases in .bashrc if they are not there yet.
    --bash-completion  configure bash completion in .bashrc if they are not there yet.
    --commands         install or upgrade the command configuration to ~/bin.
    --engine           create a symbolic link to the workflow engine in ~/bin.
    --path-in-bashrc   update .bashrc to include ~/bin in PATH.

Note that grc configuration files will also be installed and configured.
```

The installation of the `grc` configuration files requires `sudo`
access to be configured.


## Use

If you used one of the `--bash-completion` or `--path-in-bashrc`
options during the installation of the workflow scripts, execute your
`.bashrc` or login with a new shell to ensure that `bash` is
configured with the new completions and paths.

Afterwards a good starting point for using the configuration is:

```
\$ $project_name-workflow --help-commands
```
Then followed with one of the `--dry-run` and `--interactions` options
applied to one of the shown commands to understand what these commands would do
if executed without options:

```
<fill in your project specific examples here>
```

You are ready to use this configuration.  Don't forget to use bash
completion to explore the available targets and commands.
";

    my $error = '';

    use IO::File;

    my $file = IO::File->new("> README.md");

    if (defined $file)
    {
	print $file $readme_text;

	$file->close();
    }
    else
    {
	$error = "cannot open README.md";
    }

    return $error;
}


sub _builtin_project_template_create
{
    my $field_project_configuration = shift;

    my $project_name = shift;

    my $project_file
	= "#!/usr/bin/perl -w

use strict;

use warnings;

my \$configuration
    = {
       field_project_name => '$project_name',
      };

return \$configuration;

";

    my $error = '';

    use IO::File;

    my $file = IO::File->new("> workflow-project.pl");

    if (defined $file)
    {
	print $file $project_file;

	$file->close();
    }
    else
    {
	$error = "cannot open workflow-project.pl";
    }

    return $error;
}


sub _builtin_tmux_sessions
{
    my $target_servers = $global_technical_project_configuration->{target_servers};

    my $tmux_sessions = [];

    foreach my $target_server_name (sort keys %$target_servers)
    {
	my $target_server = $target_servers->{$target_server_name};

	my $name = $target_server->{name};

	if ($name =~ m(^tmux_))
	{
	    my $remote_policy = $target_server->{remote_policy};

	    $remote_policy =~ m(-t ([^:\s]+)(:[^\s]+)?);

	    my $tmux_session_name = $1;

	    push @$tmux_sessions, $tmux_session_name;
	}
    }

    return $tmux_sessions;
}


sub _install_script_bashrc_aliasses
{
    my $project_name = shift;

    # 3. Install to .bashrc: text addition for aliases (add to ~/.bash_aliases?) and for bash completion

    my $alias_marker = "alias $project_name-workflow=\"grc $project_name-workflow\"";

    my $alias_additions
	= "# $project_name-workflow

alias $project_name-workflow=\"grc $project_name-workflow\"
alias $project_name-configuration=\"grc $project_name-configuration\"
";

    my $bashrc_matches = _file_contains_regex("$ENV{HOME}/.bashrc", $alias_marker);

    if ($option_verbose)
    {
	if (not $bashrc_matches)
	{
	    print "$global_program_name: all_install_scripts: .bashrc has the correct alias definitions\n";
	}
	else
	{
	    print "$global_program_name: all_install_scripts: .bashrc does not have the correct alias definitions, installing them\n";
	}
    }

    if (not $bashrc_matches)
    {
	{
	    _file_append_string("$ENV{HOME}/.bashrc", $alias_additions);
	}
    }
}


sub _install_script_bash_completion
{
    my $project_name = shift;

    my $command_filename_directory = $global_field_project_configuration->{search_path_workflow_executable_directory};

    use Cwd;

    my $abs_command_filename_directory = Cwd::abs_path($command_filename_directory);

    my $bash_completion_filename = "$abs_command_filename_directory/$project_name-bash-completion.sh";

    if (-e $bash_completion_filename)
    {
	my $bash_completion_additions
	    = ". $bash_completion_filename
";

	_file_append_string("$ENV{HOME}/.bashrc", $bash_completion_additions);
    }
}


sub _install_script_git_repository
{
    my $project_name = shift;

    # 6. Create and populate the git repository

    my $command = "git init -b master";

    execute_shell_command($command, );

    my $commands
	= [
	   "echo >.gitignore '*~'",
	   "echo >>.gitignore '_Inline'",
	   "echo >>.gitignore '$project_name-commands-data/cache'",
	   "echo >>.gitignore '$project_name-configuration-data/cache'",
	   "git add --all",
	   "git commit --quiet --message 'Default workflow engine configuration for project $project_name.'",
	  ];

    execute_shell_command_array($commands);
}


#
# Add configuration to /etc/grc.conf
#

sub _install_script_grc_conf_additions
{
    my $project_name = shift;

    # 4. Install to /etc/grc.conf: text addition

    my $etc_grc_conf_filename = "/etc/grc.conf";

    my $etc_grc_conf_marker = "$project_name-workflow";

    my $grc_conf_matches = _file_contains_regex($etc_grc_conf_filename, $etc_grc_conf_marker);

    if ($option_verbose)
    {
	if (not $grc_conf_matches)
	{
	    print "$global_program_name: all_install_scripts: grc_conf does not match\n";
	}
	else
	{
	    print "$global_program_name: all_install_scripts: grc_conf matches\n";
	}
    }

    if (not $grc_conf_matches)
    {
	my $etc_grc_conf_additions
	    = "
# $project_name-workflow
(^|[/\\w\\.]+/)$project_name-workflow\\s?
conf.$project_name-workflow

# $project_name-configuration
(^|[/\\w\\.]+/)$project_name-configuration\\s?
conf.$project_name-configuration

";

	_file_append_string($etc_grc_conf_filename, $etc_grc_conf_additions, { sudo => 1, }, );
    }

}


sub _install_script_grc_symbolic_links
{
    my $project_name = shift;

    my $field_configuration = shift;

    # 5. Install to /usr/share/grc/: symbolic links

    {
	my $grc_configuration = "conf.$project_name-configuration";

	my $grc_workflow = "conf.$project_name-workflow";

	my $source_directory = $field_configuration->{search_path_workflow_executable_directory};

	use Cwd;

	my $abs_source_directory = Cwd::abs_path($source_directory);

	my $target_directory = "/usr/share/grc";

	my $source_file_configuration = "$abs_source_directory/$grc_configuration";

	my $target_file_configuration = "$target_directory/$grc_configuration";

	if (not -e $target_directory)
	{
		my $command = "mkdir -p $target_directory";
		execute_shell_command($command, { sudo => 1, }, );
	}

	if ($option_verbose)
	{
	    use Data::Dumper;

	    print STDERR Dumper(
				{
				 _install_script_grc_symbolic_links => {
									source_directory => $source_directory,
									abs_source_directory => $abs_source_directory,
									target_directory => $target_directory,
								       },
				},
			       );
	}

	if (-e $source_file_configuration
	    and not -e $target_file_configuration)
	{
	    if ($option_verbose)
	    {
		print STDERR "Installing _install_script_grc_symbolic_links, configuration\n";
	    }

	    my $command = "ln -sf $source_file_configuration $target_file_configuration";

	    execute_shell_command($command, { sudo => 1, }, );
	}
	else
	{
	    if ($option_verbose)
	    {
		print STDERR "NOT Installing _install_script_grc_symbolic_links, configuration, either the source file ($source_file_configuration) does not exist or the target file ($target_file_configuration) already exists.\n";
	    }
	}

	my $source_file_workflow = "$abs_source_directory/$grc_workflow";

	my $target_file_workflow = "$target_directory/$grc_workflow";

	if (-e $source_file_workflow
	    and not -e $target_file_workflow)
	{
	    if ($option_verbose)
	    {
		print STDERR "Installing _install_script_grc_symbolic_links, workflow\n";
	    }

	    my $command = "ln -sf $source_file_workflow $target_file_workflow";

	    execute_shell_command($command, { sudo => 1, }, );
	}
	else
	{
	    if ($option_verbose)
	    {
		print STDERR "NOT Installing _install_script_grc_symbolic_links, workflow, either the source file ($source_file_workflow) does not exist or the target file ($target_file_workflow) already exists.\n";
	    }
	}

    }
}


sub _install_script_path_in_bashrc
{
    my $project_name = shift;

    # export PATH="$HOME/bin:$PATH"

    my $bin_path_marker = 'export PATH="$HOME/bin:$PATH"';

    my $bin_path_additions
	= '# necessary for $project_name-workflow

export PATH="$HOME/bin:$PATH"

';

    my $bashrc_matches = _file_contains_regex("$ENV{HOME}/.bashrc", $bin_path_marker);

    if ($option_verbose)
    {
	if (not $bashrc_matches)
	{
	    print "$global_program_name: all_install_scripts: .bashrc does not have $bin_path_marker, installing it\n";
	}
	else
	{
	    print "$global_program_name: all_install_scripts: .bashrc already $bin_path_marker\n";
	}
    }

    if (not $bashrc_matches)
    {
	{
	    _file_append_string("$ENV{HOME}/.bashrc", $bin_path_additions);
	}
    }
}


sub _install_script_symbolic_link_to_commands_configured
{
    my $project_name = shift;

    my $option_install_commands = shift;

    my $option_install_report = shift;

    if ($option_verbose)
    {
	print "$global_program_name: _install_script_symbolic_link_to_commands_configured with (--install-commands == $option_install_commands, --install-report == $option_install_report)\n";
    }

    # 2.b. from configured filenames to symbolic links.

    # generate list of scripts

    my $command_filenames_configured = [ @{ _init_command_filenames_configured('full-paths') }, ];

    # install each script to the ~/bin directory

    # TODO: use case if a script exists but does not have a symbolic
    # link in ~/bin yet, a new script that was just created:
    # 1. requires adding the symbolic link.
    # 2. requires adding the targets defined in the script to the configuration
    # -- this requires to guess the targets.

    if (defined $option_verbose
	and $option_verbose > 2)
    {
	print "In: sub _install_script_symbolic_link_to_commands_configured()\n";
    }

    my $commands_configured = _init_filenames_2_symlink_commands($command_filenames_configured);

    _all_install_scripts_execute_shell_command_array($option_install_commands, $option_install_report, "    # 2. Install to ~/bin: symbolic links for commands

    # 2.b. from configured filenames to symbolic links.
", $commands_configured);
}


sub _install_script_symbolic_link_to_configuration
{
    my $project_name = shift;

    my $option_install_commands = shift;

    my $option_install_report = shift;

    if ($option_verbose)
    {
	print "$global_program_name: installation of the workflow configuration with (--install-commands == $option_install_commands, --install-report == $option_install_report)\n";
    }

    my $configuration_filenames_found_2
	= {
	   map
	   {
	       $_ => 1,
	   }
	   @{ _init_command_filenames_found('full-paths-configuration') },
	  };

    if (defined $option_verbose
	and $option_verbose > 2)
    {
	print Dumper( { configuration_filenames_found_2 => $configuration_filenames_found_2, }, );
    }

    my $configurations_found = _init_filenames_2_symlink_commands( [ keys %$configuration_filenames_found_2, ], );

    _all_install_scripts_execute_shell_command_array($option_install_commands, $option_install_report, "    # 1. Install to ~/bin: symbolic links for workflow engine configuration
", $configurations_found);
}


sub _install_script_symbolic_link_to_engine
{
    my $project_name = shift;

    my $option_install_engine = shift;

    my $option_install_report = shift;

    my $source = "/usr/local/bin/workflow";

    my $target = "$ENV{HOME}/bin/$project_name-workflow";

    my $command = "ln -sf $source $target";

    if (not -e $target)
    {
	if ($option_verbose)
	{
	    print "$global_program_name: installation of the workflow engine with (--install-engine == $option_install_engine, --install-report == $option_install_report)\n";
	}

	_all_install_scripts_execute_shell_command_array($option_install_engine, $option_install_report, "    # 1. Install to ~/bin: symbolic link for the workflow engine with correct name\n", [ $command, ], );
    }
}


sub builtin_add_target
{
    my $arguments = shift || [];

    my $option_install_command_pl;
    my $option_install_command_python;
    my $option_install_command_sh;
    # my $option_install_command_yml;

    our $install_options
      = {
	 "install-commands-pl!" => \$option_install_command_pl,
	 "install-commands-python!" => \$option_install_command_python,
	 "install-commands-sh!" => \$option_install_command_sh,
	 # "install-commands-yml!" => \$option_install_command_yml,
	};

    use Getopt::Long qw(GetOptionsFromArray);;

    my $result = GetOptionsFromArray($arguments, %$install_options);

    if (!$result)
    {
        die "$global_program_name: *** error in option processing, try --help";
    }

    if ($option_verbose)
    {
	use Data::Dumper;

	print "$global_program_name: builtin_add_target, installation options:\n";

	print Dumper( { install_options => $install_options, }, );
    }

    my $error = '';

    my $target_name = $arguments->[0];

    if (not $error)
    {
	if (not defined $target_name)
	{
	    $error = 'no target_name found on the command line';
	}
    }

    my $target_description = $arguments->[1];

    if (not $error)
    {
	if (not defined $target_description)
	{
	    $error = 'no target_description found on the command line';
	}
    }

#     use Data::Dumper;

#     print Dumper($global_technical_project_configuration);

#     print Dumper($global_field_project_configuration);

    my $field_project_name = $global_field_project_configuration->{field_project_name};

    if (not $error)
    {
	if (not $field_project_name)
	{
	    $error = 'no valid field_project_name found in the field_project_configuration';
	}
    }

    my $sources_configuration_directory = $global_field_project_configuration->{sources_configuration_directory};

    my $configuration_data_directory = "$sources_configuration_directory/$field_project_name-configuration-data";

    if (not $error)
    {
	if (not $configuration_data_directory)
	{
	    $error = 'no valid configuration_data_directory found in the field_project_configuration';
	}
    }

    # read the targets configuration file

    my $targets_configuration_filename = "$configuration_data_directory/targets.yml";

    my $targets = YAML::LoadFile($targets_configuration_filename);

    if (not $error)
    {
	if (exists $targets->{targets}->{$target_name})
	{
	    $error = "target $target_name already exists";
	}
    }

    # add the new target, if the file already exists, we overwrite the old description

    if (!$error
	|| $error eq "target $target_name already exists")
    {
	$targets->{targets}->{$target_name}->{description} = $target_description;
    }

    # write the new targets configuration file

    if (!$error
	|| $error eq "target $target_name already exists")
    {
	YAML::DumpFile($targets_configuration_filename, $targets);

	print "$global_program_name: added target $target_name to $targets_configuration_filename\n";
    }

    if ($option_install_command_pl)
    {
	my $new_command_filename = "$field_project_name-commands-$target_name";

	$error = _builtin_add_command_filename($global_field_project_configuration, 'perl', $target_name, $new_command_filename);

	# add a template commands file with the given name

	if (not $error)
	{
	    $error = _builtin_project_commands_template_create_perl($global_field_project_configuration, $field_project_name, $target_name, $new_command_filename);

	    print "$global_program_name: created the perl command file $new_command_filename for target $target_name\n";
	}
    }

    if ($option_install_command_python)
    {
	my $new_command_filename = "$field_project_name-commands-$target_name.py";

	$error = _builtin_add_command_filename($global_field_project_configuration, 'python', $target_name, $new_command_filename);

	# add a template commands file with the given name

	if (not $error)
	{
	    $error = _builtin_project_commands_template_create_python($global_field_project_configuration, $field_project_name, $target_name, $new_command_filename);

	    print "$global_program_name: created the python command file $new_command_filename for target $target_name\n";
	}
    }

    if ($option_install_command_sh)
    {
	if (!$error
	    || $error eq "target $target_name already exists")
	{
	    $error = _builtin_project_commands_sh_template_create($global_field_project_configuration, $field_project_name, $target_name);

	    print "$global_program_name: created the shell command file for target $target_name\n";
	}
    }

    # if ($option_install_command_yml)
    # {
    # 	if (not $error)
    # 	{
    # 	    $error = _builtin_project_commands_yml_template_create($global_field_project_configuration, $field_project_name, $target_name);

    # 	    print "$global_program_name: created the yml command file for target $target_name\n";
    # 	}
    # }

    # return errors

    return $error;
}


sub builtin_add_target_completions
{
    my $complete_command_string = shift;

    my $complete_arguments_array = shift;

    my $debug_completion = 0;

    if ($debug_completion > 2)
    {
	print STDERR Dumper(
			    {
			     arguments => \@_,
			     complete_arguments_array => $complete_arguments_array,
			     complete_command_string => $complete_command_string,
			    },
			   );
    }

    my $completions_hash
	= {
	   "1.<target_name>" => '',
	   "2.<target_description>" => '',
	   "'3.[--_<options>_]'" => '',
	   "--install-commands-pl" => '',
	   "--install-commands-py" => '',
	   "--install-commands-sh" => '',
	  };

    if (scalar @$complete_arguments_array > 2)
    {
	return {};
    }
    else
    {
	return $completions_hash;
    }
}


sub builtin_add_target_help
{
    my $command = shift;

    return "$command: add a new target and update the configuration to integrate it.

synopsis:

$command <target-name> <target-description> [-- <options>]

arguments:

    ARGV[0]: name of the new target.
    ARGV[1]: description of the new target.

options:

    --install-commands-pl: install a perl command file template.
    --install-commands-py: install a python command file template.
    --install-commands-sh: install a shell command file template.
";
}


sub builtin_archive_configuration
{
    my $scripts_directory = $global_field_project_configuration->{sources_configuration_directory};

    my $tar_filename = $ARGV[0];

    # make sure the --interactions family of options works

    if ($::option_dry_run)
    {
	return '';
    }

    if (not defined $tar_filename)
    {
	die "$global_program_name: *** Error: builtin_archive_scripts expects the tar_filename as its only argument on the command line";
    }

    use Archive::Tar;

    my $compression = COMPRESS_GZIP;

    if ($tar_filename =~ m(^.*tar\.gz$))
    {
	$compression = COMPRESS_GZIP;
    }
    elsif ($tar_filename =~ m(^.*tar\.bz2$))
    {
	$compression = COMPRESS_BZIP;
    }
    elsif ($tar_filename =~ m(^.*tgz$))
    {
	$compression = COMPRESS_GZIP;
    }
    elsif ($tar_filename =~ m(^.*tbz$))
    {
	$compression = COMPRESS_BZIP;
    }
    else
    {
	die "$global_program_name: *** Error: builtin_archive_scripts expects the tar_filename to end with .tar.gz, .tar.bz2, .tgz or .tbz";
    }

    {
	my $archive_directory = "$scripts_directory/..";

	$scripts_directory =~ m(.*/(.*));

	my $directory_inside_tar_name = $1;

	use Cwd 'abs_path';

	use File::chdir;

	local $CWD = $archive_directory;

	my $getcwd = Cwd::getcwd();

	my $scripts
	    = [
	       sort
	       map
	       {
		   chomp; $_;
	       }
	       grep
	       {
		   my $filename = $_;

		   my $exclude = '';

		   if ($filename =~ m(_Inline))
		   {
		       $exclude = 'is_inline_directory';
		   }

		   not $exclude;
	       }
	       `find $directory_inside_tar_name -type f`,
	      ];

	my $tar = Archive::Tar->new();

	$tar->add_files(@$scripts);

	$tar->write($tar_filename, $compression);

	if ($option_verbose)
	{
	    use YAML;

	    print Dump( { global_field_project_configuration => $global_field_project_configuration, }, );

	    print Dump
		(
		 {
		  CWD => $CWD,
		  # directory_inside_tar_name => $directory_inside_tar_name,
		  # getcwd => $getcwd,
		  scripts => $scripts,
		  tar_filename => $tar_filename,
		 },
		);
	}
    }

    return '';
}


sub builtin_archive_configuration_completions
{
    my $complete_command_string = shift;

    my $complete_arguments_array = shift;

    my $completions_hash
	= {
	   ".tar.gz" => 'abc',
	  };

    if (scalar @$complete_arguments_array > 2)
    {
	return {};
    }
    else
    {
	return $completions_hash;
    }
}


sub builtin_archive_configuration_help
{
    my $command = shift;

    return "$command: create a tarball with the configuration of the current workflow project.

synopsis:

$command <tarball-name>

arguments:

    ARGV[0]: name of the tarball.  Recognized filename extensions are 'tar.gz', 'tar.bz2', '.tgz' and '.tbz'.

";
}


sub builtin_fetch_scripts
{
    my $sources_configuration_directory = $global_field_project_configuration->{sources_configuration_directory};

    my $commands
	= [
	   "cd '$sources_configuration_directory'",
	   "git fetch",
	  ];

    execute_shell_command_array($commands);
}


sub builtin_fetch_scripts_help
{
    my $command = shift;

    return "$command: do 'git fetch' in the workflow project directory to fetch the latest changes without updating the current workflow configuration.
";
}


sub builtin_install_scripts
{
#     use Data::Dumper;

#     print Dumper(\@_);

    my $arguments = shift || [];

    my $option_install_aliasses = 'by default';
    my $option_install_bash_completion = 'by default';
    my $option_install_commands;
    my $option_install_engine = 'by default';
    my $option_install_force;
    my $option_install_git;
    my $option_install_grc_configuration = 'by default';
    my $option_install_path_in_bashrc;
    my $option_install_report;

    our $install_options
	= {
	   "aliasses!" => \$option_install_aliasses,
	   "bash-completion!" => \$option_install_bash_completion,
	   "commands!" => \$option_install_commands,
	   "engine!" => \$option_install_engine,
	   "force!" => \$option_install_force,
	   "git!" => \$option_install_git,
	   "grc-configuration!" => \$option_install_grc_configuration,
	   "path-in-bashrc!" => \$option_install_path_in_bashrc,
	   "report!" => \$option_install_report,
	  };

    use Getopt::Long qw(GetOptionsFromArray);;

    my $result = GetOptionsFromArray($arguments, %$install_options);

    if (!$result)
    {
        die "$global_program_name: *** Error in option processing, try --help";
    }

    # need to take these actions:
    #
    # 1. Install to ~/bin: symbolic link for the workflow engine with correct name and the configuration of the project
    # 2. Install to ~/bin: symbolic links for commands
    # 3. Install to .bashrc: text addition for aliases (add to ~/.bash_aliases?) and for bash completion
    # 4. Install to /etc/grc.conf: text addition
    # 5. Install to /usr/share/grc/: symbolic links
    # 6. Create and populate the git repository

    # 1. Install to ~/bin: symbolic link for the workflow engine with correct name and the configuration of the project

    my $field_configuration = FieldProject::_init_get_field_project_configuration();

    if (!$field_configuration)
    {
        die "$global_program_name: *** error: no valid field_configuration found";
    }

    my $project_name = $field_configuration->{field_project_name};

    if (!$project_name)
    {
        die "$global_program_name: *** error: no valid project_name in the field_configuration found";
    }

    # add the ~/bin directory to PATH in .bashrc, make this optional on option_install_path_in_bashrc

    if ($option_install_path_in_bashrc)
    {
	_install_script_path_in_bashrc($project_name);
    }

    my $command_mkdir = "mkdir --parents $ENV{HOME}/bin";

    execute_shell_command($command_mkdir);

    _install_script_symbolic_link_to_engine($project_name, $option_install_engine, $option_install_report);

    _install_script_symbolic_link_to_configuration($project_name, $option_install_commands, $option_install_report);

    # _install_script_symbolic_link_to_commands_in_commands_directory($project_name, $option_install_commands, $option_install_report);

    _install_script_symbolic_link_to_commands_configured($project_name, $option_install_commands, $option_install_report);

    if ($option_install_aliasses)
    {
	_install_script_bashrc_aliasses($project_name);
    }

    if ($option_install_bash_completion)
    {
	_install_script_bash_completion($project_name);
    }

    if ($option_install_grc_configuration)
    {
	_install_script_grc_conf_additions($project_name);

	_install_script_grc_symbolic_links($project_name, $field_configuration);
    }

    if ($option_install_git)
    {
	_install_script_git_repository($project_name);
    }

    if ($option_install_engine
	or $option_install_bash_completion)
    {
	my $commands
	    = [
	       # "echo",
	       # "echo",
	       # "echo  scripts for '$project_name' have been installed.",
	       "echo",
	       "echo Bash completion can be enabled using:",
	       "echo",
	       "echo   . ./$project_name-bash-completion.sh",
	       "echo",
	       # "echo Then maybe followed with commands removing existing commands:",
	       # "echo",
	       # "echo   $project_name-workflow builtin remove_commands $project_name-commands-perl_examples $project_name-commands-python_examples.py examples_sh/*",
	       # "echo",
	       # "echo Or / and maybe followed with commands removing existing targets:",
	       # "echo",
	       # "echo   $project_name-workflow builtin remove_target perl_examples $project_name-commands-python_examples.py examples_sh/*",
	       # "echo   $project_name-workflow builtin remove_target python_examples",
	       # "echo   $project_name-workflow builtin remove_target examples_sh\n",
	       # "echo",
	       "echo Or / and maybe followed with a command to add or modify a first target, here, for the target named 'source_code':",
	       "echo",
	       "echo   $project_name-workflow builtin add_target source_code 'Operations on the source code, such as git checkout, build and installation.' -- --install-commands-py",
	       "echo",
	      ];

	execute_shell_command_array($commands, { quiet => 'only show the output of the commands' } );
    }
}


sub builtin_install_scripts_completions
{
    my $complete_command_string = shift;

    my $complete_arguments_array = shift;

    if (scalar @$complete_arguments_array > 2)
    {
	# insert all your completions here when there are arguments to complete,
	# bash will select those that apply to the current argument to be completed.

	my $options_completions_hash
	    = {
	       '--' => {
			'--aliasses' => "configure the grc aliases in .bashrc if they are not there yet.",
			'--bash-completion' => "configure bash completion in .bashrc if they are not there yet.",
			'--commands' => "install or upgrade the command configuration to ~/bin.",
			'--engine' => "create a symbolic link to the workflow engine in ~/bin.",
			'--force' => "don't use this.",
			'--git' => "create a git repository for the workflow configuration.",
			'--grc-configuration' => "install symbolic links for grc configuration to color code the workflow output (requires sudo access).",
			'--path-in-bashrc' => "update .bashrc to include ~/bin in PATH.",
			'--report' => "report on what is being done.",
		       },
	      };

	foreach my $options_completion (keys %{$options_completions_hash->{'--'}})
	{
	    $options_completions_hash->{'--'}->{$options_completion}
		= {
		   map
		   {
		       $_ => '';
		   }
		   keys %{$options_completions_hash->{'--'}}
		  };
	}

	# use Data::Dumper; print STDERR Dumper($options_completions_hash);

	return $options_completions_hash;
    }
    else
    {
	my $arguments_completions_hash
	    = {
	       'There-are-no-arguments-possible-but-options-are-available-after-a-double-dash.' => '',
	       '--' => {
			'0.Available_options:' => '',
			'--aliasses' => '',
			'--bash-completion' => '',
			'--commands' => '',
			'--engine' => '',
			'--force' => '',
			'--git' => '',
			'--grc-configuration' => '',
			'--path-in-bashrc' => '',
			'--report' => '',
		       },
	      };

	return $arguments_completions_hash;
    }
}


sub builtin_install_scripts_help
{
    my $command = shift;

    return "$command : install or upgrade the workflow scripts that are found in the current directory.

options:

    --aliasses           configure the grc aliases in .bashrc if they are not there yet.
    --bash-completion    configure bash completion in .bashrc if they are not there yet.
    --commands           install or upgrade the command configuration to ~/bin.
    --engine             create a symbolic link to the workflow engine in ~/bin.
    --force              don't use this.
    --git                create a git repository for the workflow configuration.
    --grc-configuration  install symbolic links for grc configuration to color code the workflow output (requires sudo access).
    --path-in-bashrc     update .bashrc to include ~/bin in PATH.
    --report             report on what is being done.

Note that grc configuration files will also be installed and configured.

";
}


sub builtin_print_configuration_directory
{
    my $project_name = shift;

    use YAML;

    print Dump( { global_field_project_configuration => $global_field_project_configuration, }, );

    my $error = '';

    return $error;
}


sub builtin_print_configuration_directory_help
{
    my $command = shift;

    return "$command : print the directory where the configuration of this project is found.

arguments:

    none.
";
}


sub builtin_pull_scripts
{
    my $sources_configuration_directory = $global_field_project_configuration->{sources_configuration_directory};

    my $commands
	= [
	   "cd '$sources_configuration_directory'",
	   "git pull",
	  ];

    execute_shell_command_array($commands);
}


sub builtin_pull_scripts_help
{
    my $command = shift;

    return "$command: do 'git pull' in the workflow project directory to fetch the latest changes and immediately update the current workflow configuration.
";
}


sub builtin_start_project
{
    my $arguments = shift || [];

    my $command_files = [ split '\n', `ls -1 2>/dev/null *-commands*`, ];

    my $result;

    if (not $::option_dry_run)
    {
	my $project_name = $arguments->[0] || $command_files->[0];

	if (not defined $project_name)
	{
	    die "$global_program_name: *** Error: No suitable project name could be determined, please give one on the command line.";
	}

	my $directory = Utilities::read_directory(".");

	if (ref $directory eq 'SCALAR')
	{
	    die "$global_program_name: *** Error: The current directory cannot be accessed.";
	}

	if (scalar @$directory)
	{
	    die "$global_program_name: *** Error: The current directory must be empty such that the workflow configuration are isolated from other files.";
	}

	$project_name =~ s((.*)-commands*)($1);

	print "Using '$project_name' for the name of your project.\n";

	my $error;

	my $field_project_configuration
	    = {
	       configuration_origin => 'statically_generated by builtin_start_project',
	       field_project_name => $project_name,
	       search_path_workflow_executable_directory => "$ENV{HOME}/bin",
	       # search_path_workflow_executable_filename => "$ENV{HOME}/bin/$project_name-configuration",
	       sources_configuration_directory => '.',
	       sources_configuration_filename => "./$project_name-configuration",
	       sources_configuration_data_directory => "./$project_name-commands-data",
	      };

	if (not $error)
	{
	    $error = _builtin_project_template_create($field_project_configuration, $project_name);
	}

	if (not $error)
	{
	    $error = _builtin_project_configuration_create($field_project_configuration, $project_name);
	}

	if (not $error)
	{
	    my $target_name = "perl_examples";

	    my $command_filename = "$project_name-commands-$target_name";

	    $error = _builtin_add_command_filename($field_project_configuration, 'perl', $target_name, $command_filename);

	    if (not $error)
	    {
		# add a template commands file with the given name

		$error = _builtin_project_commands_template_create_perl($field_project_configuration, $project_name, $target_name, $command_filename);
	    }
	}

	if (not $error)
	{
	    my $target_name = "python_examples";

	    my $command_filename = "$project_name-commands-$target_name.py";

	    $error = _builtin_add_command_filename($field_project_configuration, 'python', $target_name, $command_filename);

	    if (not $error)
	    {
		$error = _builtin_project_commands_template_create_python($field_project_configuration, $project_name, $target_name, $command_filename);
	    }
	}

	if (not $error)
	{
	    $error = _builtin_project_commands_sh_template_create($field_project_configuration, $project_name, "examples_sh");
	}

	if (not $error)
	{
	    # $error = _builtin_project_commands_yml_template_create($field_project_configuration, $project_name, "examples_yml");
	}

	if (not $error)
	{
	    $error = _builtin_project_gc_configuration_create($field_project_configuration, $project_name);
	}

	if (not $error)
	{
	    $error = _builtin_project_gc_workflow_create($field_project_configuration, $project_name);
	}

	if (not $error)
	{
	    $error = _builtin_project_bash_completion_create($field_project_configuration, $project_name);
	}

	if (not $error)
	{
	    $error = _builtin_project_readme_create($field_project_configuration, $project_name);
	}

	if (not $error)
	{
	    print "Created a configuration file for project '$project_name'\n";

	    print "---\nTest it with the command:\n\n";
	    print "  workflow --help-field-project-name\n\n";
	    print "Afterwards install the scripts on your system using the command:\n\n";
	    print "  workflow builtin install_scripts -- --engine --commands --git\n\n";
	    print "Then check if they work by inspecting the examples they provide (with various options):\n\n";
	    print "  $project_name-workflow examples array_of_commands_remote_execution --interactions\n\n";
	    print "  $project_name-workflow examples sequencing_and_composition --interactions-module\n\n";
	    print "  $project_name-workflow examples single_command --dry-run\n\n";
	    print "  $project_name-workflow examples array_of_commands --help\n\n";
	    print "To enable bash completion after installation of the scripts, either execute:\n\n";
	    print "  . ~/.bashrc\n\n";
	    print "Or:\n\n";
	    print "  . ./$project_name-bash-completion.sh\n\n";
	}
	else
	{
	    print STDERR "$global_program_name: *** Error: could not initialize the project $project_name ($error)\n";

	    $result = "$global_program_name: *** Error: could not initialize the project $project_name ($error)\n";
	}
    }
    else
    {
	# schedule one shell command such that it is visible in diagrams for this command

	my $commands = [ "cat 'workflow-project.pl'", ];

	execute_shell_command_array($commands);
    }

    return $result;
}


sub builtin_start_project_completions
{
    my $complete_command_string = shift;

    my $complete_arguments_array = shift;

    my $completions_hash
	= {
	   '0.Necessary_argument:' => 'help message',
	   '<project_name>' => 'name of the new project',
	  };

    if (scalar @$complete_arguments_array > 2)
    {
	return {};
    }
    else
    {
	return $completions_hash;
    }
}


sub builtin_start_project_help
{
    my $command = shift;

    return "$command: start a new project with a given name in the current directory.

This will create a project descriptor, a configuration file and an
empty command file in the current working directory.

arguments:

    name: name of the new project.
";
}


sub builtin_tmux_create_sessions
{
    my $arguments = shift || [ '_all' ];

    # my $force = $arguments->[0] || '';

    if (not scalar @$arguments)
    {
	$arguments = [ '_all' ];
    }

    my $selection = { map { $_ => 1 } @$arguments };

    my $tmux_sessions
	= [
	   grep
	   {
	       $selection->{'_all'} || $selection->{$_}
	   }
	   @{_builtin_tmux_sessions()}
	  ];

    my $tmux_session_commands
	= [
	   map { "tmux new-session -d -s $_"; }
	   @$tmux_sessions,
	  ];

    my $tmux_session_attach_commands
	= [
	   map { "echo For tmux session $_, attach with: 'tmux attach-session -t $_'"; }
	   @$tmux_sessions,
	  ];

    if (scalar @$tmux_session_commands)
    {
	execute_shell_command_array
	    (
	     [ @$tmux_session_commands, @$tmux_session_attach_commands, ],
	     {
	      # quiet => (! $force),
	      # allow_fail => $force,
	     },
	    );
    }
}


sub builtin_tmux_create_sessions_completions
{
    my $tmux_sessions = _builtin_tmux_sessions();

    return
    {
     "1.Type-the-name-of-a-known-tmux-session:" => '',
     "_all" => '',
     # '--force' => '',
     map
     {
	 $_ => ''
     }
     @$tmux_sessions,
    };
}


sub builtin_tmux_create_sessions_help
{
    my $command = shift;

    my $tmux_sessions = _builtin_tmux_sessions();

    return "$command: Create one or more configured tmux session(s).

    ARGV[0]: Optional name of a configured tmux session (the default is all configured sessions).

Configured tmux sessions are:
    " . (join ", ", @$tmux_sessions) . "
";
}


sub builtin_tmux_kill_sessions
{
    my $arguments = shift || [];

    my $force = $arguments->[0] || '';

    my $tmux_sessions = _builtin_tmux_sessions();

    my $tmux_session_commands
	= [
	   map { "tmux kill-session -t $_"; }
	   @$tmux_sessions,
	  ];

    if (scalar @$tmux_session_commands)
    {
	execute_shell_command_array
	    (
	     $tmux_session_commands,
	     {
	      allow_fail => $force,
	     },
	    );
    }
}


sub execute_shell_command
{
    return Engine::execute_shell_command(@_);
}


sub execute_shell_command_array
{
    if (not ref $_[0] eq 'ARRAY')
    {
	die "$global_program_name: *** Error: execute_shell_command_array() requires an ARRAY reference as its first argument";
    }
    elsif (defined $_[1] and not ref $_[1] eq 'HASH')
    {
	die "$global_program_name: *** Error: execute_shell_command_array() requires a HASH reference as its second argument";
    }

    return Engine::execute_shell_command_array(@_);
}


sub execute_shell_command_schedule
{
    return Engine::execute_shell_command_schedule(@_);
}


sub execute_shell_command_schedule_array
{
    return Engine::execute_shell_command_schedule_array(@_);
}


sub execute_shell_script
{
    my $filename = shift;

    # assumes $/ has its default value of a newline

    use IO::File;

    my $file = IO::File->new("<$filename");

    if (not $file)
    {
	die "$global_program_name: *** Error: no valid commands available in file '$filename'\n";
    }

    my $commands
	= [
	   map
	   {
	       chomp; $_;
	   }
	   <$file>,
	  ];

    # use Data::Dumper;

    # print Dumper($commands);

    return Engine::execute_shell_command_array($commands, @_);
}


sub execute_shell_script_command
{
    my $script_command = shift;

    my $commands_data_directory = $global_field_project_configuration->{sources_configuration_data_directory};

    my $arguments = join ' ', $script_command, map { "'$_'" } @_ ;

    my $commands
	= [
	   "cd $commands_data_directory",
	   "$arguments",
	  ];

    return Engine::execute_shell_command_array($commands);

#     return Engine::execute_shell_command("cd $commands_data_directory && $arguments");
}


# given a local script filename, execute the script remotely

sub execute_shell_script_remote
{
    my $local_filename_arguments = shift;

    my $options = shift;

    $local_filename_arguments =~ m(^(\S+)(\s+(.*))?$);

    my $local_filename = $1;

    my $arguments = $3;

    if (not -e $local_filename)
    {
	die "$global_program_name: *** Error: no valid script file '$local_filename'\n";
    }

    my $remote = $options->{remote};

    my $remote_and_interaction_role = Engine::compute_remote_and_interaction_role("", $remote, "scp");

    my $ssh_options = $remote_and_interaction_role->{ssh_options} || "";

#    my $remote_prefix = $remote_and_interaction_role->{remote_prefix};

    my $interaction_role_with_policy_syntax = $remote_and_interaction_role->{interaction_role_with_policy_syntax} || "";

    use File::Spec;

    my ($volume, $directories, $remote_filename) = File::Spec->splitpath( $local_filename );

    $remote_filename = "/tmp/$remote_filename";

    # copy the local file to the remote

    my $scp_command = "scp -pr $ssh_options $local_filename $interaction_role_with_policy_syntax$remote_filename";

    # execute_shell_command($scp_command, { %$options, remote => undef, }, @_);
    execute_shell_command($scp_command, { remote => undef, }, @_);

    # execute the remote file with the remote role

    return Engine::execute_shell_command("$remote_filename $arguments", $options, @_);
}


sub _file_append_string
{
    my $filename = shift;

    my $string = shift;

    my $options = shift;

    $string =~ s(")(\\")g;

    my $command = "bash -c \"echo '$string' | cat >>$filename\"";

    execute_shell_command($command, $options);

    # open(my $fh, ">>$filename");

    # print $fh $string;

    # close $fh;
}


sub _file_contains_regex
{
    my $filename = shift;

    my $string = shift;

    if (!-e $filename)
    {
	return '';
    }

    my $data
	= do {
	    open my $fh, '<', $filename;
	    local $/;
	    <$fh>;
	};

    my $result = ($data =~ /$string/);

    if ($option_verbose
	and $option_verbose > 1)
    {
	if ($result)
	{
	    print "$global_program_name: _file_contains_regex(): match file '$filename' with '$string' (result is $result)\n";
	}
	else
	{
	    print "$global_program_name: _file_contains_regex(): no match file '$filename' with '$string' (result is $result)\n";
	}
    }

    return $result;
}


#
# Initialize the command module.
#
# This sub reads and parses the workflows written in perl or python.
#

sub _workflow_commands_initialize
{
    my $commands_seen;

    my $field_project_name = $global_field_project_configuration->{field_project_name};

    # only those command files mentioned in the configuration

    my $command_filenames_configured = _init_command_filenames_configured('true-paths');

    # print STDERR Dumper( { command_filenames_configured => $command_filenames_configured, } );

    my $command_filenames_to_use
	= [
	   sort
	   grep
	   {
	       # remove duplicate filenames to avoid duplicate command definitions

	       if ($commands_seen->{$_})
	       {
		   print "$global_program_name: *** Warning: $_ is mentioned $commands_seen->{$_} time(s) in the configuration (hint: sort your filenames to spot such errors quickly).\n";
	       }

	       not $commands_seen->{$_}++;
	   }
	   @$command_filenames_configured,
	  ];

    foreach my $command_filename (@$command_filenames_to_use)
    {
	# print STDERR "Executing $command_filename\n";

	my $file_type;

	if ($command_filename =~ m(\.yml$))
	{
	    $file_type = 'yaml';
	}
	elsif ($command_filename =~ m(\.py$))
	{
	    $file_type = 'python';
	}
	else
	{
	    $file_type = 'perl';
	}

	if ($file_type eq 'python')
	{
	    # my ($commands, $eval_status) = FieldProject::_init_do_eval_python_file($command_filename);
	    my ($commands, $eval_status) = Command::_init_do_eval_python_file($command_filename);

	    if ($eval_status)
	    {
		die "$global_program_name: *** Error: no valid commands file '$command_filename' found ($eval_status)\n";
	    }
	}
	elsif ($file_type eq 'perl')
	{
	    my ($commands, $eval_status) = FieldProject::_init_do_eval_perl_file($command_filename);

	    if ($eval_status)
	    {
		die "$global_program_name: *** Error: no valid commands file '$command_filename' found ($eval_status)\n";
	    }
	}
	elsif ($file_type eq 'yaml')
	{
	    my ($commands, $eval_status) = FieldProject::_init_do_eval_yaml_command_file($command_filename);

	    if ($eval_status)
	    {
		die "$global_program_name: *** Error: no valid commands file '$command_filename' found ($eval_status)\n";
	    }
	}
	else
	{
	    die "$global_program_name: *** Error: invalid file type $file_type for commands file '$command_filename'\n";
	}
    }
}


#
# construct the command filename list, then:
#
# if full_paths is the empty string: nothing more is done.
#
# if full_paths is 'true-paths': the ~/bin directory is prefixed.
#
# if full_paths is 'full-paths': the sources_configuration_directory is prefixed.
#
# Only command filenames containing the string '-commands' are
# returned.

sub _init_command_filenames_configured
{
    # full_paths is either the empty string '' or 'full-paths' or 'true-paths'.

    my $full_paths = shift;

    my $field_project_name = $global_field_project_configuration->{field_project_name};

    # when invoked as just 'workflow' the directory where to search
    # for command files will not necessarily be /usr/local/bin'
    # it may also be the current working directory

    # default to the directory with the main executable

    my $command_filename_directory = $global_field_project_configuration->{sources_configuration_directory};

    my $command_filenames = $global_technical_project_configuration->{command_filenames};

    my $command_filenames_full_paths
	= [
	   map
	   {
	       # map the command filename to its full path

	       $full_paths ? "$command_filename_directory/$_" : "$_";
	   }
	   @$command_filenames,
	  ];

    my $command_filenames_full_paths_selected
	= [
	   grep
	   {
	       # select filenames with the correct project name prefix

	       /$field_project_name-commands[-\._a-z0-9]*$/;
	   }
	   grep
	   {
	       my $command_filename = $_;

	       # select filenames that have the string -commands

	       my $result = ($command_filename =~ m(-commands));

	       if (not $result)
	       {
		   print STDERR "$global_program_name: *** Error: $command_filename does not follow command filename conventions (must have '-commands')\n";
	       }

	       $result;
	   }
	   @$command_filenames_full_paths,
	  ];

    # print STDERR Dumper(@$command_filenames_full_paths_selected);

    my $result
	= [
	   sort
	   map
	   {
	       # map the command filename to its true path if this was requested

	       my $command_filename = $_;

	       # if (not defined $command_filename)
	       # {
	       # 	   use Data::Dumper;

	       # 	   print Dumper(
	       # 			{
	       # 			 command_filenames_full_paths => $command_filenames_full_paths,
	       # 			 command_filenames_full_paths_selected => $command_filenames_full_paths_selected,
	       # 			 command_filenames => $command_filenames,
	       # 			 full_paths => $full_paths,
	       # 			},
	       # 		       );
	       # }

	       #! this returns undef if the file does not exist

	       if ($full_paths eq 'true-paths')
	       {
		   use Cwd;

 		   $command_filename = Cwd::abs_path($command_filename);

		   # print STDERR $!;
	       }

	       defined $command_filename ? $command_filename : ();
	   }
	   @$command_filenames_full_paths_selected
	  ];

    #! options haven't been processed yet for some execution paths

    if ($option_verbose
	and $option_verbose > 1)
    {
	use Data::Dumper;

	print STDERR Dumper(
			    {
			     _init_command_filenames_configured => $result,
			     command_filename_directory => $command_filename_directory,
			     command_filenames => $global_technical_project_configuration->{command_filenames},
			     command_filenames_full_paths => $command_filenames_full_paths,
			     command_filenames_full_paths_selected => $command_filenames_full_paths_selected,
			     full_paths => $full_paths,
			    },
			   );
    }

    return $result;
}


# find all the command files, including those not mentioned in the
# configuration
#
# full_paths is either 'full-paths' or 'full-paths-configuration'.
#

sub _init_command_filenames_found
{
    my $full_paths = shift;

    my $field_project_name = $global_field_project_configuration->{field_project_name};

    # when invoked as just 'workflow' the directory where to search
    # for command files will not necessarily be /usr/local/bin'
    # it may also be the current working directory

    my $command_filename_directory = $global_field_project_configuration->{search_path_workflow_executable_directory};

    my $result
	= [
	   sort
	   # grep
	   # {
	   #     ($full_paths =~ "configuration"
	   # 	? m/$field_project_name-configuration[-a-z0-9]*$/
	   # 	: m/$field_project_name-commands[-a-z0-9]*$/);
	   # }
	   map
	   {
	       chomp; $_;
	   }
	   ($full_paths =~ "configuration"
	    ? `ls 2>/dev/null $command_filename_directory/$field_project_name-configuration`
	    : `ls 2>/dev/null $command_filename_directory/$field_project_name-commands*`),
	  ];

    # system "ls 2>/dev/null $command_filename_directory/$field_project_name-configuration*";
    # system "ls 2>/dev/null $command_filename_directory/$field_project_name-commands*";

    # use Data::Dumper;

    # print STDERR "ls $command_filename_directory/$field_project_name-commands*\n";

    # print STDERR Dumper(
    # 			{
    # 			 global_field_project_configuration => $global_field_project_configuration,
    # 			 _init_command_filenames_found => $result,
    # 			 all_path_globals => $all_path_globals,
    # 			},
    # 		       );

    return $result;
}


# given a list of filenames, create system shell commands that create
# symbolic links in the ~/bin directory to each of these filenames.
#
# each given filename must match with *-(commands|configuration) and
# is checked for existence.

sub _init_filenames_2_symlink_commands
{
    my $filenames = shift;

    use Data::Dumper;

    if (defined $option_verbose
	and $option_verbose > 3)
    {
	print Dumper( { _init_filenames_2_symlink_commands_filenames => $filenames, }, );
    }

    my $commands
	= [
	   map
	   {
	       # $_ =~ m(.*/(.*)$);

	       my $command_filename = $_;

	       use Cwd;

	       my $source = Cwd::abs_path($command_filename);

	       use File::Spec;

	       my ($volume, $directories, $filename) = File::Spec->splitpath($command_filename);

	       my $target = "$ENV{HOME}/bin/$filename";

	       my $result = "ln -sf $source $target";

	       if (defined $option_verbose
		   and $option_verbose > 2)
	       {
		   print "$command_filename: $result\n";
	       }

	       $result;
	   }
	   grep
	   {
	       my $command_filename = $_;

	       my $result = ($command_filename =~ m(-commands|-configuration));

	       if (not $result)
	       {
		   print STDERR "$global_program_name: *** Error: $command_filename does not follow command filename conventions (must have '-commands|-configuration')\n";
	       }

	       $result;
	   }
	   grep
	   {
	       my $command_filename = $_;

	       use File::Spec;

	       my ($volume, $directories, $filename) = File::Spec->splitpath($command_filename);

	       my $target = "$ENV{HOME}/bin/$filename";

	       not -e $target;
	   }
	   sort @$filenames,
	  ];

    if (defined $option_verbose
	and $option_verbose > 3)
    {
	print Dumper( { _init_filenames_2_symlink_commands_commands => $commands, }, );
    }

    return $commands;
}


package Command::Buildroot;

# add op-target-dependencies of op-power

sub builtin_packages
{
}


sub builtin_packages_help
{
    my $command = shift;

    return "$command: List all the packages that Buildroot can build in a given configuration.

This skips host-* (uninteresting) and target-* (buildroot special) packages.
";
}


sub builtin_package_dependencies
{
    my $arguments = shift || [];

    my $package_name = $arguments->[0];

    if (not defined $package_name)
    {
	die "$0: *** Error: No package given but it is required for finding its dependencies.";
    }
}


sub builtin_package_dependencies_help
{
    my $command = shift;

    return "$command: List the dependencies of a given package.
";
}


package Command::Git;


# Based on https://gist.github.com/bonovoxly/b4f7502f2b6cdb26a779dbfb73d4d134

sub builtin_git_move_file_across_keep_history
{
    my $arguments = shift || [];

    my $git_source_repo = $arguments->[0];

    if (!defined $git_source_repo)
    {
	die "$0: *** Error: git_source_repo, ARGV[0] is not defined.";
    }

    my $git_source_branch = $arguments->[1];

    if (!defined $git_source_branch)
    {
	die "$0: *** Error: git_source_branch, ARGV[1] is not defined.";
    }

    my $git_target_repo = $arguments->[2];

    if (!defined $git_target_repo)
    {
	die "$0: *** Error: git_target_repo, ARGV[2] is not defined.";
    }

    my $git_target_branch = $arguments->[3];

    if (!defined $git_target_branch)
    {
	die "$0: *** Error: git_target_branch, ARGV[3] is not defined.";
    }

    #! git supports muliple --path arguments, the filename could be a comma separated list of filenames

    my $working_directory = $arguments->[4] || "/tmp/working-directory";

    if (!defined $working_directory)
    {
	die "$0: *** Error: working_directory, ARGV[4] is not defined.";
    }

    my $filename = $arguments->[5];

    if (!defined $filename)
    {
	die "$0: *** Error: filename, ARGV[5] is not defined.";
    }

    # take the remainder of the arguments as path names for filter-repo

    my $filenames = [ @$arguments[5 .. $#$arguments], ];

    my $paths = join ' ', (map { "--path $_"; } @$filenames);

    # determine the source and target project names

    $git_source_repo =~ m(.*/(.*)$);

    my $git_source_name = "$1_1";

    $git_target_repo =~ m(.*/(.*)$);

    my $git_target_name = "$1_2";

    if (!defined $git_source_repo
	|| !defined $git_source_branch
	|| !defined $git_target_repo
	|| !defined $git_target_branch
	|| !defined $filename
	|| !defined $working_directory
	|| !defined $git_source_name
	|| !defined $git_target_name)
    {
    }

    # copy a file across repositories and keep its history

    # 11143  cd ~/projects/git-copy-file-between-repos/
    # ...
    # 11160  git clone --no-local ~/projects/developer/source/snapshots/master ./developer
    # 11161  git clone --no-local ~/projects/workflow-automation-engine/source/snapshots/master ./workflow-automation-engine

    # 11162  cd ./developer/
    # 11163  git checkout master
    # ...
    # 11168  git filter-repo --force --path bin/neurospaces_harness --refs refs/heads/master
    # ...
    # 11171  cd ../workflow-automation-engine/
    # 11172  git checkout -b add-harness
    # 11173  git remote add repo-source ../developer/
    # 11174  git fetch repo-source
    # ...
    # 11178  git branch branch-source remotes/repo-source/master
    # 11179  git merge branch-source --allow-unrelated-histories

    my $commands
	= [
	   ## git-filter-repo

	   # - Stage a working area. These are somewhat throwaway directories and local git repos.
	   # - clone both source and target repos.

	   "mkdir -p '$working_directory'",
	   "cd '$working_directory'",
	   "git clone '$git_source_repo' './$git_source_name'",
	   "git clone '$git_target_repo' './$git_target_name'",

	   ### In source repo

	   # We checkout a branch that we will filter against. We specify the path(s) that we want.

	   "cd './$git_source_name'",
	   "git checkout '$git_source_branch'",

	   #! note: requires 'sudo apt install git-filter-repo'

	   "git filter-repo $paths --refs refs/heads/$git_source_branch --force",

	   ## In target repo

	   "cd '../$git_target_name'",
	   "git checkout -b 'working-target-branch'",
	   "git remote add repo-source '../$git_source_name'",
	   "git fetch repo-source",
	   "git branch branch-source 'remotes/repo-source/$git_source_branch'",
	   "git merge branch-source --allow-unrelated-histories",
	  ];

    Command::execute_shell_command_array($commands);

    my $commands_echo
	= [
	   "echo",
	   "echo ==========",
	   "cd '$working_directory/$git_target_name'",
	   "git log -1",
	   "echo ==========",
	   "echo",
	   "echo The resulting repository can be found in '$working_directory/$git_target_name'",
	   "echo",
	   "echo 'Maybe you should now synchronize that repository with your remote:'",
	   "echo",
	   "echo 'git pull <your-remote> $git_source_branch'",
	   "echo",
	  ];

    Command::execute_shell_command_array
	    (
	     $commands_echo,
	     {
	      quiet => 'give a meaningful end message to the user',
	     },
	    );
}


sub builtin_git_move_file_across_keep_history_help
{
    my $command = shift;

    return "$command: given a source and target git repository and a file in the
source, copy the file with its Git history to the target repository.

This workflow:

(1) clones the two given repositories in the working_directory

(2) in the cloned source repository, removes all files in the source
branch, except the given file,

(3) adds the cloned source repository as a remote to the cloned target
repository

(4) merges the source branch with the target branch.

This workflow depends on 'git-filter-repo'.  To install it on Ubuntu
you use:

'sudo apt install git-filter-repo'

arguments:

    ARGV[0]: source_repo
    ARGV[1]: source_branch with the file
    ARGV[2]: target_repo
    ARGV[3]: target working branch
    ARGV[4]: working_directory, when '0' or an empty string, /tmp/working-directory is used
    ARGV[5] ... : filenames

After the command has completed, you likely want to do:

\$ git pull <your-remote> \$git_source_branch

where <your-remote> repository is your base repository which may be
the same as your source repository.

"; }


package Command::Git::RepositorySet;


our $project_name = 'example_project';

our $source_code_directory_prefix = "$ENV{HOME}/projects/$project_name/source";

our $all_repository_descriptors
    = {
       simple_repository1 => {
			      name => 'simple_repository1',
			      repository => 'git@gitlab.com:example_repositories/simple_repository1.git',
			     },
       simple_repository2 => {
			      name => 'simple_repository2',
			      repository => 'git@gitlab.com:example_repositories/simple_repository2.git',
			     },
       recursive_repository => {
				name => 'recursive_repository',
				recurse => 1,
				repository => 'git@gitlab.com:example_repositories/recursive_repository.git',
			       },
      };


sub _repository_2_directory
{
    my $repository = shift;

    my $directory;
    my $port;
    my $repository_name;
    my $server;

    if ($repository =~ m(^https?://))
    {
	$repository =~ m(^https?://([^/:]+(:([0-9]+))?)/(.*?)/([^/]*)$);

	$directory = $4;
	$port = $3;
	$repository_name = $5;
	$server = $1;
    }
    else
    {
	$repository =~ m(:(([0-9]+)/)?(.*?)/([^/]*)$);

	$directory = $3;
	$port = $2;
	$repository_name = $4;
    }

    if ((not defined $source_code_directory_prefix)
	or (not defined $directory)
	or (not defined $repository_name))
    {
	die "$0: *** Error: _repository_2_directory() does not find a suitable directory for the '$repository' repository (directory: directory, repository_name: $repository_name).";
    }

    my $result = "$source_code_directory_prefix/$directory/$repository_name";

    if (defined $option_verbose
	and $option_verbose > 3)
    {
	use Data::Dumper;

	print Dumper(
		     {
		      _repository_2_directory => {
						  port => $port,
						  directory => $directory,
						  repository_name => $repository_name,
						  repository => $repository,
						  result => $result,
						  source_code_directory_prefix => $source_code_directory_prefix,
						 },
		     },
		    );
    }

    return $result;
}


sub _populate_directories
{
    foreach my $repository_descriptor_key (sort keys %$all_repository_descriptors)
    {
	my $repository_descriptor = $all_repository_descriptors->{$repository_descriptor_key};

	my $repository = $repository_descriptor->{repository};

	$repository_descriptor->{directory} = _repository_2_directory($repository);
    }
}


sub _commands_branches
{
    my $repository = shift || '.*';

    my $commands
	= [
	   map
	   {
	       my $repository_descriptor = $all_repository_descriptors->{$_};

	       my $directory = $repository_descriptor->{directory};

	       ("cd '$directory'",
		"git branch -a");
	   }
	   sort
	   grep
	   {
	       # only those that match with the given repository name

	       $_ =~ m(^$repository$);
	   }
	   keys %$all_repository_descriptors,
	  ];
}


sub _commands_create
{
    my $commands
	= [
	   map
	   {
	       my $repository_descriptor = $all_repository_descriptors->{$_};

	       my $name = $repository_descriptor->{name};

	       my $repository = $repository_descriptor->{repository};

	       my $directory = _repository_2_directory($repository);

	       my $recurse = $repository_descriptor->{recurse};

	       my $recurse_option = $recurse ? "--recurse-submodules" : "";

	       ("mkdir -p '$directory'",
		"cd '$directory'",
		"echo '---\n$name'",
		"git clone $recurse_option '$repository' .");
	   }
	   sort keys %$all_repository_descriptors,
	  ];
}


sub _flags_create
{
    return
    {
     allow_fail => 'to allow partial updates after new repositories have been added',
     quiet => 'always',
    };
}


sub _commands_echo_directories
{
    my $commands
	= [
	   map
	   {
	       my $repository_descriptor = $all_repository_descriptors->{$_};

	       my $repository = $repository_descriptor->{repository};

	       my $directory = _repository_2_directory($repository);

	       ("echo '---\n$directory'",
		"echo '    --> $repository'");
	   }
	   sort keys %$all_repository_descriptors,
	  ];
}


sub _flags_echo_directories
{
    return { quiet => 'always', };
}


sub _commands_checkout
{
    my $branch = shift || '';

#     use Data::Dumper; print STDERR Dumper($all_repository_descriptors);

    my $commands
	= [
	   map
	   {
	       my $repository_descriptor = $all_repository_descriptors->{$_};

	       my $repository = $repository_descriptor->{repository};

	       my $directory = _repository_2_directory($repository);

	       my $recurse = $repository_descriptor->{recurse};

	       my $recurse_option = $recurse ? "--recurse-submodules" : "";

	       ("cd '$directory'",
		"git checkout $recurse_option $branch");
	   }
	   sort keys %$all_repository_descriptors,
	  ];
}


sub _commands_fetch
{
    my $repository = shift || '.*';

    my $commands
	= [
	   map
	   {
	       my $repository_descriptor = $all_repository_descriptors->{$_};

	       my $repository = $repository_descriptor->{repository};

	       my $directory = _repository_2_directory($repository);

	       my $recurse = $repository_descriptor->{recurse};

	       my $recurse_option = $recurse ? "--recurse-submodules" : "";

	       ("cd '$directory'",
		"git fetch $recurse_option");
	   }
	   sort
	   grep
	   {
	       # only those that match with the given repository name

	       $_ =~ m(^$repository$);
	   }
	   keys %$all_repository_descriptors,
	  ];
}


sub _commands_pull
{
    my $repository = shift || '.*';

    my $commands
	= [
	   map
	   {
	       my $repository_descriptor = $all_repository_descriptors->{$_};

	       my $repository = $repository_descriptor->{repository};

	       my $directory = _repository_2_directory($repository);

	       my $recurse = $repository_descriptor->{recurse};

	       my $recurse_option = $recurse ? "--recurse-submodules" : "";

	       ("cd '$directory'",
		"git pull $recurse_option");
	   }
	   sort
	   grep
	   {
	       # only those that match with the given repository name

	       $_ =~ m(^$repository$);
	   }
	   keys %$all_repository_descriptors,
	  ];
}


sub _flags_pull
{
    return ();
}



sub _commands_status
{
    my $commands
	= [
	   map
	   {
	       my $repository_descriptor = $all_repository_descriptors->{$_};

	       my $repository = $repository_descriptor->{repository};

	       my $directory = _repository_2_directory($repository);

	       my $recurse = $repository_descriptor->{recurse};

	       ("cd '$directory'",
		"git status");
	   }
	   sort keys %$all_repository_descriptors,
	  ];
}


sub _flags_status
{
    return ();
}


sub _repository_completions
{
    my $complete_command_string = shift;

    my $complete_arguments_array = shift;

    my $completions_hash
	= {
	   "1.type-one-of-the-following-repositories" => '',
	   map
	   {
	       $_ => '',
	   }
	   keys %$all_repository_descriptors,
	  };

    my $debug_completion = 0;

    if ($debug_completion > 2)
    {
	print STDERR Dumper(
			    {
			     arguments => \@_,
			     complete_arguments_array => $complete_arguments_array,
			     complete_command_string => $complete_command_string,
			     completions_hash => $completions_hash,
			    },
			   );
    }

    return $completions_hash;
}


package Command::GitLab;


sub builtin_gitlab_clone_install
{
    my $project_name = $ARGV[0];

    my $url = $ARGV[1];

    my $branch_name = $ARGV[2] || "main";

    # create a new repository

    my $commands
	= [
	   "git clone git\@gitlab.com:$url/$project_name.git",
	   "cd $project_name",
	   "git switch --create $branch_name",
	   "touch README.md",
	   "git add README.md",
	   "git commit -m \"Add README.\"",
	   "git push --set-upstream origin $branch_name",
	  ];

    execute_shell_command_array($commands);
}


sub builtin_gitlab_push
{
    my $project_name = $ARGV[0];

    my $url = $ARGV[1];

    my $branch_name = $ARGV[2] || "main";

    # after creation of a new project, upload it to gitlab with gitlab-workflow push <url>

    my $commands
	= [
	   "git remote rename origin old-origin",
	   "git remote add origin git\@gitlab.com:$url/$project_name.git",
	   "git push --set-upstream origin --all",
	   "git push --set-upstream origin --tags",
	  ];

    execute_shell_command_array($commands);
}


sub builtin_gitlab_create_unused
{
    my $project_name = $ARGV[0];

    my $url = $ARGV[1];

    my $branch_name = $ARGV[2] || "main";

    # push an existing folder

    my $commands
	= [
	   "git init --initial-branch=$branch_name",
	   "git remote add origin git\@gitlab.com:$url/$project_name.git",
	   "git add .",
	   "git commit -m \"Initial commit.\"",
	   "git push --set-upstream origin $branch_name",
	  ];

    execute_shell_command_array($commands);
}


package Command::Linux;


sub _config_compare_items
{
    my $commands
	= [
	   'grep ^CONFIG_ .config | sort > old.config',
	   'yes \'\' | make oldconfig',
	   'grep ^CONFIG_ .config | sort > new.config',
	   'diff -Nur old.config new.config',
	  ];

    Command::execute_shell_command_array($commands);
}


sub _config_compare_items_help
{
    my $command = shift;

    return "$command: Determine which CONFIG options have been renamed or deprecated in a newer kernel

After running this command, check what was dropped between old and new, and use the Git log of the kernel to find out what happened.

";
}


package Command::Net::IPerf;


my $iperf_configuration
    = {
       command => "iperf3",
       server => {
		  command => "/home/fio/iperf3-arm32v7",
		  options_old => "-s -f K -D",
		  options => "-s -D",
		 },
       client => {
		  options_old => "-f M",
		  options => "-i 1 -t 5 -b 0",
		 },
      };


sub _iperf_test
{
    my $test_file = shift;

    my $server = shift;

    my $client = shift;

    if ($client eq 'local')
    {
	$client = undef;
    }

    if ($server eq 'local')
    {
	$server = undef;
    }

    my $iperf_command = $iperf_configuration->{command};

    my $iperf_command_server = $iperf_configuration->{server}->{command} || $iperf_command;

    my $iperf_command_client = $iperf_configuration->{client}->{command} || $iperf_command;

    my $iperf_server_options = $iperf_configuration->{server}->{options};

    my $schedule_server
	= {
	   commands => [
			"$iperf_command_server $iperf_server_options",
		       ],
	   options => [
		       {
			remote => $server,
		       },
		      ],
	  };

    my $iperf_client_options = $iperf_configuration->{client}->{options};

    my $ip_server = $server ? $server->{ssh_server} : '127.0.0.1';

    my $schedule_client
	= {
	   commands => [
			"$iperf_command_client $iperf_client_options -c $ip_server",
		       ],
	   options => [
		       {
			remote => $client,
		       },
		      ],
	  };

    my $schedule_terminate_server
	= {
	   commands => [
			"killall $iperf_command_server",
		       ],
	   options => [
		       {
			remote => $server,
		       },
		      ],
	  };

    Command::execute_shell_command_schedule_array
	(
	 [
	  $schedule_server,
	  $schedule_client,
	  $schedule_terminate_server,
	 ],
	);

}


package Engine;


our $global_exported_sh_file;

our $global_exported_sh_filename;

our $global_exported_times_file;

our $global_exported_times_filename;


# note: keys are interaction_roles, values are working directories

our $global_remote_working_directory = {};


sub working_directory_for_interaction_role_apply
{
    my $interaction_role = shift;

    my $command = shift;

    my $result = $command;

    if ($interaction_role eq "localuser\@localhost")
    {
    }

    # apply the current directory

    my $current_working_directory = $global_remote_working_directory->{$interaction_role};

    if (defined $current_working_directory)
    {
	if ($interaction_role eq "localuser\@localhost")
	{
	    #! the cd command will be executed by the (process running the) workflow engine.
	}
	else
	{
	    #! quoting is a problem here

	    $result = "'cd $current_working_directory && $command'";
	}
    }

    if ($interaction_role =~ m(^tmux_))
    {
	$result = "'$command' ENTER";
    }

    return $result;
}


# keep track of the possibly remote working directory

sub _working_directory_for_interaction_role_change
{
    my $interaction_role = shift;

    my $working_directory = shift;

    my $current_working_directory = $global_remote_working_directory->{$interaction_role};

    if (not defined $current_working_directory)
    {
	if ($interaction_role eq 'localuser@localhost')
	{
	    $current_working_directory = '.';
	}
	else
	{
	    $current_working_directory = '~';
	}
    }

    use File::Spec;

    my $is_absolute = File::Spec->file_name_is_absolute( $working_directory );

    my $new_working_directory;

    if ($is_absolute)
    {
	$new_working_directory = $working_directory;
    }
    else
    {
	if (not defined $current_working_directory)
	{
	    die "*** Error: $global_program_name: current_working_directory not defined when parsing directories for interaction role '$interaction_role'.";
	}

	if (not defined $working_directory)
	{
	    die "*** Error: $global_program_name: working_directory not defined when parsing directories for interaction role '$interaction_role'.";
	}

	$new_working_directory = File::Spec->catdir( $current_working_directory, $working_directory );
    }

    $global_remote_working_directory->{$interaction_role} = $new_working_directory;
}


sub working_directory_for_interaction_role_parse
{
    my $executable_command = shift;

    my $dry_run = shift;

    my $interaction_role = shift;

    my $cd_argument;

    # if this is a chdir executable_command

    my $cd_command = _process_cd_command($executable_command);

    if ($cd_command)
    {
	# process its arguments

	my $cd_argument = $cd_command->{argument};

	# remove quotes, they are invalid in directory names for the purpose of this script

	$cd_argument =~ s/^'//g;
	$cd_argument =~ s/'$//g;

	# some forms of chdir require an argument,
	# some forms of cd don't and use a default of $HOME

	if ($cd_argument =~ /^\s*$/)
	{
	    $cd_argument = $ENV{HOME};
	}

	my $rest_of_command_line = $cd_command->{rest_of_command_line};

	$executable_command = "cd $cd_argument $rest_of_command_line";

	# keep track of the possibly remote working directory

	_working_directory_for_interaction_role_change($interaction_role, $cd_argument);
    }
    else
    {
#  	$executable_command = working_directory_for_interaction_role_apply($interaction_role, $executable_command);
    }

    # return the possibly processed result

    return $executable_command;
}


sub build_tree_needs_rebuild
{
    my $build_tree = shift;

    my $options = shift;

    my $result = "default is to rebuild";

    my $remote_prefix = $options->{remote_prefix};

    if ($option_force_rebuild)
    {
	if ($option_verbose
	    and $option_verbose > 1)
	{
	    print "build_tree_needs_rebuild(): option_force_rebuild is set\n";
	}

	return "option_force_rebuild";
    }

    # if we have sources and targets

    if ($build_tree->{sources}
	and $build_tree->{targets})
    {
	# determine the youngest source file

	my $source_youngest = 0;

	my $sources = $build_tree->{sources};

	foreach my $source (@$sources)
	{
	    #! %Y gives second accuracy, %y gives a higher resolution
	    #! but its output requires more parsing

	    my $source_stat_command = 'stat --format="%Y" ' . "'$source'";

	    if ($remote_prefix)
	    {
		$source_stat_command = "$remote_prefix   $source_stat_command";
	    }

	    my $source_stat_output = `$source_stat_command 2>/dev/null`;

	    if ($option_verbose
		and $option_verbose > 1)
	    {
		print "build_tree_needs_rebuild(): source_stat_output: $source_stat_output ($source)\n";
	    }

	    if ($?)
	    {
		return 1;
	    }

	    # the youngest source file is the one with the highest seconds value

	    if ($source_stat_output > $source_youngest)
	    {
		$source_youngest = $source_stat_output;
	    }
	}

	# determine the oldest target file

	my $target_oldest = 16127117390; # GMT: Friday, January 17, 2481 10:49:50 AM

	my $targets = $build_tree->{targets};

	foreach my $target (@$targets)
	{
	    #! %Y gives second accuracy, %y gives a higher resolution
	    #! but its output requires more parsing

	    my $target_stat_command = 'stat --format="%Y" ' . "'$target'";

	    if ($remote_prefix)
	    {
		$target_stat_command = "$remote_prefix   $target_stat_command";
	    }

	    my $target_stat_output = `$target_stat_command 2>/dev/null`;

	    if ($option_verbose
		and $option_verbose > 1)
	    {
		print "build_tree_needs_rebuild(): target_stat_output: $target_stat_output ($target)\n";
	    }

	    if ($?)
	    {
		return 1;
	    }

	    # the oldest target file is the one with the smallest seconds value

	    if ($target_stat_output < $target_oldest)
	    {
		$target_oldest = $target_stat_output;
	    }
	}

	# if the youngest source file is younger than the oldest target file

	if ($source_youngest >= $target_oldest)
	{
	    # we need to rebuild

	    $result = 1;
	}

	# else all the target files  are younger than the youngest source file

	else
	{
	    # so we don't need to rebuild

	    $result = 0;
	}

	if ($option_verbose
	    and $option_verbose > 1)
	{
	    print "build_tree_needs_rebuild(): source_youngest: $source_youngest, target_oldest: $target_oldest ==> needs_rebuild: $result\n";
	}

    }

    # return result

    return $result;
}


sub display_commented_command
{
    my $command = shift;

    my $options = shift;

    if (not $options->{quiet})
    {
	if ($options->{annotation})
	{
	    my $annotation = "\n$options->{annotation}";

	    $annotation =~ s(\n(.))(\n### $1)g;

	    print "$annotation\n";
	}

	# print "# $command (length: $command_length)\n#\n";

	print "# $command\n#\n";
    }
}


# TODO: this needs refactoring to appear as an argument to function calls

our $global_interaction_roles = {};

my $current_interaction_role;


# apply the remoting prefix

sub apply_remote_record_exported_command
{
    my $interaction_roles = shift;

    my $remote_prefix = shift;

    my $command = shift;

    my $export_remote = shift;

    my $export_sh_command = shift;

    # if we are exporting remotes

    if (defined $export_remote)
    {
	# if we are exporting this one role or all roles

	if (($export_remote eq 0)
	    or ($export_remote eq $interaction_roles->{$current_interaction_role}->{name})
	    or $export_remote eq $interaction_roles->{$current_interaction_role}->{number})
	{
	    # we export the command without the remoting information

	    $export_sh_command = $command;
	}

	# this is a command for a different role

	else
	{
	    # export as a comment

	    if ($remote_prefix)
	    {
		$export_sh_command = "# <remote command at $remote_prefix: $command>";
	    }
	    else
	    {
		$export_sh_command = "# <local command: $command>";
	    }
	}

	if ($current_interaction_role =~ m(^tmux_))
	{
	    $export_sh_command =~ s(\s+ENTER\s*$)();
	}
    }

    # apply the remote prefix

    if ($remote_prefix)
    {

	$command = "$remote_prefix   $command";
    }

    # if we are exporting all roles

    if (defined $export_remote
	and ($export_remote eq 0))
    {
	# we export the command with the remoting information prefixed

	$export_sh_command = $command;
    }

    return ($command, $export_sh_command);
}


# apply the sudo prefix

sub apply_sudo
{
    my $sudo_prefix = shift;

    my $command = shift;

    my $option_export_sudo = shift;

    my $export_sh_command = shift;

    if ($sudo_prefix)
    {
	$command = "$sudo_prefix   $command";

	if ($option_export_sudo)
	{
	    $export_sh_command = $command;
	}
    }

    return ($command, $export_sh_command);
}


# apply the timeout prefix

sub apply_timeout
{
    my $timeout_prefix = shift;

    my $command = shift;

    my $option_export_timeout = shift;

    my $export_sh_command = shift;

    if ($timeout_prefix)
    {
	$command = "$timeout_prefix   $command";

	$export_sh_command = $command;
    }

    return ($command, $export_sh_command);
}


sub compute_remote_and_interaction_role
{
    my $command = shift;

    my $options_remote = shift;

    my $remote_policy = shift;

    # default result: an empty string

    my $remote_prefix = "";

    my $interaction_role;

    my $interaction_role_with_policy_syntax;

    my $ssh_options;

    if ($option_verbose)
    {
	use Data::Dumper;

	print Dumper
	    (
	     {
	      compute_remote_and_interaction_role => {
						      command => $command,
						      options_remote => $options_remote,
						      remote_policy => $remote_policy,
						     },
	     },
	    );
    }

    # remote_policy should be 'ssh', 'scp', or something with docker exec

    # 'ssh' is used for regular ssh remote execution
    # 'scp' is used before remotely executing a local script

    if (not defined $remote_policy)
    {
	$remote_policy = 'ssh';
    }
    else
    {
	# remote_policy is 'scp'
    }

    if ($options_remote)
    {
	# if we need to skip remoting for this command?

	if (exists $options_remote->{skip}
	    and $command =~ /$options_remote->{skip}/)
	{
	    # use the localuser interaction role to prevent remoting

	    $interaction_role = "localuser\@localhost";
	}

	# if this is the local account

	elsif (exists $options_remote->{localuser}
	       and $options_remote->{localuser} eq 'yes')
	{
	    # use the localuser interaction role to prevent remoting

	    $interaction_role = "localuser\@localhost";
	}

	# else construct the remote role

	else
	{
	    # a hardcoded remote policy in the configuration options
	    # overrides any configuration options for ssh or scp

	    if (exists $options_remote->{remote_policy})
	    {
		$remote_policy = $options_remote->{remote_policy};

		$remote_prefix = $options_remote->{remote_policy};

		$interaction_role = $options_remote->{name};

	    }

	    # no hardcoded remote_policy, try something ssh / scp related

	    else
	    {
		if (exists $options_remote->{ssh_password})
		{
		    my $ssh_password = $options_remote->{ssh_password};

		    $remote_prefix .= "sshpass -p $ssh_password ";
		}

		if (exists $options_remote->{ssh_options})
		{
		    $ssh_options = "$options_remote->{ssh_options} ";
		}
		else
		{
		    $ssh_options = '';
		}

		if (exists $options_remote->{ssh_port})
		{
		    $ssh_options .= "-p $options_remote->{ssh_port} ";
		}

		if (exists $options_remote->{ssh_server})
		{
		    $interaction_role = "";

		    my $ssh_server = $options_remote->{ssh_server};

		    my $remote_role = exists $options_remote->{name} ? $options_remote->{name} : $ssh_server;

		    if (exists $options_remote->{ssh_user})
		    {
			my $ssh_user = $options_remote->{ssh_user};

			$interaction_role = "$ssh_user\@$remote_role";

			#t where is the scp use case?

			#t execute_shell_script_remote seems to be a use case?

			$remote_prefix .= "$remote_policy $ssh_options$ssh_user\@$ssh_server ";

			# either ssh syntax ...

			if ($remote_policy eq 'ssh')
			{
			    $interaction_role_with_policy_syntax = "$ssh_user\@$ssh_server";
			}

			# ... or scp syntax (the filename should be appended -- is this clumsy?)

			#t where is the scp use case?

			else
			{
			    $interaction_role_with_policy_syntax = "$ssh_user\@$ssh_server:";
			}
		    }
		    else
		    {
			$interaction_role = $remote_role;

			$remote_prefix .= "$remote_policy $ssh_options$ssh_server ";

			# $remote_prefix .= "$remote_policy $ssh_options";
		    }
		}
		else
		{
		    #t we could have a case here where we have a local user and no ssh_server

		    $interaction_role = "localuser\@localhost";
		}
	    }

	    if (defined $option_verbose and $option_verbose > 1)
	    {
		print STDERR "$global_program_name: *** result is $remote_prefix\n";
	    }
	}
    }

    # else no remoting information

    else
    {
	# track the interaction role

	$interaction_role = "localuser\@localhost";
    }

    $current_interaction_role = $interaction_role;

    # return result

    return
    {
     interaction_role => $interaction_role,
     interaction_role_with_policy_syntax => $interaction_role_with_policy_syntax,
     remote_prefix => $remote_prefix,
     ssh_options => $ssh_options,
    };
}


# prefix the given command with appropriate sudo options.

sub compute_sudo
{
    my $command = shift;

    my $option_sudo = shift;

    # default result: an empty string

    my $result = "";

    if ($option_sudo)
    {
	# default: sudo the command

	my $sudo_skip = 0;

	# default: all commands are sudo'd

	my $sudo_pattern = '.*';

	# default: no additional sudo options

	my $sudo_options = "";

	# if there are specific sudo options

	if (ref $option_sudo eq 'HASH')
	{
	    # get the specific sudo command pattern

	    $sudo_pattern
		= (exists $option_sudo->{pattern}
		   ? $option_sudo->{pattern}
		   : '.*');

	    # if we need to skip sudo information

	    if (exists $option_sudo->{skip}
		and $command =~ /$option_sudo->{skip}/)
	    {
		# remember to skip

		$sudo_skip = 1;
	    }

	    # remember the sudo options

	    if (exists $option_sudo->{options})
	    {
		$sudo_options = $option_sudo->{options};
	    }
	}

	# if the command matches the sudo pattern

	if ($command =~ /$sudo_pattern/)
	{
	    # construct the sudo command prefix

	    $result .= "sudo $sudo_options ";
	}
    }

    # return result

    return $result;
}


# prefix the command with appropriate timeout options

sub compute_timeout
{
    my $command = shift;

    my $option_timeout = shift;

    # default result: an empty string

    my $result = "";

    if ($option_timeout)
    {
	# if we need to skip timeout information

	if (exists $option_timeout->{skip}
	    and $command =~ /$option_timeout->{skip}/)
	{
	}

	# else construct the timeout command

	else
	{
	    if (exists $option_timeout->{sudo}
		and $option_timeout->{sudo} eq 1)
	    {
		$result .= "sudo ";
	    }

	    $result .= "timeout ";

	    if (exists $option_timeout->{options})
	    {
		$result .= "$option_timeout->{options} ";
	    }

	    if (not exists $option_timeout->{duration})
	    {
		die "*** Error: $global_program_name: the timeout option of '$command' does not have the mandatory duration specified";
	    }

	    $result .= "$option_timeout->{duration} ";
	}
    }

    # return result

    return $result;
}


sub execute_scheduled_command_option_dry_run
{
    my $scheduled_command = shift;

    my $command = $scheduled_command->{command};

    my $dry_run = $scheduled_command->{dry_run};

    my $executable_command = $scheduled_command->{executable_command};

    my $export_sh = $scheduled_command->{export_sh};

    my $interaction_role = $scheduled_command->{interaction_role};

    my $options = $scheduled_command->{options};

    if ($export_sh
	and exists $export_sh->{prefix})
    {
	my $dry_run_prefix = "$global_program_name: *** Running in dry_run mode, export prefix: '";

	print map { "$dry_run_prefix$_\n" } split "\n", $export_sh->{prefix};
    }

    #! when is this option a simple number?

    if ($dry_run =~ /^[0-9]+$/)
    {
	print "$global_program_name: *** Running in dry_run $dry_run mode, not executing: '$command'\n";
    }

    my $cd_command = _process_cd_command($executable_command);

    if ($cd_command)
    {
	my $cd_argument = $cd_command->{argument};

	my $exit_status = not chdir $cd_argument;
    }
    else
    {
    }
}


sub identify_interaction_roles
{
    my $command = shift;

    my $executable_command = shift;

    my $indent_delta = 40;

    # either we have already inserted a descriptive record for this interaction role

    if (exists $global_interaction_roles->{$current_interaction_role})
    {
    }

    # or we show the interaction diagram with all the interaction roles in the configuration.

    elsif ($option_interactions_module_all_roles)
    {
	my $target_servers = $global_technical_project_configuration->{target_servers};

	my $interaction_indent = 4;

	my $interaction_number = 1;

	# create a hash with a descriptive record for each interaction role

	$global_interaction_roles
	    = {
	       # map each human readable role to a descriptive record with appropriate indent

	       map
	       {
		   my $target = $_;

		   my $result
		       = {
			  $target => {
				      indent => $interaction_indent,
				      is_new_and_needs_header => 'yes',
				      name => $target,
				      number => $interaction_number,
				     },
			 };

		   $interaction_number += 1;

		   $interaction_indent += 24;

		   %$result;
	       }

	       # sort roles in a intuitive order

	       sort
	       {
		   # make sure that localhost always comes first

		   if ($a =~ /local/)
		   {
		       return -1;
		   }
		   elsif ($b =~ /local/)
		   {
		       return 1;
		   }
		   else
		   {
		       $a cmp $b;
		   }
	       }

	       # convert each target server to a human readable role

	       map
	       {
		   my $target_server_key = $_;

		   my $target_server = $target_servers->{$target_server_key};

		   my $result;

		   if (exists $target_server->{localuser}
		       and $target_server->{localuser} eq 'yes')
		   {
		       $result = "localuser\@localhost";
		   }
		   else
		   {
		       my $target_server_name = $target_server->{name} || $target_server->{ssh_server} || 'localhost';

		       my $target_user = $target_server->{ssh_user} || 'localuser';

		       $result = $target_user . '@' . $target_server_name;
		   }

		   $result;
	       }

	       # based on the target servers

	       keys %$target_servers,
	      };
    }

    # or we show only the interaction roles used in this workflow

    else
    {
	my $sorted_roles = [ keys %$global_interaction_roles, ];

	my $interaction_indent = 4 + scalar @$sorted_roles * $indent_delta;

	$global_interaction_roles->{$current_interaction_role}
	    = {
	       indent => $interaction_indent,
	       is_new_and_needs_header => 'yes',
	       name => $current_interaction_role,
	       number => (scalar @$sorted_roles) + 1,
	      };
    }
}


sub execute_option_interactions
{
    my $interaction_roles = shift;

    my $scheduled_command = shift;

    my $all = shift;

    my $command = $scheduled_command->{command};

    my $executable_command = $scheduled_command->{executable_command};

    my $interaction_role_arg = $scheduled_command->{interaction_role};

    # we must have a valid interaction role

    if (not defined $interaction_role_arg)
    {
	# use Data::Dumper;

	# print Dumper( { interaction_roles => $interaction_roles, }, );

	die "*** Error: $global_program_name: option_interactions cannot compute an indentation level without a valid interaction role (is '$interaction_role_arg')";
    }

    # if we are printing all interaction roles in the configuration

    if ($all)
    {
	# print the interaction header for all the configured roles

	foreach my $interaction_role_name (sort
					   {
					       $interaction_roles->{$a}->{number} <=> $interaction_roles->{$b}->{number};
					   }
					   keys %$interaction_roles)
	{
	    my $interaction_role = $interaction_roles->{$interaction_role_name};

	    if ($interaction_role->{is_new_and_needs_header} eq 'yes')
	    {
		_print_interaction_header($interaction_role);
	    }
	}
    }

    # if there is no interaction role

    if ($interaction_role_arg eq 'none')
    {
	# print the command without indentation

	print "$command\n";
    }

    # else with a defined interaction_role

    else
    {
	my $interaction_role = $interaction_roles->{$interaction_role_arg};

	# print the interaction_role header if this was not printed yet

	if ($interaction_role->{is_new_and_needs_header} eq 'yes')
	{
	    _print_interaction_header($interaction_role);
	}

	# print the command with indentation

	if ($executable_command !~ /^\s*$/)
	{
	    my $interaction_indent = $interaction_role->{indent};

	    my $indent = " " x $interaction_indent;

	    print "$indent'$executable_command'\n";
	}
    }
}


# see https://sequencediagram.org/

sub _print_sequence_diagram_header
{
    my $interaction_role = shift;

    my $interaction_role_name = $interaction_role->{name};

    print "participant $interaction_role_name\n\n";
}


sub _print_interaction_header
{
    my $interaction_role = shift;

    # calculate the indentation level

    my $interaction_role_name = $interaction_role->{name};

    my $interaction_indent = $global_interaction_roles->{$interaction_role_name}->{indent};

    # TODO: this is here to figure out whether the above use of $global_interaction_roles can be removed.

    if ($interaction_indent != $interaction_role->{indent})
    {
	print "$global_program_name: *** Warning: Inconsistent interaction_indent ($interaction_indent != $interaction_role->{indent})\n";
    }

    my $indent = " " x $interaction_indent;

    my $header = "${indent}ROLE: '$interaction_role_name'";

    # print the header

    print "$header\n\n";

    # remember that the header for this interaction_role has been printed

    $interaction_role->{is_new_and_needs_header} = $header;
}


sub _process_cd_command
{
    my $command = shift;

    my $result;

    if ($command =~ /^\s*chdir\s+(.*?)\s*(.*)$/)
    {
	$result
	    = {
	       type => 'chdir',
	       argument => $1,
	       rest_of_command_line => $2,
	      };
    }
    elsif ($command =~ /^\s*cd\s*$/)
    {
	$result
	    = {
	       type => 'cd',
	       argument => $1,
	      };
    }
    elsif ($command =~ /^\s*cd\s+([^\s]*)\s*(.*)$/)
    {
	$result
	    = {
	       type => 'cd',
	       argument => $1,
	       rest_of_command_line => $2,
	      };
    }

    return $result;
}


sub execute_option_export_sh
{
    my $interaction_roles = shift;

    my $scheduled_command = shift;

    my $executable_command = $scheduled_command->{executable_command};

    my $export_sh = $scheduled_command->{export_sh};

    my $export_sh_command = $scheduled_command->{export_sh_command};

    my $interaction_role = $scheduled_command->{interaction_role};

    if (not defined $global_exported_sh_file)
    {
	if (not defined $global_exported_sh_filename)
	{
	    $global_exported_sh_filename = $export_sh->{filename};
	}

	my $ok = open($global_exported_sh_file, ">", $global_exported_sh_filename);

	if (not $ok)
	{
	    die "*** Error: $global_program_name: cannot open $global_exported_sh_filename for writing ($!)";
	}

	print $global_exported_sh_file "#!/bin/sh\n";
	print $global_exported_sh_file "#\n";
	print $global_exported_sh_file "# script generated with $::global_program_name\n";
	print $global_exported_sh_file "#\n";
	print $global_exported_sh_file "# the command line to generate this script was:\n";
	print $global_exported_sh_file "#\n";
	print $global_exported_sh_file "# $global_command_line\n";
	print $global_exported_sh_file "#\n";

	if (not defined $option_export_remote)
	{
	    print $global_exported_sh_file "# --export-remote is not set, exporting all roles without a remote prefix\n";
	    print $global_exported_sh_file "#\n";
	}
	elsif ($option_export_remote eq 0)
	{
	    print $global_exported_sh_file "# --export-remote is 0, exporting all roles with the appriopriate remote prefix\n";
	    print $global_exported_sh_file "#\n";
	}
	else
	{
	    my $export_remote_interaction_roles
		= [
		   grep
		   {
		       my $interaction_role = $_;

		       $option_export_remote eq $interaction_roles->{$interaction_role}->{name}
			   or $option_export_remote eq $interaction_roles->{$interaction_role}->{number};
		   }
		   keys %$interaction_roles,
		  ];

	    my $export_remote_interaction_role = $export_remote_interaction_roles->[0] || 'undefined role';

	    print $global_exported_sh_file "# --export-remote is $option_export_remote, role: $export_remote_interaction_role\n";
	    print $global_exported_sh_file "#\n";
	}

	chmod 0755, $global_exported_sh_filename;
    }

    # 'cd' commands must both be exported and executed

    my $cd_command = _process_cd_command($export_sh_command);

    if ($cd_command)
    {
	my $cd_argument = $cd_command->{argument};

	my $exit_status = not chdir $cd_argument;
    }

    if ($export_sh_command =~ /^'/
	and $export_sh_command =~ /'$/)
    {
	$export_sh_command =~ s/^'//;
	$export_sh_command =~ s/'$//;
    }

    print "$global_program_name: *** Running in export_sh mode, exporting: '$export_sh_command'\n";

    if ((not defined $option_export_remote or $option_export_remote eq 0)
	or $option_export_remote eq $interaction_roles->{$interaction_role}->{name}
	or $option_export_remote eq $interaction_roles->{$interaction_role}->{number})
    {
	if ($option_export_verbose)
	{
	    print $global_exported_sh_file "echo '$export_sh_command'\n";
	}

	if (exists $export_sh->{prefix})
	{
	    print $global_exported_sh_file $export_sh->{prefix};
	}

	print $global_exported_sh_file "$export_sh_command\n";
    }
    else
    {
	print $global_exported_sh_file "$export_sh_command\n";
    }
}


# see https://stackoverflow.com/questions/571368/how-can-i-use-bash-syntax-in-perls-system

sub _system_bash
{
    my @args = ( "bash", "-c", shift );

    return system(@args);
}


sub execute_scheduled_command
{
    my $scheduled_command = shift;

    my $command = $scheduled_command->{command};

    my $dry_run = $scheduled_command->{dry_run};

    my $executable_command = $scheduled_command->{executable_command};

    my $interaction_role = $scheduled_command->{interaction_role};

    my $options = $scheduled_command->{options};

    my $exit_status;

    #! note the difference in processing and exit status for a local cd vs a remote cd

    my $cd_command = _process_cd_command($executable_command);

    if ($interaction_role eq 'localuser@localhost'
	and ($cd_command))
    {
	my $cd_argument = $cd_command->{argument};

	display_commented_command($command, $options);

	$exit_status = not chdir $cd_argument;
    }
    elsif ($dry_run)
    {
	#! this should never be called, if I am correct

	execute_scheduled_command_option_dry_run($scheduled_command);
    }
    else
    {
	my $export_output = $options->{export_output};

	my $export_times = $options->{export_times};

	if ($export_times)
	{
	    if (not defined $global_exported_times_file)
	    {
		if (not defined $global_exported_times_filename)
		{
		    $global_exported_times_filename = $export_times->{filename};
		}

		my $ok = open($global_exported_times_file, ">", $global_exported_times_filename);

		if (not $ok)
		{
		    die "*** Error: $global_program_name: cannot open $global_exported_times_filename for writing ($!)";
		}

		print $global_exported_times_file "#!/bin/sh\n";
		print $global_exported_times_file "#\n";
		print $global_exported_times_file "# script generated with $::global_program_name\n";
		print $global_exported_times_file "#\n";
		print $global_exported_times_file "# the command line to generate this script was:\n";
		print $global_exported_times_file "#\n";
		print $global_exported_times_file "# $global_command_line\n";
		print $global_exported_times_file "#\n";

		chmod 0644, $global_exported_times_filename;
	    }
	}

	# execute the command, collect start and end time

	use IPC::System::Simple qw(capture);

	my $start_time = time();

	my $output = "";

	my $command_is_empty = $executable_command =~ /^\s*$/ ? 'yes' : '';

	if (not $command_is_empty)
	{
	    if (not $export_output)
	    {
		display_commented_command($command, $options);

		my $use_bash = (exists $options->{use_bash}) && $options->{use_bash};

		if ($use_bash)
		{
		    # _system_bash('diff <(ls -l) <(ls -al)');

		    _system_bash($command);
		}
		else
		{
		    $exit_status = system "$command";
		}
	    }
	    else
	    {
		$output .= capture($command);

		$exit_status = $IPC::System::Simple::EXITVAL;
	    }
	}

	my $end_time = time();

	if ($export_times)
	{
	    print $global_exported_times_file "$0: *** Starting ('$command') at " . localtime($start_time) . "\n";

	    print $global_exported_times_file "$0: *** Ended    ('$command') at " . localtime($end_time) . "\n";

	    print $global_exported_times_file "$0: *** Duration (s): " . ($end_time - $start_time) . "\n";

	    print $global_exported_times_file "\n";
	}

	#! we could add the output to $scheduled_command->{output} or something similar

	if ($export_output)
	{
	    my $filename = generate_output_filename($global_target_command, $command);

	    my $output_file;

	    my $ok = open($output_file, ">", $filename);

	    if (not $ok)
	    {
		die "*** Error: $global_program_name: cannot open $filename for writing ($!)";
	    }

	    print $output_file "# $command\n#\n";

	    print $output_file $output;

	    close($output_file);
	}
	# else
	# {
	# 	print $output;
	# }
    }

    my $output_path = $options->{output_path};

#     my $exit_status = system "( $command ) >>$output_path 2>&1";

    if ($exit_status)
    {
	my $allow_fail = $options->{allow_fail};

	if ($allow_fail)
	{
# 	    system "echo >>$output_path 2>&1 failed with $exit_status: $command\n";

	    print "$global_program_name: *** Note: $command was allowed to fail (because $allow_fail) and has exit status $exit_status\n";
	}
	else
	{
	    die "$global_program_name: *** Fatal: $command failed with exit status $exit_status\n";
	}
    }

    # return the result of command execution

    return $exit_status;
}


sub schedule_real_command
{
    my $command = shift;

    my $executable_command = shift;

    my $interaction_role = shift;

    my $options = shift;

    my $dry_run = shift;

    my $export_sh = shift;

    my $export_sh_command = shift;

    my $scheduled_command
	= {
	   command => $command,
	   dry_run => $dry_run,
	   executable_command => $executable_command,
	   export_sh => $export_sh,
	   export_sh_command => $export_sh_command,
	   interaction_role => $interaction_role,
	   options => $options,
	  };

    push @$global_scheduled_commands, $scheduled_command;

    return '';
}


sub execute_all_scheduled_commands
{
    my $interaction_roles = shift;

    my $results = [];

    if ($option_dump_schedule)
    {
	use Data::Dumper;

	print Dumper( { scheduled_commands => $global_scheduled_commands, }, );
    }
    elsif ($option_dump_interaction_roles)
    {
	use Data::Dumper;

	print Dumper( { interaction_roles => $interaction_roles, }, );
    }
    elsif ($option_dump_module_interaction_roles)
    {
	print Dumper( { interaction_roles => $interaction_roles, }, );
    }
    else
    {
	foreach my $scheduled_command (@$global_scheduled_commands)
	{
	    # we are either in dry-run ...

	    if ($option_dry_run =~ /^[0-9]+$/)
	    {
		my $result = execute_scheduled_command_option_dry_run($scheduled_command);

		$scheduled_command->{result} = $result;

		push @$results, $result;
	    }

	    # ... or printing an interaction diagram

	    elsif ($option_interactions
		   or $option_interactions_all
		   or $option_interactions_module
		   or $option_interactions_module_all_roles)
	    {
		my $result = execute_option_interactions($interaction_roles, $scheduled_command, $option_interactions_module_all_roles || $option_interactions_all);

		$scheduled_command->{result} = $result;

		push @$results, $result;
	    }

	    # ... or exporting to an executable shell script ...

	    elsif (defined $option_export_sh)
	    {
		my $result = execute_option_export_sh($interaction_roles, $scheduled_command);

		$scheduled_command->{result} = $result;

		push @$results, $result;
	    }

	    # or real-time executing the scheduled command

	    else
	    {
		my $result = execute_scheduled_command($scheduled_command);

		$scheduled_command->{result} = $result;

		push @$results, $result;
	    }
	}
    }

    return $results;
}


sub execute_shell_command
{
    my $command = shift;

    my $options = shift;

    # keep a record of the command that will be executed

    my $executable_command = $command;

    $executable_command =~ s(^\s*#.*)()g;

    my $command_length = length $executable_command;

    # option preprocessing

    my $verbose = $options->{verbose} || $option_verbose;

    # the command to be exported defaults to the command given

    my $export_sh_command = defined $option_export_sh ? $command : undef;

    if (defined $verbose
	and $verbose =~ /^[0-9]+$/)
    {
	$verbose = "*** INFO: ";
    }

    # start of meta option and information processing

    # if exporting to a script for this command

    my $export_sh = $options->{export_sh};

    if (not defined $export_sh)
    {
	if (defined $option_export_sh)
	{
	    $export_sh = { filename => $option_export_sh, };
	}
    }
    else
    {
	# if globally exporting all commands

	if (defined $option_export_sh)
	{
	    $export_sh->{filename} = $option_export_sh;
	}
    }

    # if we are not exporting timing information specifically for this command

    my $export_times = $options->{export_times};

    if (not defined $export_times)
    {
	# are we globally exporting all timing information?

	if (defined $option_export_times)
	{
	    # configure the export_times option

	    $export_times = { filename => $option_export_times, };
	}
	else
	{
	    # we are not exporting any timing information
	}
    }

    # if we are exporting timing information specifically for this command

    else
    {
	# if globally exporting all timing information to the same file

	if (defined $option_export_times)
	{
	    # set the shared filename

	    $export_times->{filename} = $option_export_times;
	}
	else
	{
	    # use the filename set in the command specific options
	}
    }

    # start of peripheral option and command processing

    # if there is remoting information

    my $remote_and_interaction_role = compute_remote_and_interaction_role($command, $options->{remote});

    my $remote_prefix = $remote_and_interaction_role->{remote_prefix};

    # identify the interaction roles

    identify_interaction_roles($command, $executable_command);

    # now that we know the remote, apply the working directory for the remote on the command to be executed

    $command = working_directory_for_interaction_role_apply($current_interaction_role, $command);

    # prefix the command with appropriate sudo options

    my $sudo_prefix = compute_sudo($command, $options->{sudo});

    # prefix the command with appropriate timeout options

    my $timeout_prefix = compute_timeout($command, $options->{timeout});

    # if we need to rebuild according to the (optionally remote) build_tree

    my $needs_rebuild = build_tree_needs_rebuild($options->{build_tree}, { remote_prefix => $remote_prefix, }, );

    if (not $needs_rebuild)
    {
	return 0;
    }

    # force the execution of a change of the working directory to this process

    my $dry_run = $options->{dry_run} || $option_dry_run;

    $executable_command = working_directory_for_interaction_role_parse($executable_command, $dry_run, $current_interaction_role);

    #! note that the order of processing determines whether the options are locally or remotely applied

    # apply the sudo prefix, possibly remote

    ($command, $export_sh_command) = apply_sudo($sudo_prefix, $command, $option_export_sudo, $export_sh_command);

    # apply the remoting prefix, always local

    ($command, $export_sh_command) = apply_remote_record_exported_command($global_interaction_roles, $remote_prefix, $command, $option_export_remote, $export_sh_command);

    # apply the timeout prefix, always local

    ($command, $export_sh_command) = apply_timeout($timeout_prefix, $command, undef, $export_sh_command);

    # schedule the given command

    my $exit_code
	= schedule_real_command
	  (
	   $command,
	   $executable_command,
	   $current_interaction_role,
	   $options,
	   $dry_run,
	   $export_sh,
	   $export_sh_command,
	  );

    return '';
}


sub execute_shell_command_array
{
    my $commands = shift;

    my $options = shift;

    my $needs_rebuild = build_tree_needs_rebuild($options->{build_tree}, );

    if (not $needs_rebuild)
    {
	return 0;
    }

    my $first = 'true';

    foreach my $command (@$commands)
    {
	my $individual_options = { %$options, };

	if (not $first)
	{
	    delete $individual_options->{annotation};
	}

	execute_shell_command($command, $individual_options);

	$first = '';
    }

    return '';
}


sub execute_shell_command_schedule
{
    my $schedule = shift;

    my $command_array = $schedule->{commands};

    my $option_array = $schedule->{options};

    if (not defined $option_array)
    {
	$option_array = [ {}, ];
    }

    foreach my $options (@$option_array)
    {
	execute_shell_command_array($command_array, $options);
    }

    return '';
}


sub execute_shell_command_schedule_array
{
    my $schedule_array = shift;

    foreach my $schedule (@$schedule_array)
    {
	execute_shell_command_schedule($schedule);
    }

    return '';
}


# given a filename prefix and a 'command' generate an output filename
# for logging the output of the command.

our $output_filename_counter = 0;

sub generate_output_filename
{
    my $prefix = shift;

    my $command = shift;

    # a command three alphanumeric sequences that are used to
    # construct an abbreviation of the command for use in the
    # generated output filename

    #! I don't believe this has ever been fully tested, and I don't
    #! believe the regex is correct, it seems to miss anchors between
    #! the alphanumeric sequences.

    $command =~ /([a-z0-9]){0,5}(?:[a-z0-9]*)([a-z0-9]){0,5}(?:[a-z0-9]*)([a-z0-9]){0,5}(?:[a-z0-9]*)/i;

    my $one = defined $1 ? $1 : "one";

    my $two = defined $2 ? $2 : "two";

    my $three = defined $3 ? $3 : "three";

    # make sure the filename is unique to the given command

    $output_filename_counter++;

    # generate the filename

    my $result = "$prefix-$output_filename_counter-$one-$two-$three";

    # return result

    return $result;
}


package FieldProject;


our $status;


sub _configuration_export
{
    my $field_project_configuration = shift;

    my $technical_project_configuration = shift;

    my $configuration
	= {
	   # assume a simple integer incremental version number

	   configuration_version => 1,
	   field_project_configuration => $field_project_configuration,
	   technical_project_configuration => $technical_project_configuration,
	  };

    if (0)
    {
	use Data::Dumper;

	print Dumper( { configuration => $configuration } );
    }

    # When starting a new project, the field_project_configuration
    # does not have the sources_configuration_directory yet.
    #
    # It is ok not to create cache files in that scenario.
    #

    if (defined $global_field_project_configuration
	and exists $global_field_project_configuration->{sources_configuration_directory}
        and exists $field_project_configuration->{field_project_name})
    {
	my $cache_directory = Utilities::configuration_cache_directory();

	my $error = Utilities::create_directories($cache_directory);

	if (not $error)
	{
	    my $yaml_export_filename = "$cache_directory/configuration.yaml";

	    # errors such as permission errors are silently discarded to allow execution to continue

	    eval
	    {
		use YAML;

		# local $SIG{'__DIE__'};

		YAML::DumpFile($yaml_export_filename, $configuration);
	    };

	    eval
	    {
		local $SIG{'__DIE__'};

		require JSON;

		my $json_export_filename = "$cache_directory/configuration.json";

		my $json = JSON->new();

		#! allow code refs, they are converted to nulls

		$json->allow_unknown(1);

		$json->canonical(1);

		my $file = IO::File->new(">$json_export_filename");

		print $file $json->pretty->encode($configuration);

		$file->close();
	    };

	    eval
	    {
		local $SIG{'__DIE__'};

		# sudo apt install libtoml-perl

		require TOML;

		my $toml_export_filename = "$cache_directory/configuration.toml";

		my $file = IO::File->new(">$toml_export_filename");

		print $file TOML::to_toml($configuration);

		$file->close();
	    };
	}
	else
	{
	    die "$0: Error: cannot create cache directory $cache_directory";
	}
    }
}


#
# Initiallize field project related global configuration.
#
# This function reads the field project configuration with the project
# name, then reads the technical configuration.
#
# This function does not read the workflows.
#

sub _configuration_initialize
{
    # default result: empty

    my $result_field;

    my $result_technical;

    # set the global field project name and field configuration data
    # this is used to find configuration and command files

    $result_field = _init_get_field_project_configuration();

    # set the technical configuration

    if ($result_field)
    {
	$result_technical = _init_get_technical_configuration($result_field, $result_field->{field_project_name});
    }

    # add what is builtin

    {
	# add the builtin targets, they are always available and possibly override the configured targets of the same name

	$result_technical->{targets}->{builtin}->{description} = "the builtin target allows starting a new project and upgrading existing projects";

    }

    # return field project configuration data

    return ($result_field, $result_technical);
}


sub _init_do_eval_perl_file
{
    my $filename = shift;

    my $status;

    # check if the file exists

    if (not -r "$filename")
    {
	$status = "$global_program_name: *** Error: file '$filename' not found (because the file cannot be read)\n";

	return (undef, undef);
    }

    # make sure perl does not complain about '.' not in the INC path

    if ($filename =~ m(^[^/]))
    {
	$filename = "./$filename";
    }

    # read and execute the perl file

    my $result;

    # I removed the creation and use of the cache directory because
    # the field project initialization calls this sub which (for some
    # reason) breaks the code.

    # my $cache_directory = Utilities::commands_cache_directory();

    # my $error = Utilities::create_directories($cache_directory);

    # if (not $error)
    {
	# Inline::Python creates an _Inline directory in the current
	# directory.
	#
	# Make sure these _Inline directories are created in the cache
	# directory rather than in a user working directory.

	# use File::chdir;

	# local $CWD = "/tmp"; # $cache_directory;

	$result = do $filename;

	# do error processing: perl problems

	if ($@)
	{
	    $status = "$global_program_name: *** Error: no valid configuration file '$filename' (syntax error: $@)\n";
	}

	# do error processing: file problems.

	if (not defined $result
	    and $!)
	{
	    $status = "$global_program_name: *** Error: no configuration file '$filename' ($!)\n";
	}
    }
    # else
    # {
    # 	die "$0: Error: cannot create cache directory $cache_directory";
    # }

    # return configuration and status

    return ($result, $status);
}


my $python_inline_directory = "/tmp/workflow-automation";


package Command;

BEGIN
{
    # Inline::Python creates an _Inline directory in the current
    # directory.
    #
    # Make sure these _Inline directories are created in the cache
    # directory rather than in a user working directory.
    #
    # But the cache directory may not be available during program
    # startup, so we use a hopefully unique directory in /tmp.

    $python_inline_directory = "/tmp/workflow-automation/$<";

    `mkdir -p $python_inline_directory`;
}


use Inline Python => <<'END_PYTHON', directory => $python_inline_directory;
execute_command = None
execute_command_array = None
execute_command_schedule = None
execute_command_schedule_array = None

def assign_api_functions(exe_command, exe_command_array, exe_command_schedule, exe_command_schedule_array):
    global execute_command
    global execute_command_array
    global execute_command_schedule
    global execute_command_schedule_array
    execute_command = exe_command
    execute_command_array = exe_command_array
    execute_command_schedule = exe_command_schedule
    execute_command_schedule_array = exe_command_schedule_array

def run_python_code(code_str, filename):
    import traceback
    import ast

    try:
        print(f"Compiling for {filename}")
        compiled = compile(code_str, filename, 'exec')
        exec(compiled, {'__file__': filename})
    except Exception:
        traceback.print_exc()

def pure_python_python_command_hard_coded(argv):
    command = "echo 'python_command from bash (1)'"
    execute_command(command)
    command_array = [
        "echo 'python_command from bash (2)'",
        "echo 'python_command from bash (3)'"
    ]
    execute_command_array(command_array)

END_PYTHON

assign_api_functions(\\&Command::execute_shell_command, \\&Command::execute_shell_command_array, \\&Command::execute_command_schedule, \\&Command::execute_command_schedule_array);


my $global_read_python_files = {};

my $global_api_bound = '';


package Command;

sub _python_print_to_stdout
{
    my $argument = shift;

    print $argument;
}


sub _python_print_to_stderr
{
    my $argument = shift;

    print STDERR $argument;
}


package FieldProject;

sub _init_do_eval_python_file
{
    my $input_pathname = shift;

    my ($result, $status);

    my $debug_inline_python = 0;

    if (exists $global_read_python_files->{$input_pathname})
    {
	my $result_and_status = $global_read_python_files->{$input_pathname};

	return ($result_and_status->{result}, $result_and_status->{status});
    }

    # check if the file exists

    if (not -r "$input_pathname")
    {
	$status = "$global_program_name: *** Error: file '$input_pathname' not found (because the file cannot be read)\n";

	return (undef, $status);
    }

    if ($debug_inline_python)
    {
	print STDERR "_init_do_eval_python_file($input_pathname)\n";
    }

    # read the python file

    my $python_code
	= do {
	    open my $fh, '<', $input_pathname;
	    local $/;
	    <$fh>;
	};

    $result = Command::run_python_code($python_code, $input_pathname);

    $global_read_python_files->{$input_pathname}
	= {
	   result => $result,
	   status => $status,
	  };

    return ($result, $status);
}


package FieldProject;

sub _init_do_eval_python_file_old
{
    my $input_pathname = shift;

    my ($result, $status);

    my $debug_python_inlining = ''; # 'yes';

    if ($debug_python_inlining)
    {
	require Carp;

	print STDERR "\n$0: _init_do_eval_python_file($input_pathname)\n\n";
	print STDERR Carp::longmess(@_);
    }

    if (exists $global_read_python_files->{$input_pathname})
    {
	my $result_and_status = $global_read_python_files->{$input_pathname};

	return ($result_and_status->{result}, $result_and_status->{status});
    }

    # check if the file exists

    if (not -r "$input_pathname")
    {
	$status = "$global_program_name: *** Error: file '$input_pathname' not found (because the file cannot be read)\n";

	return (undef, $status);
    }

    my $commands_cache_directory = Utilities::commands_cache_directory();

    my $configuration_cache_directory = Utilities::configuration_cache_directory();

    my $error = Utilities::create_directories($commands_cache_directory);

    #t Using py_bind_func() may resolve these warnings:
    #t
    #t Subroutine Command::_load_json_configuration_file redefined at (eval 44) line 1.
    #t Subroutine Command::assign_api_functions redefined at (eval 45) line 1.
    #t Subroutine Command::more_python_python_command redefined at (eval 46) line 1.
    #t Subroutine Command::more_python_python_command_completions redefined at (eval 47) line 1.
    #t Subroutine Command::more_python_python_command_help redefined at (eval 48) line 1.

    if (not $error)
    {
	# read the python file

	my $python_code
	    = do {
		open my $fh, '<', $input_pathname;
		local $/;
		<$fh>;
	    };

	my $sources_configuration_directory = $global_field_project_configuration->{sources_configuration_directory};
	# insert the code into a perl command file in the cache directory that binds it to the workflow core.

	# makes the execute_command and execute_command_array functions available from python.
	# reads the configuration in json into a global variable to make it available from python.

	my $api_bind_code = "

import json

global_technical_project_configuration_path = '$configuration_cache_directory/configuration.json'

global_technical_project_configuration = None

def _load_json_configuration_file(filepath):
    global global_technical_project_configuration
    with open(filepath, 'r', encoding='utf-8') as f:
        global_technical_project_configuration = json.load(f)
    # print_to_stdout('Configuration loaded')
    # print_to_stderr('Configuration loaded')

_load_json_configuration_file(global_technical_project_configuration_path)


execute_command = None
execute_command_array = None
execute_command_schedule = None
execute_command_schedule_array = None
print_to_stdout = None
print_to_stderr = None

def assign_api_functions(exe_command, exe_command_array, exe_command_schedule, exe_command_schedule_array, ref_print_to_stdout, ref_print_to_stderr):
    global execute_command
    global execute_command_array
    global execute_command_schedule
    global execute_command_schedule_array
    global print_to_stdout
    global print_to_stderr
    execute_command = exe_command
    execute_command_array = exe_command_array
    execute_command_schedule = exe_command_schedule
    execute_command_schedule_array = exe_command_schedule_array
    print_to_stdout = ref_print_to_stdout
    print_to_stderr = ref_print_to_stderr

";

	my $api_bind_call_code = "
assign_api_functions(\\&Command::execute_shell_command, \\&Command::execute_shell_command_array, \\&Command::execute_command_schedule, \\&Command::execute_command_schedule_array, \\&_python_print_to_stdout, \\&_python_print_to_stderr);

";
	my $commands_template_code
	    = "#!/usr/bin/perl -w

package Command;

use strict;

use warnings;

# set your PYTHONPATH to include the appropriate directories if this is needed
#
# export PYTHONPATH=\$HOME/projects/my-python-modules-directory

BEGIN
{
	if (not exists \$ENV{PYTHONPATH})
	{
		\$ENV{PYTHONPATH} = \"$commands_cache_directory\";
	}
}

use Inline Python => <<'PYTHON';

___API_BIND_CODE___

___YOUR_PYTHON_CODE_HERE___
PYTHON


___API_BIND_CALL_CODE___

# return success

1;


";

	if (not $global_api_bound)
	{
	    if ($debug_python_inlining)
	    {
		print STDERR "_init_do_eval_python_file: Binding APIs\n";
	    }

	    $commands_template_code =~ s(___API_BIND_CODE___)($api_bind_code);

	    $commands_template_code =~ s(___API_BIND_CALL_CODE___)($api_bind_call_code);

	    $global_api_bound = 'yes';
	}
	else
	{
	    if ($debug_python_inlining)
	    {
		print STDERR "_init_do_eval_python_file: Removing API markerss\n";
	    }

	    $commands_template_code =~ s(___API_BIND_CODE___)();

	    $commands_template_code =~ s(___API_BIND_CALL_CODE___)();
	}

	$commands_template_code =~ s(___YOUR_PYTHON_CODE_HERE___)($python_code);

	$input_pathname =~ m(.*/(.*));

	my $input_filename = $1;

	my $output_filename = "$commands_cache_directory/$input_filename";

	if (0)
	{
	    print STDERR "$0: For $input_pathname: creating cache file $output_filename\n";
	}

	{
	    open my $fh, '>', $output_filename;

	    print $fh $commands_template_code;

	    close $fh;
	}

	# Inline::Python creates an _Inline directory in the current
	# directory.
	#
	# Make sure these _Inline directories are created in the cache
	# directory rather than in a user working directory.
	#
	# But the cache directory may not be available during program
	# startup, so we use a hopefully unique directory in /tmp.

	# my $python_inline_directory = "/tmp/workflow-python-inline/$$";

	# `mkdir -p $python_inline_directory`;

	my $python_inline_directory = $commands_cache_directory;

	use File::chdir;

	local $CWD = $python_inline_directory; # $commands_cache_directory;

	# read the perl command file

	($result, $status) = FieldProject::_init_do_eval_perl_file($output_filename);
    }
    else
    {
	die "$0: Error: cannot create the commands cache directory $commands_cache_directory";
    }

    # return configuration and status

    $global_read_python_files->{$input_pathname}
	= {
	   result => $result,
	   status => $status,
	  };

    return ($result, $status);
}


sub _init_do_eval_yaml_command_file
{
    my $filename = shift;

    my $status;

    # check if the file exists

    if (not -r "$filename")
    {
	$status = "$global_program_name: *** Error: file '$filename' cannot be read\n";

	return undef;
    }

    print "using $filename\n";

    # read the yaml file

    use YAML;

    my $result = YAML::LoadFile($filename);

    #t this needs more work

    # do error processing: perl problems

    if ($@)
    {
	$status = "$global_program_name: *** Error: no valid configuration file '$filename' found (syntax error: $@)\n";
    }

    # do error processing: file problems.

    if (not defined $result
	and $!)
    {
	$status = "$global_program_name: *** Error: no configuration file '$filename' found ($!)\n";
    }

    # return configuration and status

    return ($result, $status);
}


sub _init_get_field_project_configuration
{
    # set default result: undefined

    my $result;

    # if we have an installed executed filename with a prefixed directory

    if ($0 =~ m((.*)/(.*)-workflow))
    {
	# try to determine the field_project_name from the installed executable name

	my $field_project_name = $2;

	# try to determine the configuration directory from the installed executable name

	my $search_path_workflow_executable_directory = $1;

	my $search_path_workflow_executable_filename = "$1/$2-configuration";

	if (-r $search_path_workflow_executable_filename)
	{
	    # resolve the symbolic link from ~/bin/* to its absolute path it refers to

	    use Cwd 'abs_path';

	    my $sources_configuration_filename = abs_path($search_path_workflow_executable_filename);

	    $sources_configuration_filename =~ m((.*)/(.*)-configuration);

	    my $sources_configuration_directory = $1;

	    my $sources_configuration_data_directory = "$sources_configuration_directory/$field_project_name-commands-data";

	    # set result

	    $result
		= {
		   configuration_origin => "dynamically_generated from the executable script name",
		   field_project_name => $field_project_name,
		   search_path_workflow_executable_directory => $search_path_workflow_executable_directory,
		   # search_path_workflow_executable_filename => $search_path_workflow_executable_filename,
		   sources_configuration_directory => $sources_configuration_directory,
		   sources_configuration_filename => $sources_configuration_filename,
		   sources_configuration_data_directory => $sources_configuration_data_directory,
		  };
	}
	else
	{
	    $status = "$global_program_name: *** Error: '$search_path_workflow_executable_filename cannot be read\n";

	    return undef;
	}
    }

    # else we don't have an installed executable filename or prefix directory

    else
    {
	# try to determine the field project name for a field_project_configuration file

	my $field_project_configuration_filename = "workflow-project.pl";

	# loop over the possible field project configuration directories

	my $technical_project_configuration_directories
	    = [
	       ".",
	       $global_program_rel_directory,
	       $global_program_abs_directory,
	      ];

	my $search_path_workflow_executable_directory;

	foreach my $tmp (@$technical_project_configuration_directories)
	{
	    # if a technical_project_configuration file can be found

	    if (-d $tmp
		and -e "$tmp/$field_project_configuration_filename"
		and -r "$tmp/$field_project_configuration_filename")
	    {
		# this is the one we use

		$search_path_workflow_executable_directory = $tmp;

		last;
	    }
	}

	# if the search_path_workflow_executable_directory was found

	if (defined $search_path_workflow_executable_directory)
	{
	    # read the field project configuration

	    my ($field_project_configuration, $eval_status) = _init_do_eval_perl_file("$search_path_workflow_executable_directory/$field_project_configuration_filename");

	    my $field_project_name = $field_project_configuration->{field_project_name};

	    $status = $eval_status;

	    # resolve the symbolic link from ~/bin/* to its absolute path it refers to

	    use Cwd 'abs_path';

	    my $sources_configuration_filename = abs_path($field_project_configuration_filename) ;

	    $sources_configuration_filename =~ m((.*)/$field_project_configuration_filename);

	    my $sources_configuration_directory = $1;

	    my $sources_configuration_data_directory = "$sources_configuration_directory/$field_project_name-commands-data";

	    # set result: field project name, it is used to find configuration and command files

	    $result
		= {
		   %$field_project_configuration,
		   configuration_origin => "workflow on the command line",
		   field_project_configuration_filename => $field_project_configuration_filename,
		   from_directory => $search_path_workflow_executable_directory,
		   search_path_workflow_executable_directory => $search_path_workflow_executable_directory,
		   sources_configuration_directory => $sources_configuration_directory,
		   sources_configuration_filename => $sources_configuration_filename,
		   sources_configuration_data_directory => $sources_configuration_data_directory,
		  };
	}

	# no field_project_configuration_directory was found

	else
	{
	    if ($0 eq '/usr/local/bin/workflow')
	    {
		#! this is ok, the user is maybe starting a new project or so.
	    }
	    else
	    {
		$status = "$global_program_name: *** Error: no valid configuration file '$field_project_configuration_filename' found in any of the configuration directories ('.', 'global_program_rel_directory' or '$global_program_abs_directory')\n";

		return undef;
	    }
	}
    }

    # return result

    return $result;
}


sub _init_get_technical_configuration
{
    my $field_project_configuration = shift;

    my $project_name = shift;

    my $technical_project_configuration_directories
	= [
	   ".",
	   $global_program_rel_directory,
	   $global_program_abs_directory,
	  ];

    my $search_path_workflow_executable_directory;

    foreach my $tmp (@$technical_project_configuration_directories)
    {
	# if a technical_project_configuration file can be found

	if (-d $tmp
	    and -e "$tmp/$project_name-configuration"
	    and -r "$tmp/$project_name-configuration")
	{
	    # this is the one we use

	    $search_path_workflow_executable_directory = $tmp;

	    last;
	}
    }

    if (not defined $search_path_workflow_executable_directory)
    {
	$status = "$global_program_name: *** Error: no configuration file '$project_name-configuration' found in any of the searched directories (would prefer this to be in $global_program_rel_directory)\n";

	return undef;
    }

    my $technical_configuration_filename = "$search_path_workflow_executable_directory/$project_name-configuration";

    # to ensure that the relative filenames in the configuration work,
    # record the current workding directory
    # cd to the configuration directory
    # read the file using _init_do_eval_perl_file()
    # cd back to the previous directory

    my ($technical_configuration, $eval_status);

    {
	use File::chdir;

	my $sources_configuration_directory = $field_project_configuration->{sources_configuration_directory};

	local $CWD = $sources_configuration_directory;

	($technical_configuration, $eval_status) = _init_do_eval_perl_file($technical_configuration_filename);
    }

    $status = $eval_status;

    return $technical_configuration;
}


our $global_main_project_name = "ssp";


package Utilities;


#
# The commands_cache_directory is a directory where the workflow
# engine caches dynamically generated scripts before their execution.
# Each run of the workflow engine, the commands cache is
# refreshed.
#

sub commands_cache_directory
{
    my $commands_data_directory = commands_data_directory();

    my $cache_directory = "$commands_data_directory/cache";

    return $cache_directory;
}


sub commands_data_directory
{
    my $sources_configuration_directory = $global_field_project_configuration->{sources_configuration_directory};

    my $field_project_name = $global_field_project_configuration->{field_project_name};

    my $commands_data_directory = "$sources_configuration_directory/$field_project_name-commands-data";

    return $commands_data_directory;
}


#
# The configuration_cache_directory is a directory where the workflow
# engine caches a read-only copy of the configuration in yaml, json
# and toml formats.  This configuration cache is used by client
# scripts.  Each run of the workflow engine, the configuration cache
# is refreshed.
#

sub configuration_cache_directory
{
    my $configuration_data_directory = configuration_data_directory();

    my $cache_directory = "$configuration_data_directory/cache";

    return $cache_directory;
}


sub configuration_data_directory
{
    my $sources_configuration_directory = $global_field_project_configuration->{sources_configuration_directory};

    my $field_project_name = $global_field_project_configuration->{field_project_name};

    my $configuration_data_directory = "$sources_configuration_directory/$field_project_name-configuration-data";

    return $configuration_data_directory;
}


sub create_directories
{
    my $directory = shift;

    my $result;

    use File::Path qw/make_path/;

    my $error;

    make_path($directory, { error => \$error, }, );

    if ($error && @$error)
    {
	for my $diagnosis (@$error)
	{
	    my ($path, $message) = %$diagnosis;

	    $result = "error creating $path: $message";

	    if ($path eq '')
	    {
		# print "general error: $message\n";
	    }
	    else
	    {
		# print "problem unlinking $file: $message\n";
	    }
	}
    }
    else
    {
	# print "No error encountered\n";
    }

    return $result;
}


sub read_directory
{
    my $directory = shift;

    my $result;

    if (opendir(my $dh, $directory))
    {
	$result
	    = [
	       grep
	       {
		   # skip . and ..

		   $_ ne '.' && $_ ne '..'
	       }
	       readdir($dh),
	      ];

	closedir($dh);
    }
    else
    {
	$result = \ "error opening directory ($directory)";
    }

    return $result;
}


package main;


sub bash_completion
{
    my $command_line = $option_bash_completion || "";

    my $arguments = [ split ' ', $command_line, ];

    #! this is sloppy: option_target is first set through a shift @ARGV and then fetched here.

    my $comp_cword = $option_target;

    #t $comp_point is not used yet, I believe it is an index into the current command line

    #t The index of the current cursor position relative to the
    #t beginning of the current command.  If the current cursor position
    #t is at the end of the current command, the value of this variable
    #t is equal to ${#COMP_LINE}

    my $comp_point = $ARGV[0];

    my $command_line_word = $arguments->[$comp_cword];

    my $command = shift @$arguments;

    my $result;

    # either generate completions for the configuration browser ...

    if ($command =~ /configuration/)
    {
	$result = bash_completion_generate($command, $arguments, $global_technical_project_configuration, $comp_cword);

	# add the depth level options that the configuration browser understands

	push @$result, '--', '-1', '-2', '-3';
    }

    # ... or generate completions for the workflow engine with or without configuration

    elsif ($command =~ /workflow/)
    {
	if (defined $command_line_word
	    and $command_line_word =~ /^-/)
	{
	    $result = bash_completion_generate_options();

	    #! why did I do this?

	    unshift @$result, 'aa', 'bb';
	}
	else
	{
	    # COMP_CWORD	An index into ${COMP_WORDS} of the word containing the current cursor position.

	    # remove the options from the argument list

	    my $position_2_type
		= {
		   0 => 'target',
		   1 => 'command',
		   2 => 'subcommand',
		  };

	    my $position = 0;

	    my $target_command = [];

	    my $position_flag = 0;

	    my $position_flags = [];

	    my $debug_completion = 0;

	    if ($comp_cword > 0)
	    {
		#! we shifted one from $arguments so $comp_cword - 1 is the last entry

		foreach my $index (0 .. $comp_cword - 1)
		{
		    #! arguments->[$index] can be undef here when the
		    #! cursor is at the first position of the next
		    #! word to be completed, resulting in all
		    #! completions still possible.

		    if ($debug_completion > 2)
		    {
			print STDERR Dumper(
					    {
					     barguments => $arguments,
					     bcomp_cword => $comp_cword,
					     bindex => $index,
					     bnot_exists_arguments_index => (not exists $arguments->[$index]),
					     brange => [ ( 0 .. $comp_cword - 1) ],
					    },
					   );
		    }

		    if (exists $arguments->[$index])
		    {
			push @$position_flags, 'exists';

			if ($arguments->[$index] =~ /^--/)
			{
			}
			else
			{
			    $target_command->[$position] = $arguments->[$index];

			    $position++;
			}
		    }
		    else
		    {
			push @$position_flags, '';
		    }
		}

		if ($debug_completion > 2)
		{
		    print STDERR Dumper(
					{
					 arguments => $arguments,
					 comp_cword => $comp_cword,
					 not_exists_arguments_index => (not exists $arguments->[$comp_cword - 1]),
					 range => [ ( 0 .. $comp_cword - 1) ],
					},
				       );
		}

		# if the command line is at the start a new word to be
		# completed, flag this

		if (not exists $arguments->[$comp_cword - 1])
		{
		    $position_flag = 1;

		    $position++;
		}
	    }

# 	    my $internal_completion = ($comp_cword < 3) or 1;
	    my $internal_completion = ($position < 3);

	    if ($internal_completion)
	    {
		my $internal_commands = generate_command_hash_with_structure();

		$result = bash_completion_generate($command, $arguments, $internal_commands, $comp_cword);

		# make sure the user gets a hint that options are also possible

		push @$result, '--a', '--b';

		if ($debug_completion)
		{
		    print STDERR Dumper(
					{
					 command_arguments => {
							       arguments => $arguments,
							       command => $command,
							       command_line => $command_line,
							       command_line_word => $command_line_word,
							       target_command => $target_command,
							      },
					 position => {
						      comp_cword => $comp_cword,
						      position => $position,
						      position_flag => $position_flag,
						      position_flags => $position_flags,
						     },
					 status => {
						    internal_completion => $internal_completion,
						    result => $result,
						   },
					},
				       );
		}
	    }
	    else
	    {
		# my $completion_sub = "Command::" . join '_', (@$target_command, 'completion');

		my $completion_sub = "Command::$target_command->[0]_$target_command->[1]_completions";

		my $command_hash = generate_command_hash_typed('with completion subs');

		# have the command generate the data structure that lists the completions

		my $external_commands
		    = {
		       "<no_completions_have_been_defined,_please_implement_the_sub_with_name_\"$completion_sub\">" => 1,
		       "_no_completions_have_been_defined,_please_implement_the_sub_with_name_\"$completion_sub\"_" => 1,
		      };

		if (exists $command_hash->{"$target_command->[0] $target_command->[1]_completions"})
		{
		    no strict "refs";

		    my $command_name = $completion_sub;

		    $command_name =~ s(^Command::)();
		    $command_name =~ s(^([a-z0-9]+?)_)($1 );
		    $command_name =~ s(_completions$)();

		    $external_commands = &$completion_sub($command_name, $arguments);
		}

		$result = bash_completion_generate($command, $arguments, $external_commands, $comp_cword);

		if ($debug_completion)
		{
		    print STDERR Dumper(
					{
					 command_arguments => {
							       arguments => $arguments,
							       command => $command,
							       command_line => $command_line,
							       command_line_word => $command_line_word,
							       target_command => $target_command,
							      },
					 position => {
						      comp_cword => $comp_cword,
						      position => $position,
						      position_flag => $position_flag,
						     },
					 status => {
						    internal_completion => $internal_completion,
						    result => $result,
						   },
					},
				       );

		    print STDERR Dumper(
					{
					 command_hash => $command_hash,
					 external_commands => $external_commands,
					 result => $result,
					},
				       );
		}

	    }
	}
    }

    # make sure we have a reproducible result by sorting it

    $result = [ sort @$result, ];

    print join " ", @$result;

    exit 0;
}


sub bash_completion_generate
{
    my $command = shift;

    use Clone qw(clone);

    my $arguments = clone(shift);

    my $configuration_or_commands = shift;

    my $comp_cword = shift;

    # search the given arguments in the configuration by following its path in the hash

    while (@$arguments and $comp_cword > 0)
    {
	if (ref $configuration_or_commands eq 'HASH')
	{
	    my $argument = shift @$arguments;

	    $comp_cword--;

	    if (exists $configuration_or_commands->{$argument})
	    {
		$configuration_or_commands = $configuration_or_commands->{$argument};
	    }
	}
	elsif (ref $configuration_or_commands eq 'ARRAY')
	{
	    last;
	}
	else
	{
	    last;
	}
    }

    # return the result depending on its type

    if (ref $configuration_or_commands eq 'HASH')
    {
	return [ keys %$configuration_or_commands, ];
    }
    elsif (ref $configuration_or_commands eq 'ARRAY')
    {
	return [ @$configuration_or_commands, ];
    }
    else
    {
	return [ $configuration_or_commands, ];
    }
}


sub bash_completion_generate_options
{
    my $result = [
		  qw(
			--bash-completion
			--branch
			--build-server
			--built-image-directory
			--command
			--dry-run
			--dump-all-interaction-roles
			--dump-interaction-roles
			--dump-module-interaction-roles
			--dump-schedule
			--export-remote
			--export-sh
			--export-sudo
			--export-times
			--export-verbose
			--force-rebuild
			--forward-destination
			--forward-source
			--help
			--help-build-servers
			--help-commands
			--help-field-project-name
			--help-module
			--help-module-all
			--help-options
			--help-packages
			--help-projects
			--help-targets
			--incremental
			--interactions
			--interactions-all
			--interactions-module
			--interactions-module-all-roles
			--packages
			--ssh-port
			--ssh-server
			--ssh-user
			--target
			--tftp-directory
			--verbose
		   )
		 ];

    return $result;
}


# generate a hash mapping targets and subroutine names to their full names.

sub generate_command_hash_with_structure
{
    my $with_feature_subs = shift;

    my $commands = generate_command_list($with_feature_subs);

    # set default result

    my $result = {};

    # loop over all the found targets and commands

    foreach my $command (@$commands)
    {
	# extract the target and the subroutine from the generated string

	$command =~ m(([^ ]+) ([^ ]+))g;

	my $target = $1;

	my $subroutine = $2;

	# insert them into the result

	$result->{$target}->{$subroutine} = $command;
    }

    # return result

    return $result;
}


sub generate_command_hash_typed
{
    my $with_feature_subs = shift;

    my $result = {};

    my $commands_subs = generate_command_hash_subs("Command::", $with_feature_subs);

    $result
	= {
	   %$result,
	   %$commands_subs,
	  };

    my $commands_shell = generate_command_hash_shell($with_feature_subs);

    $result
	= {
	   %$result,
	   %$commands_shell,
	  };

    my $commands_yaml = generate_command_hash_yaml($with_feature_subs);

    $result
	= {
	   %$result,
	   %$commands_yaml,
	  };

    return $result;
}


sub generate_command_list
{
    my $with_feature_subs = shift;

    my $command_hash = generate_command_hash_typed($with_feature_subs);

    my $result = [ keys %$command_hash, ];

    return $result;
}


sub generate_command_hash_data_directory
{
    my $type = shift;

    my $with_feature_subs = shift;

    my $result = {};

    # use Carp;

    # carp "HERE";

    # use Data::Dumper; print Dumper( { global_field_project_configuration => $global_field_project_configuration, } );

    if (defined $global_field_project_configuration)
    {
	my $commands_data_directory = $global_field_project_configuration->{sources_configuration_data_directory};

	$result
	    = {
	       map
	       {
		   $_ => $type,
	       }
	       sort
	       map
	       {
		   s($commands_data_directory/)();

		   s((.*)/(.*).$type)($1 $2);

		   $_
	       }
	       map
	       {
		   chomp; $_;
	       }
	       `ls 2>/dev/null $commands_data_directory/*/*.$type`,
	      };
    }

    return $result;
}


sub generate_command_hash_shell
{
    my $with_feature_subs = shift;

    my $result = generate_command_hash_data_directory('sh', $with_feature_subs);

    return $result;
}


sub generate_command_hash_yaml
{
    my $with_feature_subs = shift;

    my $result = generate_command_hash_data_directory('yml', $with_feature_subs);

    return $result;
}


#
# generate all the subs in the given package and return them as a hash
# with the values defining their type.
#
# with_feature_subs is either "with help subs" or "with completion
# subs".
#

sub generate_command_hash_subs
{
    my $package_name = shift;

    my $with_feature_subs = shift;

    # generate a list of the available command subroutines

    my $subroutines = [
		       sort

		       # select only code references

		       grep
		       {
		       	   defined &{"$_"};
		       }

		       # clarify that they belong to the Command:: package

		       map
		       {
			   "$package_name$_";
		       }

		       # select only code references

		       # grep
		       # {
		       # 	   ref {Command::}->{$_} eq 'CODE';
		       # }
		       # grep
		       # {
		       # 	   not defined &$_;
		       # }
		       keys %Command::,
		      ];

    # rework, select and sort these commands

    my $targets = $global_technical_project_configuration->{targets};

    if (defined $option_verbose
	and $option_verbose > 2)
    {
	use Data::Dumper;

	print STDERR Dumper(
			    {
			     defined_found_subroutines => $subroutines,
			     global_technical_project_configuration_targets => $targets,
			    },
			   );
    }

    my $commands = {
		    map
		    {
			$_ => 'sub';
		    }

		    # alphabatically group and make sense

		    sort

		    # remove internal commands and commands that don't belong to a target

		    grep
		    {
			$_ !~ /Command::/;
		    }

		    # remove Command:: package name and split target name from operation name on that target

		    map
		    {
			foreach my $target (sort keys %$targets)
			{
			    $target =~ s/-/_/g;

			    s/Command::${target}_(.*)/${target} $1/g;
			}

			$_;
		    }

		    # no help subroutines if so asked

		    grep
		    {
			my $sub_name = $_;

			my $is_help = ($sub_name =~ m(_help$));

			my $is_completion = ($sub_name =~ m(_completions$));

			my $is_none = !$is_help && !$is_completion;

			my $allow_none = 'always';

			my $allow_help = defined $with_feature_subs && $with_feature_subs eq 'with help subs';

			my $allow_completion = defined $with_feature_subs && $with_feature_subs eq 'with completion subs';

			my $result;

			$result
			    = ($is_none && $allow_none
			       || $is_help && $allow_help
			       || $is_completion && $allow_completion);

			$result;
		    }

		    # all internal commands

		    sort @$subroutines,
		   };

    if (defined $option_verbose
	and $option_verbose > 2)
    {
	use Data::Dumper;

	print Dumper( { all_targets => $targets, }, );
    }

    return $commands;
}


sub main
{
    # this is YAML related, see for instance https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=707229

    $INC{'Mo/builder.pm'} = 1;
    $INC{'Mo/default.pm'} = 1;

    # initiallize field project related global configuration

    ($global_field_project_configuration, $global_technical_project_configuration) = FieldProject::_configuration_initialize();

    # make the configuration available to external programs

    FieldProject::_configuration_export($global_field_project_configuration, $global_technical_project_configuration);

    if ($global_field_project_configuration
	and $global_technical_project_configuration)
    {
	# initialize the command module

	Command::_workflow_commands_initialize();

	# parse the local.mk packages to update the dynamically generated help pages

	$global_overriden_packages = buildroot_parse_packages_directories();
    }

    # parse command line

    parse_command_line();

    if (defined $option_verbose
	and $option_verbose > 2)
    {
	use Data::Dumper;

	print STDERR Dumper(
			    {
			     global_field_project_configuration => $global_field_project_configuration,
# 			     global_overriden_packages => $global_overriden_packages,
			     global_technical_project_configuration => $global_technical_project_configuration,
			    },
			   );
    }

    # perform bash completion logic, this will exit the script

    if ($option_bash_completion)
    {
	bash_completion();

	#! bash_completion() never returns
    }

    # parse package directories

    #t this will overwrite the code in the build directories with custom code for packages listed in local.mk.
    #t should set a flag whether a build will be required and honor the flag in preprocessing stages.

    buildroot_process_packages_directories($global_overriden_packages);

    # figure out the target and the command

    my $requested_target = (defined $option_interactions_all ? '.*' : $option_target);

    my $command = $option_commands->[0] || "";

    # # we allow finger laziness: the shift key is not necessary for the underscore

    # $requested_target =~ s/-/_/g;
    # $command =~ s/-/_/g;

    $global_target_command = "$requested_target-$command";

    # given the requested target and the command generate a useful filename for exporting commands to a shell script

    if (defined $option_export_sh)
    {
	if ($option_export_sh eq 0)
	{
	    $option_export_sh = "/tmp/$global_target_command.sh";
	}
	elsif ($option_export_sh eq 1
	       or $option_export_sh eq '')
	{
	    $option_export_sh = "$global_target_command.sh";
	}

	# again we prefer to not need to press the shift key

	$option_export_sh =~ s/_/-/g;
    }

    # given the requested target and the command generate a useful filename for exporting execution times to a log file

    if (defined $option_export_times)
    {
	if ($option_export_times eq 0)
	{
	    $option_export_times = "/tmp/$global_target_command.times";
	}
	elsif ($option_export_times eq 1
	       or $option_export_times eq '')
	{
	    $option_export_times = "$global_target_command.times";
	}

	# again we prefer to not need to press the shift key

	$option_export_times =~ s/_/-/g;
    }

    # if we are using a build server

    if ($option_build_server)
    {
	die "$global_program_name: *** option_build_server is still in development";

	my $build_source = "";

	my $build_servers = $global_technical_project_configuration->{build_servers};

	my $build_server = $build_servers->{$option_build_server};

	if ($build_server->{name} ne 'laptop')
	{
	    my $ssh_user = $build_server->{ssh_user};

	    my $ssh_server = $build_server->{ssh_server};

	    my $tftp_directory = $build_server->{tftp_directory};

	    $build_source .= "$ssh_user\@$ssh_server";
	}

	# this results in something like this:
	#
	# ssh cornelih@cbi.utsa.edu tmux new-session -d 'project-workflow ssp build && bash'
	#
	# but I will likely also need to use sendkeys to detach from the session
	# also need to cd to the correct directory

	Engine::execute_shell_command("ssh $build_source tmux new-session -d 'neurospaces-workflow $requested_target $command && bash'");
    }

    # we are not using a build server

    else
    {
	# are we dry running all the commands of a module (target)?

	my $dry_run_module_commands;

	if ($option_interactions_all
	    or $option_interactions_module
	    or $option_interactions_module_all_roles)
	{
	    $dry_run_module_commands = 'option_interactions_module';

	    # make sure we don't actually run any commands

	    $option_dry_run = 'option_interactions_module';
	}

	if ($option_dump_module_interaction_roles)
	{
	    $dry_run_module_commands = 'option_dump_module_interaction_roles';

	    # make sure we don't actually run any commands

	    $option_dry_run = 'option_dump_module_interaction_roles';
	}

	if ($dry_run_module_commands)
	{
	    # generate the list of all commands

	    my $all_commands = generate_command_hash_with_structure('with help subs');

	    # loop over all the matching targets

	    my $all_defined_targets = $global_technical_project_configuration->{targets};

	    foreach my $defined_target (
					grep
					{
					    m(^$requested_target$);
					}
					keys %$all_defined_targets
				       )
	    {
		# reference subroutine names specific for the given target: they belong together

		my $target_subroutines = $all_commands->{$defined_target};

		# collect the subroutine names

		my $command_implementations
		    = [
		       map
		       {
			   my $subroutine = $_;

			   "Command::${defined_target}_${subroutine}";
		       }
		       keys %$target_subroutines,
		      ];

		# invoke all these subroutines in dry run mode to have them either generate or report the module roles

		foreach my $command_implementation (sort @$command_implementations)
		{
		    if ($option_verbose)
		    {
			print "Invoking ($command_implementation)\n";
		    }

		    if ($command_implementation =~ /_help$/)
		    {
			next;
		    }

		    my $has_help = '';

		    if (grep(/^${command_implementation}_help$/, @$command_implementations))
		    {
			$has_help = " (use --help to see the help page)";
		    }

		    $command_implementation =~ /Command::(.*)/;

		    my $short_command = $1;

		    # add a header to the schedule / diagram for this command

		    my $scheduled_command
			= {
			   command => "---\nCOMMAND: $short_command$has_help",
			   dry_run => $dry_run_module_commands,
			   interaction_role => 'none',
			  };

		    push @$global_scheduled_commands, $scheduled_command;

		    # add the command to the schedule / diagram

		    {
			no strict "refs";

			&$command_implementation([]);
		    }

		    # end the command in the schedule / diagram

		    $scheduled_command
			= {
			   command => "\n\n---\n",
			   dry_run => $dry_run_module_commands,
			   interaction_role => 'none',
			  };

		    push @$global_scheduled_commands, $scheduled_command;
		}
	    }
	}
	else
	{
	    my $command_implementation;

	    my $type_package_builtin;

	    if (exists $global_known_command_packages_builtin->{$command})
	    {
		my $sub_name = shift @ARGV;

		if (!defined $sub_name)
		{
		    die "$0: *** Error: No function name given while trying to use a builtin package '$command'";
		}

		$type_package_builtin = $command;

		# if help was requested for this command

		if ($option_help)
		{
		    # call the subroutine that implements the help function

		    $sub_name .= "_help";
		}

		$command_implementation = "${command}::$sub_name";
	    }
	    else
	    {
		# if help was requested for this command

		if ($option_help)
		{
		    # call the subroutine that implements the help function

		    $command .= "_help";
		}

		$command_implementation = "Command::${requested_target}_${command}";
	    }

	    if ($option_verbose)
	    {
		print "Invoking ($command_implementation)\n";
	    }

	    # if this command exists ...

	    my $command_hash = generate_command_hash_typed('with help subs');

	    if (defined $option_verbose
		and $option_verbose > 2)
	    {
		use Data::Dumper;

		print Dumper( { command_hash_with_help_subs => $command_hash, }, );
	    }

	    if (exists $command_hash->{"$requested_target $command"}
	        or $type_package_builtin)
	    {
		# ... either invoke the --help sub

		if ($option_help)
		{
		    no strict "refs";

		    my $command_name = $command_implementation;

		    $command_name =~ s(^Command::)();
		    $command_name =~ s(^([a-z0-9]+?)_)($1 );
		    $command_name =~ s(_help$)();

		    my $help_string = &$command_implementation($command_name, \@ARGV);

		    # old style help pages ...

		    if ($help_string =~ /^[0-9]*$/)
		    {
			# ... are printed by the help function
		    }

		    # new style help pages ...

		    else
		    {
			# ... are printed by us

			print "$global_program_name $help_string\n";
		    }
		}

		# ... or invoke the implementation sub of the command ...

		else
		{
		    # ... depending on the type of the requested command ...

		    my $type = $command_hash->{"$requested_target $command"};

		    # ... either as a regular perl sub ...

		    if ($type_package_builtin
			or $type eq 'sub')
		    {
			no strict "refs";

			my $error = &$command_implementation(\@ARGV);

			if ($error)
			{
			    # die "$global_program_name: *** Error: $error";

			    warn "$global_program_name: *** Warning: $requested_target $command generated an warning response ($error)";
			}
		    }

		    # ... or as a shell script ...

		    elsif ($type eq 'sh')
		    {
			# invoke the script as a single command

			my $commands_data_directory = $global_field_project_configuration->{sources_configuration_data_directory};

			my $shell_script = "$commands_data_directory/$requested_target/$command";

			Command::execute_shell_command(join ' ', "$shell_script.sh", map { "'$_'" } @ARGV );
		    }

		    # ... or as a yaml script ...

		    elsif ($type eq 'yml')
		    {
		    }

		    # ... or we have an error

		    else
		    {
			die "$global_program_name: *** Error: unknown command type $type when invoking command '$requested_target $command'";
		    }
		}
	    }
	    else
	    {
		die "$global_program_name: *** Error: Either target '$requested_target' does not exist or it does not provide command '$command'.";
	    }
	}

	Engine::execute_all_scheduled_commands($global_interaction_roles);
    }
}


sub parse_command_line
{
    my $result = GetOptionsFromArray(\@ARGV, %$global_options);

    if (!$result)
    {
        die "$global_program_name: *** error in option processing, try --help";
    }

    # my $asking_help = ($option_help
    # 		       or $option_help_build_servers
    # 		       or $option_help_commands
    # 		       or $option_help_packages
    # 		       or $option_help_projects
    # 		       or $option_help_targets);

    # try to make sure there is a target early on

    if (not defined $option_target
	and scalar @ARGV)
    {
	$option_target = shift @ARGV;
    }

    # try to make sure there is a command on this target early on

    if (not defined $option_commands->[0]
	and scalar @ARGV)
    {
	$option_commands->[0] = shift @ARGV;
    }

    if ($option_help and (not $option_target) and (not $option_commands->[0]))
    {
        print
            "
$global_program_name: support for workflow design for embedded software engineers.

SYNOPSIS

$global_program_name <options> <target> <command> -- < ... command specific options and arguments ... >

EXAMPLES -- first try these with the --dry-run to understand what they do:

  \$ $global_program_name --help-targets                                       # display the available targets that are found in the configuration file.

  \$ $global_program_name --help-commands                                      # display the available commands that are found in the configuration file.

  \$ $global_program_name ssp build                                            # 'build' the 'ssp' target (if it exists for your local configuration).

  \$ $global_program_name --dry-run ssp build                                  # display the shell commands that would be executed to 'build' the 'ssp' target.

options:
    --bash-completion               compute bash completion for the given command line.
                                    hint: the bash completion script implements completion for options, targets and commands.
    --branch                        git branch to work with.
    --build-server                  the build server profile to work with.
    --built-image-directory         the directory on the build server where the built images are to be found.
    --command                       commands to execute, hyphens (-) in the command will be replaced with underscores (_).
    --dry-run                       if set, do not execute system shell commands but print them to STDOUT.
    --dump-all-interaction-roles    dump all the interaction roles found in the configuration.
    --dump-interaction-roles        dump the found interaction roles (note that they depend on the scheduled commands).
    --dump-module-interaction-roles dump all the interaction roles found in the module of the given command.
    --dump-schedule                 dump the constructed schedule to standard output without executing the scheduled commands.
    --export-remote                 include the remote access part of exported commands.
                                    this option takes a number: 0 means all roles are exported, any other number exports only that respective role.
    --export-sh                     export the commands to a file with the given name.
    --export-sudo                   include the sudo commands when exporting commands to a file.
    --export-times                  export the times when commands are started and ended to a file with the given name.
    --export-verbose                when exporting the commands to a file, interleave them with echo commands.
    --force-rebuild                 force a rebuild regardless of the existence and build date of previously built artefacts.
    --forward-destination           the target file forward destination to copy to.
    --forward-source                the target file forward source to copy from.
    --help                          display usage information and stop execution.
    --help-build-servers            display the known build servers.
    --help-commands                 display the available commands, add a target name for restricted output.
    --help-field-project-name       print the field project name and exit.
    --help-module                   display all the available help information about the commands of the module.
    --help-module-all               display all the available convenience modules.
    --help-options                  print the option values.
    --help-packages                 display known package and overriden package information and stop execution.
    --help-projects                 display known project information and stop execution.
    --help-targets                  display known targets and stop execution.
    --incremental                   assume an incremental build (default is " . ($option_incremental ? "yes" : "no") . "
    --interactions                  show the interaction diagram of the commands.
    --interactions-all              show a diagram with all the commands and all the interaction roles.
    --interactions-module           show the interaction diagram of all the commands in the module.
    --interactions-module-all-roles show the interaction diagram of the commands using all the found interaction roles in the configuration.
    --packages                      packages to operate on, can be given multiple times.
    --ssh-port                      the ssh port.
    --ssh-server                    the used ssh build server.
    --ssh-user                      ssh-user on the build server (please configure your public key).
    --target                        the target to apply the given commands to.
    --tftp-directory                the target tftp directory (eg. where your device will find its kernel and rootfs).
    --verbose                       set verbosity level.

NOTES

OVERRIDE_SRCDIR delivered packages for Buildroot targets are recognized.

";

	exit 0;
    }

    if (defined $option_build_server)
    {
	my $build_servers = $global_technical_project_configuration->{build_servers};

	if (not exists $build_servers->{$option_build_server})
	{
	    die "$global_program_name: *** Error: unknown build server $option_build_server, use --help-build-servers to learn about the known servers";
	}

	# if (not defined $option_ssh_server)
	# {
	#     $option_ssh_server = $build_servers->{$option_build_server}->{ssh_server};
	# }

	# if (not defined $option_ssh_user)
	# {
	#     $option_ssh_user = $build_servers->{$option_build_server}->{ssh_user};
	# }

	if (not defined $option_ssh_port)
	{
	    $option_ssh_port = $build_servers->{$option_build_server}->{ssh_port};
	}

	# if (not defined $option_tftp_directory)
	# {
	#     $option_tftp_directory = $build_servers->{$option_build_server}->{tftp_directory};
	# }

	# if (not defined $option_built_image_directory)
	# {
	#     $option_built_image_directory = $build_servers->{$option_build_server}->{built_image_directory};
	# }
    }

    my $build_servers = $global_technical_project_configuration->{build_servers};

    my $status;

    if (defined $option_forward_destination_server)
    {
	if (not exists $build_servers->{$option_forward_destination_server})
	{
	    $status = "$global_program_name: *** Error: unknown forwarding server $option_forward_destination_server, use --help-build-servers to learn about the known servers";
	}
    }

    if (defined $option_forward_source_server)
    {
	if (not exists $build_servers->{$option_forward_source_server})
	{
	    $status = "$global_program_name: *** Error: unknown forwarding server $option_forward_source_server, use --help-build-servers to learn about the known servers";
	}
    }

    if ($option_help_build_servers)
    {
	use YAML;

	print Dump( { build_servers => $build_servers, }, );

	exit 0;
    }

    if ($option_help_commands)
    {
	use YAML;

	my $commands = generate_command_list();

	if ($option_target)
	{
	    $commands
		= [
		   grep
		   {
		       /$option_target/;
		   }
		   @$commands,
		  ];
	}

	$commands
	    = [
	       sort
	       {
		   $a cmp $b;
	       }
	       map
	       {
		   "$global_program_name $_";
	       }
	       @$commands,
	      ];

	print Dump(
		   {
		    '0_description' => "The list of available commands for this project are
  (copy-paste the one you would like to execute,
   try them with the --dry-run and --interactions options,
   some commands may implement a usage message available with the --help option):",
		    '1_commmands' => $commands,
		   },
		  );

	exit 0;
    }

    if ($option_help_module
        or $option_help_module_all)
    {
	if (not defined $option_target
	    and $option_help_module)
	{
	    die "$global_program_name: *** Error: neither a target option nor target argument given, try '$global_program_name Command --help-module'";
	}

	my $known_command_packages
	    = {
	       'Command' => {
			     description => 'a library of workflows (try these ones: ' . (join ' or ', map { "'$global_program_name $_ --help-module'" } sort keys %$global_known_command_packages_builtin ) . ')',
			     documentation => 'each entry in the library provides a builtin set of workflows that facilitate the implementation of software projects',
			    },
	       %$global_known_command_packages_builtin,
	      };

	my $module_all_help
	    = [
	       map
	       {
		   generate_command_hash_subs($_, "with help subs");
	       }
	       keys %$known_command_packages,
	      ];

	if ($option_help_module)
	{
	    if (exists $known_command_packages->{$option_target})
	    {
		use YAML;

		print Dump( { $option_target => $known_command_packages->{$option_target}, }, );

		exit 0;
	    }
	    else
	    {
		die "$global_program_name: *** Error: module '$option_target' does not provide --help-module, does this module exist?'";
	    }
	}
	elsif ($option_help_module_all)
	{
	    use YAML;

	    print Dump( { help_module_all => $known_command_packages, }, );

	    exit 0;
	}
	else
	{
	    die "$global_program_name: *** Internal Error.";
	}
    }

    if ($option_help_options)
    {
	use YAML;

	print Dump( { "global_options" => $global_options, }, );

	exit 0;
    }

    if ($option_help_packages)
    {
	use YAML;

	my $packages = $global_technical_project_configuration->{packages};

	print Dump( { global_packages => $packages, }, );

	print Dump( { global_overriden_packages => $global_overriden_packages, }, );

	exit 0;
    }

    if ($option_help_field_project_name)
    {
	use YAML;

	print Dump( { global_field_project_configuration => $global_field_project_configuration, }, );

	exit 0;
    }

    # if ($option_help_node_configuration)
    # {
    # 	use YAML;

    # 	print Dump( { configuration => $global_node_configuration, }, );

    # 	exit 0;
    # }

    if ($option_help_projects)
    {
	use YAML;

	my $workflow_projects
	    = [
	       map
	       {
		   s(^.*?/bin/)(); $_;
	       }
	       map
	       {
		   chomp; "$_ --help-commands";
	       }
	       `ls -1 ~/bin/*workflow`,
	      ];

# 	my $projects = $global_technical_project_configuration->{projects};

	print Dump( { "available_workflow automation projects (copy-paste the one you would like to get help for)" => $workflow_projects, }, );

	exit 0;
    }

    if ($option_help_targets)
    {
	use YAML;

	my $targets = $global_technical_project_configuration->{targets};

	print Dump( { targets => $targets, }, );

	exit 0;
    }

    if ((not defined $option_interactions_all
	 and not defined $option_interactions_module_all_roles)
	and not defined $option_target)
    {
	die "$global_program_name: *** Error: neither a target option nor target argument given, try --help";
    }

    if ($FieldProject::status)
    {
	$status = $FieldProject::status;
    }

    # always allow the builtin commands (start a new project, add a new target, ...)

    #! they should do their own checking for a valid
    #! field_configuration, project_name as required.

    #t this may give an 'Use of uninitialized value in exists at /home/neurospaces/bin/workflow-tests-workflow line 7929.'
    #t *** Executing docker workflow-tests-workflow --bash-completion "workflow-tests-workflow perl_examples single_command aa 12" 5

    if ($option_target eq 'builtin'
	and (defined $option_commands->[0]
	     and exists $global_builtin_commands->{$option_commands->[0]})
	or (defined $option_commands->[0]
	    and exists $global_known_command_packages_builtin->{$option_commands->[0]}))
    {
    }
    else
    {
	if ($status)
	{
	    die $status;
	}
    }
}


# parse the package directories in local.mk

sub buildroot_parse_packages_directories
{
#     "$ENV{HOME}/projects/developer/source/snapshots/$branch";

    # packages listed in alphabetical order, dashes replaced with underscores

    my $package_overrides_filename = "local.mk";

    my $package_overrides;

    {
	# see also https://stackoverflow.com/questions/8963400/the-correct-way-to-read-a-data-file-into-an-array

	# local $/;		# enable localized slurp mode

	$package_overrides = [ `cat 2>/dev/null "$package_overrides_filename"` ];
    }

    # loop over all lines in local.mk

    my $overriden_packages;

    foreach my $package_override (@$package_overrides)
    {
	# we are only interested custom repositories

	if ($package_override !~ /_OVERRIDE_SRCDIR/)
	{
	    next;
	}

	if ($package_override =~ /_RSYNC_EXCLUSIONS/)
	{
	    next;
	}

	# skip comment lines

	if ($package_override =~ /^\s*#/)
	{
	    next;
	}

	#! beware of unmatched characters in the directory name

	$package_override =~ /^\s*(\w+)_OVERRIDE_SRCDIR\s*=\s*([\w\/\.-]*)/;

	my $package_name = lc $1;

	# # skip gcc related overrides, buildroot ignores them, we deal with them elsewhere

	# if ($package_name eq 'cr_gcc')
	# {
	#     next;
	# }

	my $package_directory = $2;

	$overriden_packages->{$package_name}->{directory} = $package_directory;

	if ($option_verbose)
	{
	    print "$global_program_name: *** added for package $package_name OVERRIDE_SRCDIR $package_directory\n";
	}
    }

    # propagate the overriden_packages

    return $overriden_packages;
}


# prepare the package directories in local.mk

sub buildroot_process_packages_directories
{
    my $overriden_packages = shift;

    # loop over all the overriden packages

    foreach my $package_name (sort keys %$overriden_packages)
    {
	# skip gcc related overrides, buildroot ignores them, we deal
	# with them in the build command of the toolchain target

	if ($package_name eq 'cr_gcc')
	{
	    next;
	}

	# get the package source directory from the override

	my $package_directory = $overriden_packages->{$package_name}->{directory};

	# get the build directory from the globally known packages

	my $packages = $global_technical_project_configuration->{packages};

	my $build_directory = $packages->{$package_name}->{build_directory};

	if (not defined $build_directory)
	{
	    die "$global_program_name: *** Fatal: package $package_name has no build_directory defined in the package list";
	}

	# Engine::execute_shell_command("mkdir --parents '$build_directory'");

	# Engine::execute_shell_command("cp -a '$package_directory'/* '$build_directory'");

	# my $stamp_filenames = $global_technical_project_configuration->{stamp_filenames};

	# my $stamp_built = $stamp_filenames->[0];

	# Engine::execute_shell_command("rm -f '$build_directory/$stamp_built'");
    }
}


main();


